{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from io import BufferedReader\n",
    "import import_ipynb\n",
    "#import optimization_cvxopt\n",
    "\n",
    "\n",
    "# THIS CODE NEEDS TO BE RUN BEFORE MAKING THE SQL CONNECTION\n",
    "\n",
    "pymysql.converters.encoders[np.float64] = pymysql.converters.escape_float\n",
    "pymysql.converters.conversions = pymysql.converters.encoders.copy()\n",
    "pymysql.converters.conversions.update(pymysql.converters.decoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "#from pandas_datareader import data as pdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{'':'',.6f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are importing all data of 10 years (2009-2019), from Balance sheet, Cash flow statement and Income statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querybs = \"SELECT * from balance_sheet\"\n",
    "\n",
    "dfbs =pd.read_sql(querybs,engine)\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querycf = \"SELECT * from cash_flow_stmt\"\n",
    "\n",
    "dfcf =pd.read_sql(querycf,engine)\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "queryis = \"SELECT * from income_statement\"\n",
    "\n",
    "dfis =pd.read_sql(queryis,engine)\n",
    "#dfis.head()\n",
    "# dffr.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "# dffr.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data loaded to sql is in text format (through python to_sql() method, we are converting data to required date and numeric format below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_NON_CURR_LIABILITIES</th>\n",
       "      <th>TOTAL_LIABILITIES</th>\n",
       "      <th>OTHER_COMPREHENSIVE_INCOME</th>\n",
       "      <th>RETAINED_EARNINGS_DEFICIT</th>\n",
       "      <th>TOTAL_SHAREHOLDERS_EQUITY</th>\n",
       "      <th>INVESTMENTS</th>\n",
       "      <th>NET_DEBT</th>\n",
       "      <th>OTHER_ASSETS</th>\n",
       "      <th>OTHER_LIABILITIES</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>10693000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.140513e+09</td>\n",
       "      <td>-4540000.0</td>\n",
       "      <td>17186000.0</td>\n",
       "      <td>97219000.0</td>\n",
       "      <td>1.130447e+09</td>\n",
       "      <td>-26481000.0</td>\n",
       "      <td>7253000.0</td>\n",
       "      <td>1.102567e+09</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44998000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>15785000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073114e+09</td>\n",
       "      <td>-1745000.0</td>\n",
       "      <td>6779000.0</td>\n",
       "      <td>89191000.0</td>\n",
       "      <td>1.055844e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002689e+09</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120006000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92000000.0</td>\n",
       "      <td>26875000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.105228e+09</td>\n",
       "      <td>-1560000.0</td>\n",
       "      <td>8531000.0</td>\n",
       "      <td>90371000.0</td>\n",
       "      <td>1.002782e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.015381e+09</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27395000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>27807000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004440e+09</td>\n",
       "      <td>-238000.0</td>\n",
       "      <td>3714000.0</td>\n",
       "      <td>86178000.0</td>\n",
       "      <td>9.857260e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.932110e+08</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>35667000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.186310e+08</td>\n",
       "      <td>1138000.0</td>\n",
       "      <td>-32126000.0</td>\n",
       "      <td>51398000.0</td>\n",
       "      <td>8.811420e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "0       FNCB            36481000.0                    0.0   \n",
       "1       FNCB            37746000.0                    0.0   \n",
       "2       FNCB           112445000.0                    0.0   \n",
       "3       FNCB            21083000.0                    0.0   \n",
       "4       FNCB            35667000.0                    NaN   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "0             36481000.0          0.0          0.0            43734000.0   \n",
       "1             37746000.0          0.0          0.0            44998000.0   \n",
       "2            112445000.0          0.0          0.0           120006000.0   \n",
       "3             21083000.0          0.0          0.0            27395000.0   \n",
       "4                    NaN          0.0          0.0                   NaN   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  ...   \\\n",
       "0                         0.0             11000000.0  10693000.0  ...    \n",
       "1                         0.0             16000000.0  15785000.0  ...    \n",
       "2                         0.0             92000000.0  26875000.0  ...    \n",
       "3                         0.0              2000000.0  27807000.0  ...    \n",
       "4                    302000.0                    NaN         0.0  ...    \n",
       "\n",
       "   TOTAL_NON_CURR_LIABILITIES  TOTAL_LIABILITIES  OTHER_COMPREHENSIVE_INCOME  \\\n",
       "0                         NaN       1.140513e+09                  -4540000.0   \n",
       "1                         NaN       1.073114e+09                  -1745000.0   \n",
       "2                         NaN       1.105228e+09                  -1560000.0   \n",
       "3                         NaN       1.004440e+09                   -238000.0   \n",
       "4                         NaN       9.186310e+08                   1138000.0   \n",
       "\n",
       "   RETAINED_EARNINGS_DEFICIT  TOTAL_SHAREHOLDERS_EQUITY   INVESTMENTS  \\\n",
       "0                 17186000.0                 97219000.0  1.130447e+09   \n",
       "1                  6779000.0                 89191000.0  1.055844e+09   \n",
       "2                  8531000.0                 90371000.0  1.002782e+09   \n",
       "3                  3714000.0                 86178000.0  9.857260e+08   \n",
       "4                -32126000.0                 51398000.0  8.811420e+08   \n",
       "\n",
       "     NET_DEBT  OTHER_ASSETS  OTHER_LIABILITIES  year  \n",
       "0 -26481000.0     7253000.0       1.102567e+09  2018  \n",
       "1         NaN           NaN       1.002689e+09  2017  \n",
       "2         NaN           NaN       1.015381e+09  2016  \n",
       "3         NaN           NaN       8.932110e+08  2015  \n",
       "4         NaN           NaN                NaN  2014  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>DEPRECIATION_AMORTIZATION</th>\n",
       "      <th>STOCK_BASED_COMPENSATION</th>\n",
       "      <th>OPERATING_CASH_FLOW</th>\n",
       "      <th>CAPITAL_EXPENDITURE</th>\n",
       "      <th>ACQUISITIONS_DISPOSALS</th>\n",
       "      <th>INVESTMENT_PURCHASES_SALES</th>\n",
       "      <th>INVESTING_CASH_FLOW</th>\n",
       "      <th>ISSUANCE_DEBT_REPAYMENT</th>\n",
       "      <th>ISSUANCE_SHARES_BUYBACKS</th>\n",
       "      <th>DIVIDEND_PAYMENTS</th>\n",
       "      <th>FINANCING_CASH_FLOW</th>\n",
       "      <th>EFFECT_FOREX_CHANGES</th>\n",
       "      <th>NET_CASH_FLOW</th>\n",
       "      <th>FREE_CASH_FLOW</th>\n",
       "      <th>NET_CASH_MARKET_CAP</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>1.067600e+10</td>\n",
       "      <td>826000000.0</td>\n",
       "      <td>2.429700e+10</td>\n",
       "      <td>-1.231200e+10</td>\n",
       "      <td>-3.807800e+10</td>\n",
       "      <td>-1.257000e+09</td>\n",
       "      <td>-5.085400e+10</td>\n",
       "      <td>3.636200e+10</td>\n",
       "      <td>-5.320000e+09</td>\n",
       "      <td>-3.352000e+09</td>\n",
       "      <td>2.714000e+10</td>\n",
       "      <td>-245000000.0</td>\n",
       "      <td>3.380000e+08</td>\n",
       "      <td>1.198500e+10</td>\n",
       "      <td>-0.6967</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>9.688000e+09</td>\n",
       "      <td>751000000.0</td>\n",
       "      <td>2.126100e+10</td>\n",
       "      <td>-1.164400e+10</td>\n",
       "      <td>-3.820000e+08</td>\n",
       "      <td>-2.292000e+09</td>\n",
       "      <td>-1.353300e+10</td>\n",
       "      <td>3.197000e+09</td>\n",
       "      <td>-5.435000e+09</td>\n",
       "      <td>-2.883000e+09</td>\n",
       "      <td>-7.572000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.560000e+08</td>\n",
       "      <td>9.617000e+09</td>\n",
       "      <td>-0.3185</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>9.426000e+09</td>\n",
       "      <td>640000000.0</td>\n",
       "      <td>1.969100e+10</td>\n",
       "      <td>-1.113700e+10</td>\n",
       "      <td>-3.711000e+09</td>\n",
       "      <td>-3.446000e+09</td>\n",
       "      <td>-1.826500e+10</td>\n",
       "      <td>7.969000e+09</td>\n",
       "      <td>-5.329000e+09</td>\n",
       "      <td>-2.601000e+09</td>\n",
       "      <td>-4.340000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.920000e+08</td>\n",
       "      <td>8.554000e+09</td>\n",
       "      <td>-0.3388</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>8.680000e+09</td>\n",
       "      <td>567000000.0</td>\n",
       "      <td>1.948500e+10</td>\n",
       "      <td>-1.004700e+10</td>\n",
       "      <td>-1.353000e+09</td>\n",
       "      <td>-8.020000e+08</td>\n",
       "      <td>-1.196400e+10</td>\n",
       "      <td>1.243000e+09</td>\n",
       "      <td>-7.139000e+09</td>\n",
       "      <td>-2.437000e+09</td>\n",
       "      <td>-9.136000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.615000e+09</td>\n",
       "      <td>9.438000e+09</td>\n",
       "      <td>-0.3628</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>8.019000e+09</td>\n",
       "      <td>513000000.0</td>\n",
       "      <td>1.694500e+10</td>\n",
       "      <td>-8.585000e+09</td>\n",
       "      <td>1.890000e+08</td>\n",
       "      <td>-1.910000e+08</td>\n",
       "      <td>-8.733000e+09</td>\n",
       "      <td>5.030000e+08</td>\n",
       "      <td>-4.216000e+09</td>\n",
       "      <td>-2.254000e+09</td>\n",
       "      <td>-6.020000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.192000e+09</td>\n",
       "      <td>8.360000e+09</td>\n",
       "      <td>-0.2915</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  DEPRECIATION_AMORTIZATION  STOCK_BASED_COMPENSATION  \\\n",
       "0      CMCSA               1.067600e+10               826000000.0   \n",
       "1      CMCSA               9.688000e+09               751000000.0   \n",
       "2      CMCSA               9.426000e+09               640000000.0   \n",
       "3      CMCSA               8.680000e+09               567000000.0   \n",
       "4      CMCSA               8.019000e+09               513000000.0   \n",
       "\n",
       "   OPERATING_CASH_FLOW  CAPITAL_EXPENDITURE  ACQUISITIONS_DISPOSALS  \\\n",
       "0         2.429700e+10        -1.231200e+10           -3.807800e+10   \n",
       "1         2.126100e+10        -1.164400e+10           -3.820000e+08   \n",
       "2         1.969100e+10        -1.113700e+10           -3.711000e+09   \n",
       "3         1.948500e+10        -1.004700e+10           -1.353000e+09   \n",
       "4         1.694500e+10        -8.585000e+09            1.890000e+08   \n",
       "\n",
       "   INVESTMENT_PURCHASES_SALES  INVESTING_CASH_FLOW  ISSUANCE_DEBT_REPAYMENT  \\\n",
       "0               -1.257000e+09        -5.085400e+10             3.636200e+10   \n",
       "1               -2.292000e+09        -1.353300e+10             3.197000e+09   \n",
       "2               -3.446000e+09        -1.826500e+10             7.969000e+09   \n",
       "3               -8.020000e+08        -1.196400e+10             1.243000e+09   \n",
       "4               -1.910000e+08        -8.733000e+09             5.030000e+08   \n",
       "\n",
       "   ISSUANCE_SHARES_BUYBACKS  DIVIDEND_PAYMENTS  FINANCING_CASH_FLOW  \\\n",
       "0             -5.320000e+09      -3.352000e+09         2.714000e+10   \n",
       "1             -5.435000e+09      -2.883000e+09        -7.572000e+09   \n",
       "2             -5.329000e+09      -2.601000e+09        -4.340000e+08   \n",
       "3             -7.139000e+09      -2.437000e+09        -9.136000e+09   \n",
       "4             -4.216000e+09      -2.254000e+09        -6.020000e+09   \n",
       "\n",
       "   EFFECT_FOREX_CHANGES  NET_CASH_FLOW  FREE_CASH_FLOW  NET_CASH_MARKET_CAP  \\\n",
       "0          -245000000.0   3.380000e+08    1.198500e+10              -0.6967   \n",
       "1                   0.0   1.560000e+08    9.617000e+09              -0.3185   \n",
       "2                   0.0   9.920000e+08    8.554000e+09              -0.3388   \n",
       "3                   0.0  -1.615000e+09    9.438000e+09              -0.3628   \n",
       "4                   0.0   2.192000e+09    8.360000e+09              -0.2915   \n",
       "\n",
       "   year  \n",
       "0  2018  \n",
       "1  2017  \n",
       "2  2016  \n",
       "3  2015  \n",
       "4  2014  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "43214"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>REVENUE_GROWTH</th>\n",
       "      <th>COST_OF_REVENUE</th>\n",
       "      <th>GROSS_PROFIT</th>\n",
       "      <th>RND_EXPENSES</th>\n",
       "      <th>SGNA_EXPENSES</th>\n",
       "      <th>OPERATING_EXPENSES</th>\n",
       "      <th>OPERATING_INCOME</th>\n",
       "      <th>INTEREST_EXPENSE</th>\n",
       "      <th>...</th>\n",
       "      <th>EBITDA_MARGIN</th>\n",
       "      <th>EBIT_MARGIN</th>\n",
       "      <th>PROFIT_MARGIN</th>\n",
       "      <th>FCF_MARGIN</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>9.450700e+10</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94507000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.482200e+10</td>\n",
       "      <td>75498000000</td>\n",
       "      <td>19009000000</td>\n",
       "      <td>3542000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>2.932900e+10</td>\n",
       "      <td>18653000000</td>\n",
       "      <td>1.186200e+10</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>8.502900e+10</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85029000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.732300e+10</td>\n",
       "      <td>67011000000</td>\n",
       "      <td>18018000000</td>\n",
       "      <td>3086000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>2.794000e+10</td>\n",
       "      <td>18252000000</td>\n",
       "      <td>2.292200e+10</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.2674</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>8.073600e+10</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80736000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.447900e+10</td>\n",
       "      <td>63905000000</td>\n",
       "      <td>16831000000</td>\n",
       "      <td>2942000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>2.634400e+10</td>\n",
       "      <td>16918000000</td>\n",
       "      <td>9.028000e+09</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>7.451000e+10</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74510000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.983200e+10</td>\n",
       "      <td>58512000000</td>\n",
       "      <td>15998000000</td>\n",
       "      <td>2702000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>2.450400e+10</td>\n",
       "      <td>15824000000</td>\n",
       "      <td>8.413000e+09</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>6.877500e+10</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68775000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.585200e+10</td>\n",
       "      <td>53871000000</td>\n",
       "      <td>14904000000</td>\n",
       "      <td>2617000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>2.288900e+10</td>\n",
       "      <td>14870000000</td>\n",
       "      <td>8.592000e+09</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1218</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR       REVENUE  REVENUE_GROWTH  COST_OF_REVENUE GROSS_PROFIT  \\\n",
       "0      CMCSA  9.450700e+10          0.1115              0.0  94507000000   \n",
       "1      CMCSA  8.502900e+10          0.0532              0.0  85029000000   \n",
       "2      CMCSA  8.073600e+10          0.0836              0.0  80736000000   \n",
       "3      CMCSA  7.451000e+10          0.0834              0.0  74510000000   \n",
       "4      CMCSA  6.877500e+10          0.0637              0.0  68775000000   \n",
       "\n",
       "   RND_EXPENSES  SGNA_EXPENSES OPERATING_EXPENSES OPERATING_INCOME  \\\n",
       "0           0.0   6.482200e+10        75498000000      19009000000   \n",
       "1           0.0   5.732300e+10        67011000000      18018000000   \n",
       "2           0.0   5.447900e+10        63905000000      16831000000   \n",
       "3           0.0   4.983200e+10        58512000000      15998000000   \n",
       "4           0.0   4.585200e+10        53871000000      14904000000   \n",
       "\n",
       "  INTEREST_EXPENSE  ...   EBITDA_MARGIN  EBIT_MARGIN PROFIT_MARGIN FCF_MARGIN  \\\n",
       "0       3542000000  ...            0.31       0.1974         0.124     0.1268   \n",
       "1       3086000000  ...           0.329       0.2147         0.267     0.1131   \n",
       "2       2942000000  ...           0.326       0.2095         0.107     0.1060   \n",
       "3       2702000000  ...           0.329       0.2124          0.11     0.1267   \n",
       "4       2617000000  ...           0.333       0.2162         0.122     0.1216   \n",
       "\n",
       "         EBITDA         EBIT  CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  \\\n",
       "0  2.932900e+10  18653000000         1.186200e+10                  0.1599   \n",
       "1  2.794000e+10  18252000000         2.292200e+10                  0.1784   \n",
       "2  2.634400e+10  16918000000         9.028000e+09                  0.1731   \n",
       "3  2.450400e+10  15824000000         8.413000e+09                  0.1761   \n",
       "4  2.288900e+10  14870000000         8.592000e+09                  0.1782   \n",
       "\n",
       "   NET_PROFIT_MARGIN  year  \n",
       "0             0.1241  2018  \n",
       "1             0.2674  2017  \n",
       "2             0.1075  2016  \n",
       "3             0.1096  2015  \n",
       "4             0.1218  2014  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "43353"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbs['DATE_YEAR'] = pd.to_datetime(dfbs['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfbs['year'] = pd.DatetimeIndex(dfbs['DATE_YEAR']).year\n",
    "dfcf['DATE_YEAR'] = pd.to_datetime(dfcf['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfcf['year'] = pd.DatetimeIndex(dfcf['DATE_YEAR']).year\n",
    "dfis['DATE_YEAR'] = pd.to_datetime(dfis['DATE_YEAR'], format='%Y-%m-%d')\n",
    "dfis['year'] = pd.DatetimeIndex(dfis['DATE_YEAR']).year\n",
    "del dfbs['index']\n",
    "del dfcf['index']\n",
    "del dfis['index']\n",
    "del dfbs['DATE_YEAR']\n",
    "del dfcf['DATE_YEAR']\n",
    "del dfis['DATE_YEAR']\n",
    "\n",
    "\n",
    "dfbs.head()\n",
    "dfbs.shape[0]\n",
    "dfcf.head()\n",
    "dfcf.shape[0]\n",
    "dfis.head()\n",
    "#dffr.info()\n",
    "dfis.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfbs.columns\n",
    "# dfcf.columns\n",
    "# dfis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use Series.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use Series.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use Series.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "floatlist = ['CASH_CASH_EQUIVALENT','SHORT_TERM_INVESTMNET', 'CASH_SHORT_TERM_INVST', 'RECEIVABLES',\n",
    "       'INVENTORIES', 'TOTAL_CURRENT_ASSETS', 'GOODWILL_INTANGIBLE_ASSETS',\n",
    "       'LONG_TERM_INVESTMENTS', 'TAX_ASSETS', 'TOTAL_NON_CURR_ASSETS',\n",
    "       'TOTAL_ASSETS', 'PAYABLES', 'SHORT_TERM_DEBT', 'TOTAL_CURR_LIABILITIES',\n",
    "       'LONG_TERM_DEBT', 'TOTAL_DEBT', 'DEFERRED_REVENUE', 'TAX_LIABILITIES',\n",
    "       'DEPOSIT_LIABILITIES', 'TOTAL_NON_CURR_LIABILITIES',\n",
    "       'TOTAL_LIABILITIES', 'OTHER_COMPREHENSIVE_INCOME',\n",
    "       'RETAINED_EARNINGS_DEFICIT', 'TOTAL_SHAREHOLDERS_EQUITY', 'INVESTMENTS',\n",
    "       'NET_DEBT', 'OTHER_ASSETS', 'OTHER_LIABILITIES']\n",
    "\n",
    "floatlist2 = ['DEPRECIATION_AMORTIZATION','STOCK_BASED_COMPENSATION', 'OPERATING_CASH_FLOW',\n",
    "       'CAPITAL_EXPENDITURE', 'ACQUISITIONS_DISPOSALS',\n",
    "       'INVESTMENT_PURCHASES_SALES', 'INVESTING_CASH_FLOW',\n",
    "       'ISSUANCE_DEBT_REPAYMENT', 'ISSUANCE_SHARES_BUYBACKS',\n",
    "       'DIVIDEND_PAYMENTS', 'FINANCING_CASH_FLOW', 'EFFECT_FOREX_CHANGES',\n",
    "       'NET_CASH_FLOW', 'FREE_CASH_FLOW', 'NET_CASH_MARKET_CAP']\n",
    "\n",
    "floatlist3 = ['REVENUE', 'REVENUE_GROWTH','COST_OF_REVENUE', 'GROSS_PROFIT', 'RND_EXPENSES', 'SGNA_EXPENSES',\n",
    "       'OPERATING_EXPENSES', 'OPERATING_INCOME', 'INTEREST_EXPENSE',\n",
    "       'EARNINGS_BEFORE_TAX', 'INCOME_TAX_EXPENSE',\n",
    "       'NET_INC_NON_CONTROLLING_INT', 'NET_INC_DISCONTINUED_OPS', 'NET_INCOME',\n",
    "       'PREFERRED_DIVIDENDS', 'NET_INCOME_COM', 'EPS', 'EPS_DILUTED',\n",
    "       'WEIGHTED_AVERAGE_SHS_OUT', 'WEIGHTED_AVERAGE_SHS_OUT_DIL',\n",
    "       'DIVIDEND_PER_SHARE', 'GROSS_MARGIN', 'EBITDA_MARGIN', 'EBIT_MARGIN',\n",
    "       'PROFIT_MARGIN', 'FCF_MARGIN', 'EBITDA', 'EBIT', 'CONSOLIDATED_INCOME',\n",
    "       'EARNINGS_BEFORE_MARGIN', 'NET_PROFIT_MARGIN']\n",
    "\n",
    "for eachcol in floatlist:\n",
    "    #print(eachcol)\n",
    "    dfbs[eachcol] = dfbs[eachcol].convert_objects(convert_numeric=True)\n",
    "for eachcol in floatlist2:\n",
    "    #print(eachcol)\n",
    "    dfcf[eachcol] = dfcf[eachcol].convert_objects(convert_numeric=True)\n",
    "for eachcol in floatlist3:\n",
    "    #print(eachcol)\n",
    "    dfis[eachcol] = dfis[eachcol].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Below code we are combining all financial statements in a single dataframe with company profile to load sector and market cap of each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPY</td>\n",
       "      <td></td>\n",
       "      <td>277445802779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMCSA</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>197130041640.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KMI</td>\n",
       "      <td>Energy</td>\n",
       "      <td>44153800000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTC</td>\n",
       "      <td>Technology</td>\n",
       "      <td>270780975000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MU</td>\n",
       "      <td>Technology</td>\n",
       "      <td>52931710000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR             sector           mktCap\n",
       "0        SPY                        277445802779\n",
       "1      CMCSA  Consumer Cyclical  197130041640.77\n",
       "2        KMI             Energy   44153800000.00\n",
       "3       INTC         Technology  270780975000.00\n",
       "4         MU         Technology   52931710000.00"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "querysp = \"SELECT STK_TKR, sector,mktCap from stock_profile\"\n",
    "\n",
    "dfsp =pd.read_sql(querysp,engine)\n",
    "dfsp.rename(columns = {'STK_TKR':'STOCK_TIKR'}, inplace = True)\n",
    "dfsp.head()\n",
    "#dfsf.rename(columns = {'Date_year':'DATE_YEAR'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBIT_MARGIN</th>\n",
       "      <th>PROFIT_MARGIN</th>\n",
       "      <th>FCF_MARGIN</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>10693000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>19388000.0</td>\n",
       "      <td>16420000.0</td>\n",
       "      <td>13349000.0</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44998000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>15785000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>13951000.0</td>\n",
       "      <td>11435000.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120006000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92000000.0</td>\n",
       "      <td>26875000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>10660000.0</td>\n",
       "      <td>8056000.0</td>\n",
       "      <td>6309000.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27395000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>27807000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>9784000.0</td>\n",
       "      <td>8081000.0</td>\n",
       "      <td>35840000.0</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>35667000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>15216000.0</td>\n",
       "      <td>13746000.0</td>\n",
       "      <td>13420000.0</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "0       FNCB            36481000.0                    0.0   \n",
       "1       FNCB            37746000.0                    0.0   \n",
       "2       FNCB           112445000.0                    0.0   \n",
       "3       FNCB            21083000.0                    0.0   \n",
       "4       FNCB            35667000.0                    NaN   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "0             36481000.0          0.0          0.0            43734000.0   \n",
       "1             37746000.0          0.0          0.0            44998000.0   \n",
       "2            112445000.0          0.0          0.0           120006000.0   \n",
       "3             21083000.0          0.0          0.0            27395000.0   \n",
       "4                    NaN          0.0          0.0                   NaN   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  \\\n",
       "0                         0.0             11000000.0  10693000.0   \n",
       "1                         0.0             16000000.0  15785000.0   \n",
       "2                         0.0             92000000.0  26875000.0   \n",
       "3                         0.0              2000000.0  27807000.0   \n",
       "4                    302000.0                    NaN         0.0   \n",
       "\n",
       "       ...       EBIT_MARGIN  PROFIT_MARGIN  FCF_MARGIN      EBITDA  \\\n",
       "0      ...            0.3589          0.292      0.3746  19388000.0   \n",
       "1      ...            0.2895          0.004      0.2702  13951000.0   \n",
       "2      ...            0.2263          0.177     -0.0120  10660000.0   \n",
       "3      ...            0.2211          0.981      0.0832   9784000.0   \n",
       "4      ...            0.2905          0.284      0.2071  15216000.0   \n",
       "\n",
       "         EBIT  CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  \\\n",
       "0  16420000.0           13349000.0                  0.3589             0.2918   \n",
       "1  11435000.0             147000.0                  0.2895             0.0037   \n",
       "2   8056000.0            6309000.0                  0.2263             0.1772   \n",
       "3   8081000.0           35840000.0                  0.2211             0.9807   \n",
       "4  13746000.0           13420000.0                  0.2905             0.2836   \n",
       "\n",
       "               sector        mktCap  \n",
       "0  Financial Services  136743892.56  \n",
       "1  Financial Services  136743892.56  \n",
       "2  Financial Services  136743892.56  \n",
       "3  Financial Services  136743892.56  \n",
       "4  Financial Services  136743892.56  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45911"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(45911, 78)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffrs1 = pd.merge(dfbs,dfcf, on=['STOCK_TIKR','year'])\n",
    "dffrs2 = pd.merge(dffrs1,dfis, on=['STOCK_TIKR','year'])\n",
    "dffrs = pd.merge(dffrs2,dfsp, on=['STOCK_TIKR'])\n",
    "\n",
    "dffrs.head()\n",
    "dffrs2.shape[0]\n",
    "dffrs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting avg. daily returns of each stock from dataset and calculating annual return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://nativeuser:password@localhost/automatic_portfolio_creation')\n",
    "queryhp = \"SELECT * from hist_annual_return\"\n",
    "\n",
    "dfhp =pd.read_sql(queryhp,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas import ExcelWriter\n",
    "# writer = ExcelWriter('DailyRet.xlsx')\n",
    "# dftemp1.to_excel(writer,'Sheet1',index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "dfhp['ANNUAL_RETURN'] = (pow((dfhp.AVG_DAILY_RET)+1,365)-1)*100\n",
    "dfhp.rename(columns = {'YR_OF_DATE':'year'}, inplace = True)\n",
    "dfhp['year'] = pd.to_datetime(dfhp['year'], format='%Y')\n",
    "dfhp['year'] = pd.DatetimeIndex(dfhp['year']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>year</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2009</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-56.031098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.000957</td>\n",
       "      <td>-29.484219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>52.298213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2012</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>-15.501688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2013</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-36.212683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  year  AVG_DAILY_RET  ANNUAL_RETURN\n",
       "0          A  2009      -0.002249     -56.031098\n",
       "1          A  2010      -0.000957     -29.484219\n",
       "2          A  2011       0.001153      52.298213\n",
       "3          A  2012      -0.000461     -15.501688\n",
       "4          A  2013      -0.001231     -36.212683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(62017, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfhp.head()\n",
    "dfhp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging annual returns with our main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>FCF_MARGIN</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>10693000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>19388000.0</td>\n",
       "      <td>16420000.0</td>\n",
       "      <td>13349000.0</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-6.419519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37746000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44998000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>15785000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>13951000.0</td>\n",
       "      <td>11435000.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>-0.000467</td>\n",
       "      <td>-15.687095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112445000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120006000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92000000.0</td>\n",
       "      <td>26875000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0120</td>\n",
       "      <td>10660000.0</td>\n",
       "      <td>8056000.0</td>\n",
       "      <td>6309000.0</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-1.625754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21083000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27395000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>27807000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>9784000.0</td>\n",
       "      <td>8081000.0</td>\n",
       "      <td>35840000.0</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>31.945557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>35667000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>15216000.0</td>\n",
       "      <td>13746000.0</td>\n",
       "      <td>13420000.0</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>117.051032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "0       FNCB            36481000.0                    0.0   \n",
       "1       FNCB            37746000.0                    0.0   \n",
       "2       FNCB           112445000.0                    0.0   \n",
       "3       FNCB            21083000.0                    0.0   \n",
       "4       FNCB            35667000.0                    NaN   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "0             36481000.0          0.0          0.0            43734000.0   \n",
       "1             37746000.0          0.0          0.0            44998000.0   \n",
       "2            112445000.0          0.0          0.0           120006000.0   \n",
       "3             21083000.0          0.0          0.0            27395000.0   \n",
       "4                    NaN          0.0          0.0                   NaN   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  \\\n",
       "0                         0.0             11000000.0  10693000.0   \n",
       "1                         0.0             16000000.0  15785000.0   \n",
       "2                         0.0             92000000.0  26875000.0   \n",
       "3                         0.0              2000000.0  27807000.0   \n",
       "4                    302000.0                    NaN         0.0   \n",
       "\n",
       "       ...        FCF_MARGIN      EBITDA        EBIT  CONSOLIDATED_INCOME  \\\n",
       "0      ...            0.3746  19388000.0  16420000.0           13349000.0   \n",
       "1      ...            0.2702  13951000.0  11435000.0             147000.0   \n",
       "2      ...           -0.0120  10660000.0   8056000.0            6309000.0   \n",
       "3      ...            0.0832   9784000.0   8081000.0           35840000.0   \n",
       "4      ...            0.2071  15216000.0  13746000.0           13420000.0   \n",
       "\n",
       "   EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN              sector  \\\n",
       "0                  0.3589             0.2918  Financial Services   \n",
       "1                  0.2895             0.0037  Financial Services   \n",
       "2                  0.2263             0.1772  Financial Services   \n",
       "3                  0.2211             0.9807  Financial Services   \n",
       "4                  0.2905             0.2836  Financial Services   \n",
       "\n",
       "         mktCap  AVG_DAILY_RET  ANNUAL_RETURN  \n",
       "0  136743892.56      -0.000182      -6.419519  \n",
       "1  136743892.56      -0.000467     -15.687095  \n",
       "2  136743892.56      -0.000045      -1.625754  \n",
       "3  136743892.56       0.000760      31.945557  \n",
       "4  136743892.56       0.002125     117.051032  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37965"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge = pd.merge(dffrs,dfhp, on=['STOCK_TIKR','year'])\n",
    "dfmerge = dfmerge.drop_duplicates(subset=['STOCK_TIKR', 'year'],keep='first')\n",
    "dfmerge.head()\n",
    "dfmerge.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge.to_csv('X_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing S&P 500 annual returns for period of 2009-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANN_RET_SnP</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.88</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.91</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-28.48</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-47.07</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.15</td>\n",
       "      <td>1932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANN_RET_SnP  year\n",
       "0        37.88  1928\n",
       "1       -11.91  1929\n",
       "2       -28.48  1930\n",
       "3       -47.07  1931\n",
       "4       -15.15  1932"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspret = pd.read_csv('sp-500-annual-returns.csv')\n",
    "dfspret['year'] = pd.DatetimeIndex(dfspret['date']).year\n",
    "dfspret.rename(columns = {'returns':'ANN_RET_SnP'}, inplace = True)\n",
    "del dfspret['date']\n",
    "dfspret.ANN_RET_SnP.dtype\n",
    "dfspret.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on annual return and S&P500 returns, we are calculating trend of a stock. If stock return is positive and greater than S&P we are marking as UP or else marking as Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "      <th>ANN_RET_SnP</th>\n",
       "      <th>TREND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FNCB</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36481000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43734000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000000.0</td>\n",
       "      <td>10693000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16420000.0</td>\n",
       "      <td>13349000.0</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>136743892.56</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-6.419519</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORD</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>9024518.0</td>\n",
       "      <td>1568914.0</td>\n",
       "      <td>15211732.0</td>\n",
       "      <td>3593609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>747767.0</td>\n",
       "      <td>1379320.0</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>9310993.35</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>118.223442</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORK</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>27760956.0</td>\n",
       "      <td>22274613.0</td>\n",
       "      <td>59520379.0</td>\n",
       "      <td>8157916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12758662.0</td>\n",
       "      <td>9758959.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>39612958.05</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>35.038547</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORTY</td>\n",
       "      <td>268492000.0</td>\n",
       "      <td>26794000.0</td>\n",
       "      <td>295286000.0</td>\n",
       "      <td>441468000.0</td>\n",
       "      <td>3882000.0</td>\n",
       "      <td>781033000.0</td>\n",
       "      <td>790901000.0</td>\n",
       "      <td>25710000.0</td>\n",
       "      <td>14214000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56666000.0</td>\n",
       "      <td>77395000.0</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>Technology</td>\n",
       "      <td>969517079.96</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>40.430389</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FPAY</td>\n",
       "      <td>6141210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6141210.0</td>\n",
       "      <td>6375963.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45199030.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5304838.0</td>\n",
       "      <td>-9461262.0</td>\n",
       "      <td>-0.1117</td>\n",
       "      <td>-0.1117</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>13719310.40</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>2003.110827</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "0       FNCB            36481000.0                    0.0   \n",
       "1       FORD             4369866.0                    0.0   \n",
       "2       FORK             6797395.0                    0.0   \n",
       "3      FORTY           268492000.0             26794000.0   \n",
       "4       FPAY             6141210.0                    0.0   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "0             36481000.0          0.0          0.0            43734000.0   \n",
       "1              4369866.0    9024518.0    1568914.0            15211732.0   \n",
       "2              6797395.0   27760956.0   22274613.0            59520379.0   \n",
       "3            295286000.0  441468000.0    3882000.0           781033000.0   \n",
       "4              6141210.0    6375963.0          0.0            45199030.0   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  ...    \\\n",
       "0                         0.0             11000000.0  10693000.0  ...     \n",
       "1                   3593609.0                    0.0         0.0  ...     \n",
       "2                   8157916.0                    0.0         0.0  ...     \n",
       "3                 790901000.0             25710000.0  14214000.0  ...     \n",
       "4                         0.0                    0.0         0.0  ...     \n",
       "\n",
       "         EBIT  CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  \\\n",
       "0  16420000.0           13349000.0                  0.3589             0.2918   \n",
       "1    747767.0            1379320.0                  0.0183             0.0400   \n",
       "2  12758662.0            9758959.0                  0.0793             0.0711   \n",
       "3  56666000.0           77395000.0                  0.0380             0.0217   \n",
       "4  -5304838.0           -9461262.0                 -0.1117            -0.1117   \n",
       "\n",
       "               sector        mktCap  AVG_DAILY_RET  ANNUAL_RETURN  \\\n",
       "0  Financial Services  136743892.56      -0.000182      -6.419519   \n",
       "1   Consumer Cyclical    9310993.35       0.002140     118.223442   \n",
       "2   Consumer Cyclical   39612958.05       0.000823      35.038547   \n",
       "3          Technology  969517079.96       0.000931      40.430389   \n",
       "4  Financial Services   13719310.40       0.008380    2003.110827   \n",
       "\n",
       "   ANN_RET_SnP  TREND  \n",
       "0        -6.24   Down  \n",
       "1        -6.24     Up  \n",
       "2        -6.24     Up  \n",
       "3        -6.24     Up  \n",
       "4        -6.24     Up  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(37965, 82)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge1 = pd.merge(dfmerge,dfspret, on='year')\n",
    "#dfmerge1.to_csv('dfm.csv')\n",
    "dfmerge1['TREND'] = np.where(((dfmerge1['ANNUAL_RETURN'] > dfmerge1['ANN_RET_SnP'])&(dfmerge1['ANNUAL_RETURN']>0)) ,'Up','Down')\n",
    "dfmerge1.head()\n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are not considering the financial sector as its financial parameters are convey different meanings than usual. We are taking care of this so avoid mis-train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmerge1.drop('Working_Capital',inplace=True)\n",
    "# Delete these row indexes from dataFrame\n",
    "indexNames = dfmerge1[ dfmerge1['sector'] == 'Financial Services' ].index\n",
    "dfmerge1.drop(indexNames , inplace=True)\n",
    "#dfmerge1.to_csv('ML_data.csv')\n",
    "dfmerge1.sector = pd.Categorical(dfmerge1.sector)\n",
    "dfmerge1.sector = dfmerge1.sector.cat.codes\n",
    "#dfepsPer['POSITIVE'] = dfepsPer['POSITIVE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "      <th>ANN_RET_SnP</th>\n",
       "      <th>TREND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORD</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>9024518.0</td>\n",
       "      <td>1568914.0</td>\n",
       "      <td>15211732.0</td>\n",
       "      <td>3593609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>747767.0</td>\n",
       "      <td>1379320.0</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>3</td>\n",
       "      <td>9310993.35</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>118.223442</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORK</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>27760956.0</td>\n",
       "      <td>22274613.0</td>\n",
       "      <td>59520379.0</td>\n",
       "      <td>8157916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12758662.0</td>\n",
       "      <td>9758959.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>3</td>\n",
       "      <td>39612958.05</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>35.038547</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORTY</td>\n",
       "      <td>268492000.0</td>\n",
       "      <td>26794000.0</td>\n",
       "      <td>295286000.0</td>\n",
       "      <td>441468000.0</td>\n",
       "      <td>3882000.0</td>\n",
       "      <td>781033000.0</td>\n",
       "      <td>790901000.0</td>\n",
       "      <td>25710000.0</td>\n",
       "      <td>14214000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56666000.0</td>\n",
       "      <td>77395000.0</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>9</td>\n",
       "      <td>969517079.96</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>40.430389</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRD</td>\n",
       "      <td>4052582.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4052582.0</td>\n",
       "      <td>17458289.0</td>\n",
       "      <td>45329434.0</td>\n",
       "      <td>67269406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5792434.0</td>\n",
       "      <td>3934101.0</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>1</td>\n",
       "      <td>41570877.38</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-11.665443</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FSI</td>\n",
       "      <td>7857936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7857936.0</td>\n",
       "      <td>4422745.0</td>\n",
       "      <td>8727709.0</td>\n",
       "      <td>21208696.0</td>\n",
       "      <td>5725289.0</td>\n",
       "      <td>807134.0</td>\n",
       "      <td>891735.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3217051.0</td>\n",
       "      <td>2421717.0</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>1</td>\n",
       "      <td>28726435.92</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>88.002405</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "1       FORD             4369866.0                    0.0   \n",
       "2       FORK             6797395.0                    0.0   \n",
       "3      FORTY           268492000.0             26794000.0   \n",
       "5        FRD             4052582.0                    0.0   \n",
       "9        FSI             7857936.0                    0.0   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "1              4369866.0    9024518.0    1568914.0            15211732.0   \n",
       "2              6797395.0   27760956.0   22274613.0            59520379.0   \n",
       "3            295286000.0  441468000.0    3882000.0           781033000.0   \n",
       "5              4052582.0   17458289.0   45329434.0            67269406.0   \n",
       "9              7857936.0    4422745.0    8727709.0            21208696.0   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  ...    \\\n",
       "1                   3593609.0                    0.0         0.0  ...     \n",
       "2                   8157916.0                    0.0         0.0  ...     \n",
       "3                 790901000.0             25710000.0  14214000.0  ...     \n",
       "5                         0.0                    0.0         0.0  ...     \n",
       "9                   5725289.0               807134.0    891735.0  ...     \n",
       "\n",
       "         EBIT  CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  \\\n",
       "1    747767.0            1379320.0                  0.0183             0.0400   \n",
       "2  12758662.0            9758959.0                  0.0793             0.0711   \n",
       "3  56666000.0           77395000.0                  0.0380             0.0217   \n",
       "5   5792434.0            3934101.0                  0.0476             0.0325   \n",
       "9   3217051.0            2421717.0                  0.1752             0.1397   \n",
       "\n",
       "   sector        mktCap  AVG_DAILY_RET  ANNUAL_RETURN  ANN_RET_SnP  TREND  \n",
       "1       3    9310993.35       0.002140     118.223442        -6.24     Up  \n",
       "2       3   39612958.05       0.000823      35.038547        -6.24     Up  \n",
       "3       9  969517079.96       0.000931      40.430389        -6.24     Up  \n",
       "5       1   41570877.38      -0.000340     -11.665443        -6.24   Down  \n",
       "9       1   28726435.92       0.001731      88.002405        -6.24     Up  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have total 31167 rows in our final dataframe\n"
     ]
    }
   ],
   "source": [
    "dfmerge1.head()\n",
    "print('We have total',dfmerge1.shape[0],'rows in our final dataframe')\n",
    "#dfmerge1.to_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With below code, we are getting rid of Null/nan data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOCK_TIKR                         0\n",
      "CASH_CASH_EQUIVALENT              16\n",
      "SHORT_TERM_INVESTMNET           2434\n",
      "CASH_SHORT_TERM_INVST           2388\n",
      "RECEIVABLES                      171\n",
      "INVENTORIES                      700\n",
      "TOTAL_CURRENT_ASSETS            1406\n",
      "GOODWILL_INTANGIBLE_ASSETS        94\n",
      "LONG_TERM_INVESTMENTS           2192\n",
      "TAX_ASSETS                      1014\n",
      "TOTAL_NON_CURR_ASSETS           2635\n",
      "TOTAL_ASSETS                       0\n",
      "PAYABLES                         249\n",
      "SHORT_TERM_DEBT                 1875\n",
      "TOTAL_CURR_LIABILITIES          1365\n",
      "LONG_TERM_DEBT                  1569\n",
      "TOTAL_DEBT                       618\n",
      "DEFERRED_REVENUE                1045\n",
      "TAX_LIABILITIES                 1021\n",
      "DEPOSIT_LIABILITIES             1955\n",
      "TOTAL_NON_CURR_LIABILITIES      2657\n",
      "TOTAL_LIABILITIES                  6\n",
      "OTHER_COMPREHENSIVE_INCOME       589\n",
      "RETAINED_EARNINGS_DEFICIT        669\n",
      "TOTAL_SHAREHOLDERS_EQUITY         15\n",
      "INVESTMENTS                     1081\n",
      "NET_DEBT                        5631\n",
      "OTHER_ASSETS                    5514\n",
      "OTHER_LIABILITIES               1298\n",
      "year                               0\n",
      "                                ... \n",
      "OPERATING_INCOME                 275\n",
      "INTEREST_EXPENSE                 540\n",
      "EARNINGS_BEFORE_TAX              850\n",
      "INCOME_TAX_EXPENSE               552\n",
      "NET_INC_NON_CONTROLLING_INT     1937\n",
      "NET_INC_DISCONTINUED_OPS        1937\n",
      "NET_INCOME                       416\n",
      "PREFERRED_DIVIDENDS             1937\n",
      "NET_INCOME_COM                   281\n",
      "EPS                              569\n",
      "EPS_DILUTED                      582\n",
      "WEIGHTED_AVERAGE_SHS_OUT        1067\n",
      "WEIGHTED_AVERAGE_SHS_OUT_DIL     639\n",
      "DIVIDEND_PER_SHARE              1935\n",
      "GROSS_MARGIN                     502\n",
      "EBITDA_MARGIN                   1616\n",
      "EBIT_MARGIN                      600\n",
      "PROFIT_MARGIN                   1612\n",
      "FCF_MARGIN                      2161\n",
      "EBITDA                           482\n",
      "EBIT                              96\n",
      "CONSOLIDATED_INCOME              425\n",
      "EARNINGS_BEFORE_MARGIN           502\n",
      "NET_PROFIT_MARGIN                652\n",
      "sector                             0\n",
      "mktCap                             0\n",
      "AVG_DAILY_RET                      8\n",
      "ANNUAL_RETURN                      8\n",
      "ANN_RET_SnP                        0\n",
      "TREND                              0\n",
      "Length: 82, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfmerge1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31167, 82)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge1 = dfmerge1.fillna(0) \n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# printing the rows that have Nans\")\n",
    "# print(\"=======================================================================================\")\n",
    "# print(dfmerge[dfmerge.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmerge[dfmerge['Average_Inventory'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rechecking with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOCK_TIKR                      0\n",
      "CASH_CASH_EQUIVALENT            0\n",
      "SHORT_TERM_INVESTMNET           0\n",
      "CASH_SHORT_TERM_INVST           0\n",
      "RECEIVABLES                     0\n",
      "INVENTORIES                     0\n",
      "TOTAL_CURRENT_ASSETS            0\n",
      "GOODWILL_INTANGIBLE_ASSETS      0\n",
      "LONG_TERM_INVESTMENTS           0\n",
      "TAX_ASSETS                      0\n",
      "TOTAL_NON_CURR_ASSETS           0\n",
      "TOTAL_ASSETS                    0\n",
      "PAYABLES                        0\n",
      "SHORT_TERM_DEBT                 0\n",
      "TOTAL_CURR_LIABILITIES          0\n",
      "LONG_TERM_DEBT                  0\n",
      "TOTAL_DEBT                      0\n",
      "DEFERRED_REVENUE                0\n",
      "TAX_LIABILITIES                 0\n",
      "DEPOSIT_LIABILITIES             0\n",
      "TOTAL_NON_CURR_LIABILITIES      0\n",
      "TOTAL_LIABILITIES               0\n",
      "OTHER_COMPREHENSIVE_INCOME      0\n",
      "RETAINED_EARNINGS_DEFICIT       0\n",
      "TOTAL_SHAREHOLDERS_EQUITY       0\n",
      "INVESTMENTS                     0\n",
      "NET_DEBT                        0\n",
      "OTHER_ASSETS                    0\n",
      "OTHER_LIABILITIES               0\n",
      "year                            0\n",
      "                               ..\n",
      "OPERATING_INCOME                0\n",
      "INTEREST_EXPENSE                0\n",
      "EARNINGS_BEFORE_TAX             0\n",
      "INCOME_TAX_EXPENSE              0\n",
      "NET_INC_NON_CONTROLLING_INT     0\n",
      "NET_INC_DISCONTINUED_OPS        0\n",
      "NET_INCOME                      0\n",
      "PREFERRED_DIVIDENDS             0\n",
      "NET_INCOME_COM                  0\n",
      "EPS                             0\n",
      "EPS_DILUTED                     0\n",
      "WEIGHTED_AVERAGE_SHS_OUT        0\n",
      "WEIGHTED_AVERAGE_SHS_OUT_DIL    0\n",
      "DIVIDEND_PER_SHARE              0\n",
      "GROSS_MARGIN                    0\n",
      "EBITDA_MARGIN                   0\n",
      "EBIT_MARGIN                     0\n",
      "PROFIT_MARGIN                   0\n",
      "FCF_MARGIN                      0\n",
      "EBITDA                          0\n",
      "EBIT                            0\n",
      "CONSOLIDATED_INCOME             0\n",
      "EARNINGS_BEFORE_MARGIN          0\n",
      "NET_PROFIT_MARGIN               0\n",
      "sector                          0\n",
      "mktCap                          0\n",
      "AVG_DAILY_RET                   0\n",
      "ANNUAL_RETURN                   0\n",
      "ANN_RET_SnP                     0\n",
      "TREND                           0\n",
      "Length: 82, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31167, 82)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfmerge1.isnull().sum())\n",
    "dfmerge1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend is our Y column, converting into categorical as few ML models don't accept string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>TAX_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "      <th>ANN_RET_SnP</th>\n",
       "      <th>TREND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORD</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4369866.0</td>\n",
       "      <td>9024518.0</td>\n",
       "      <td>1568914.0</td>\n",
       "      <td>15211732.0</td>\n",
       "      <td>3593609.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>747767.0</td>\n",
       "      <td>1379320.0</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>3</td>\n",
       "      <td>9310993.35</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>118.223442</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FORK</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6797395.0</td>\n",
       "      <td>27760956.0</td>\n",
       "      <td>22274613.0</td>\n",
       "      <td>59520379.0</td>\n",
       "      <td>8157916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12758662.0</td>\n",
       "      <td>9758959.0</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>3</td>\n",
       "      <td>39612958.05</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>35.038547</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FORTY</td>\n",
       "      <td>268492000.0</td>\n",
       "      <td>26794000.0</td>\n",
       "      <td>295286000.0</td>\n",
       "      <td>441468000.0</td>\n",
       "      <td>3882000.0</td>\n",
       "      <td>781033000.0</td>\n",
       "      <td>790901000.0</td>\n",
       "      <td>25710000.0</td>\n",
       "      <td>14214000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56666000.0</td>\n",
       "      <td>77395000.0</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>9</td>\n",
       "      <td>969517079.96</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>40.430389</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FRD</td>\n",
       "      <td>4052582.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4052582.0</td>\n",
       "      <td>17458289.0</td>\n",
       "      <td>45329434.0</td>\n",
       "      <td>67269406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5792434.0</td>\n",
       "      <td>3934101.0</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>1</td>\n",
       "      <td>41570877.38</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-11.665443</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FSI</td>\n",
       "      <td>7857936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7857936.0</td>\n",
       "      <td>4422745.0</td>\n",
       "      <td>8727709.0</td>\n",
       "      <td>21208696.0</td>\n",
       "      <td>5725289.0</td>\n",
       "      <td>807134.0</td>\n",
       "      <td>891735.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3217051.0</td>\n",
       "      <td>2421717.0</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>1</td>\n",
       "      <td>28726435.92</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>88.002405</td>\n",
       "      <td>-6.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STOCK_TIKR  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "1       FORD             4369866.0                    0.0   \n",
       "2       FORK             6797395.0                    0.0   \n",
       "3      FORTY           268492000.0             26794000.0   \n",
       "5        FRD             4052582.0                    0.0   \n",
       "9        FSI             7857936.0                    0.0   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "1              4369866.0    9024518.0    1568914.0            15211732.0   \n",
       "2              6797395.0   27760956.0   22274613.0            59520379.0   \n",
       "3            295286000.0  441468000.0    3882000.0           781033000.0   \n",
       "5              4052582.0   17458289.0   45329434.0            67269406.0   \n",
       "9              7857936.0    4422745.0    8727709.0            21208696.0   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS  TAX_ASSETS  ...    \\\n",
       "1                   3593609.0                    0.0         0.0  ...     \n",
       "2                   8157916.0                    0.0         0.0  ...     \n",
       "3                 790901000.0             25710000.0  14214000.0  ...     \n",
       "5                         0.0                    0.0         0.0  ...     \n",
       "9                   5725289.0               807134.0    891735.0  ...     \n",
       "\n",
       "         EBIT  CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  \\\n",
       "1    747767.0            1379320.0                  0.0183             0.0400   \n",
       "2  12758662.0            9758959.0                  0.0793             0.0711   \n",
       "3  56666000.0           77395000.0                  0.0380             0.0217   \n",
       "5   5792434.0            3934101.0                  0.0476             0.0325   \n",
       "9   3217051.0            2421717.0                  0.1752             0.1397   \n",
       "\n",
       "   sector        mktCap  AVG_DAILY_RET  ANNUAL_RETURN  ANN_RET_SnP  TREND  \n",
       "1       3    9310993.35       0.002140     118.223442        -6.24      1  \n",
       "2       3   39612958.05       0.000823      35.038547        -6.24      1  \n",
       "3       9  969517079.96       0.000931      40.430389        -6.24      1  \n",
       "5       1   41570877.38      -0.000340     -11.665443        -6.24      0  \n",
       "9       1   28726435.92       0.001731      88.002405        -6.24      1  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge1.TREND = pd.Categorical(dfmerge1.TREND)\n",
    "dfmerge1['TREND'] = dfmerge1.TREND.cat.codes\n",
    "dfmerge1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether our data is balanced or imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16046\n",
       "1    15121\n",
       "Name: TREND, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge1['TREND'].value_counts()\n",
    "#dfmerge.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, ourr distribution of Y or Trend is almost equally devided betwwen up and down trend. So we have a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmerge1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmerge['STOCK_TIKR'] = pd.Categorical(dfmerge.STOCK_TIKR)\n",
    "# dfmerge['STOCK_CAT'] = dfmerge.STOCK_TIKR.cat.codes\n",
    "# dfmerge.head()\n",
    "# dfmerge.to_csv('ML_Dataframe_Final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding soft recession and treasury rates for 10 years in our features or X to check the influence on trent or Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = pd.read_csv('Soft_Recession.csv')\n",
    "#dfres.head()\n",
    "dfres['year'] = pd.DatetimeIndex(dfres['DATE']).year\n",
    "del dfres['DATE'] \n",
    "dfres.rename(columns = {'RECPROUSM156N':'recession_prob'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = pd.read_csv('treasury_rates.csv')\n",
    "#dftr.head()\n",
    "dftr['DATE'] = pd.to_datetime(dftr['DATE'], format='%m/%d/%Y')\n",
    "dftr['year'] = pd.DatetimeIndex(dftr['DATE']).year\n",
    "del dftr['DATE'] \n",
    "dftr.rename(columns = {'DGS10':'treasury_rate'}, inplace = True)\n",
    "#dftr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of all null values from treasury and recession prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recession_prob    0\n",
      "year              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treasury_rate    115\n",
      "year             115\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2850, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfres.isnull().sum())\n",
    "dfres.shape\n",
    "print(dftr.isnull().sum())\n",
    "dftr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recession_prob    0\n",
      "year              0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treasury_rate    0\n",
      "year             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2850, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr.fillna(method='ffill',inplace=True)\n",
    "\n",
    "print(dfres.isnull().sum())\n",
    "dfres.shape\n",
    "print(dftr.isnull().sum())\n",
    "dftr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group all the data based on year and merge these two parameters in our main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>recession_prob</th>\n",
       "      <th>treasury_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>3.266284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>3.210769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>2.774061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>1.801111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.378333</td>\n",
       "      <td>2.355709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  recession_prob  treasury_rate\n",
       "0  2009        0.120000       3.266284\n",
       "1  2010        0.078333       3.210769\n",
       "2  2011        0.113333       2.774061\n",
       "3  2012        0.110000       1.801111\n",
       "4  2013        0.378333       2.355709"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfres = dfres.groupby(['year']).mean().reset_index()\n",
    "#dfres.head()\n",
    "dftr = dftr.groupby(['year']).mean().reset_index()\n",
    "#dftr.head()\n",
    "dftemp = pd.merge(dfres,dftr,on='year')\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>recession_prob</th>\n",
       "      <th>treasury_rate</th>\n",
       "      <th>STOCK_TIKR</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "      <th>mktCap</th>\n",
       "      <th>AVG_DAILY_RET</th>\n",
       "      <th>ANNUAL_RETURN</th>\n",
       "      <th>ANN_RET_SnP</th>\n",
       "      <th>TREND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>FORD</td>\n",
       "      <td>20103502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20103502.0</td>\n",
       "      <td>3259462.0</td>\n",
       "      <td>666485.0</td>\n",
       "      <td>222000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1093626.0</td>\n",
       "      <td>-1394125.0</td>\n",
       "      <td>-0.0627</td>\n",
       "      <td>-0.0799</td>\n",
       "      <td>3</td>\n",
       "      <td>9310993.35</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>35.135072</td>\n",
       "      <td>23.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>FORTY</td>\n",
       "      <td>100205000.0</td>\n",
       "      <td>58009000.0</td>\n",
       "      <td>158214000.0</td>\n",
       "      <td>130237000.0</td>\n",
       "      <td>2439000.0</td>\n",
       "      <td>313365000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27612000.0</td>\n",
       "      <td>33030000.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>9</td>\n",
       "      <td>969517079.96</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-21.979784</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>FSI</td>\n",
       "      <td>2126150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2126150.0</td>\n",
       "      <td>1544364.0</td>\n",
       "      <td>2796307.0</td>\n",
       "      <td>6588174.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-163390.0</td>\n",
       "      <td>-743441.0</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>-0.0760</td>\n",
       "      <td>1</td>\n",
       "      <td>28726435.92</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>105.361674</td>\n",
       "      <td>23.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>FTFT</td>\n",
       "      <td>14404500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14404500.0</td>\n",
       "      <td>27621753.0</td>\n",
       "      <td>4925625.0</td>\n",
       "      <td>48487920.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22032207.0</td>\n",
       "      <td>16404600.0</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>4</td>\n",
       "      <td>11250795.92</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>58.592164</td>\n",
       "      <td>23.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>GBR</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>925000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2087000.0</td>\n",
       "      <td>-2210000.0</td>\n",
       "      <td>-0.5393</td>\n",
       "      <td>-0.5393</td>\n",
       "      <td>5</td>\n",
       "      <td>3324780.00</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>13.400058</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  recession_prob  treasury_rate STOCK_TIKR  CASH_CASH_EQUIVALENT  \\\n",
       "0  2009            0.12       3.266284       FORD            20103502.0   \n",
       "1  2009            0.12       3.266284      FORTY           100205000.0   \n",
       "2  2009            0.12       3.266284        FSI             2126150.0   \n",
       "3  2009            0.12       3.266284       FTFT            14404500.0   \n",
       "4  2009            0.12       3.266284        GBR              155000.0   \n",
       "\n",
       "   SHORT_TERM_INVESTMNET  CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  \\\n",
       "0                    0.0             20103502.0    3259462.0     666485.0   \n",
       "1             58009000.0            158214000.0  130237000.0    2439000.0   \n",
       "2                    0.0              2126150.0    1544364.0    2796307.0   \n",
       "3                    0.0             14404500.0   27621753.0    4925625.0   \n",
       "4                    0.0               155000.0     203000.0          0.0   \n",
       "\n",
       "   TOTAL_CURRENT_ASSETS  ...          EBIT  CONSOLIDATED_INCOME  \\\n",
       "0              222000.0  ...    -1093626.0           -1394125.0   \n",
       "1           313365000.0  ...    27612000.0           33030000.0   \n",
       "2             6588174.0  ...     -163390.0            -743441.0   \n",
       "3            48487920.0  ...    22032207.0           16404600.0   \n",
       "4              925000.0  ...    -2087000.0           -2210000.0   \n",
       "\n",
       "   EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  sector        mktCap  \\\n",
       "0                 -0.0627            -0.0799       3    9310993.35   \n",
       "1                  0.0583             0.0406       9  969517079.96   \n",
       "2                 -0.0235            -0.0760       1   28726435.92   \n",
       "3                  0.3581             0.2564       4   11250795.92   \n",
       "4                 -0.5393            -0.5393       5    3324780.00   \n",
       "\n",
       "   AVG_DAILY_RET  ANNUAL_RETURN  ANN_RET_SnP  TREND  \n",
       "0       0.000825      35.135072        23.45      1  \n",
       "1      -0.000680     -21.979784        23.45      0  \n",
       "2       0.001973     105.361674        23.45      1  \n",
       "3       0.001264      58.592164        23.45      1  \n",
       "4       0.000345      13.400058        23.45      0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "31167"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmerge_param = pd.merge(dftemp,dfmerge1, on='year')\n",
    "dfmerge_param.head()\n",
    "dfmerge_param.shape[0]\n",
    "#dfmerge_param1.to_csv('merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data in train and test dataset. Remove unwanted features/parameter from X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recession_prob</th>\n",
       "      <th>treasury_rate</th>\n",
       "      <th>CASH_CASH_EQUIVALENT</th>\n",
       "      <th>SHORT_TERM_INVESTMNET</th>\n",
       "      <th>CASH_SHORT_TERM_INVST</th>\n",
       "      <th>RECEIVABLES</th>\n",
       "      <th>INVENTORIES</th>\n",
       "      <th>TOTAL_CURRENT_ASSETS</th>\n",
       "      <th>GOODWILL_INTANGIBLE_ASSETS</th>\n",
       "      <th>LONG_TERM_INVESTMENTS</th>\n",
       "      <th>...</th>\n",
       "      <th>EBITDA_MARGIN</th>\n",
       "      <th>EBIT_MARGIN</th>\n",
       "      <th>PROFIT_MARGIN</th>\n",
       "      <th>FCF_MARGIN</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <th>EARNINGS_BEFORE_MARGIN</th>\n",
       "      <th>NET_PROFIT_MARGIN</th>\n",
       "      <th>sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>20103502.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20103502.0</td>\n",
       "      <td>3259462.0</td>\n",
       "      <td>666485.0</td>\n",
       "      <td>222000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.0627</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>-1018041.0</td>\n",
       "      <td>-1093626.0</td>\n",
       "      <td>-1394125.0</td>\n",
       "      <td>-0.0627</td>\n",
       "      <td>-0.0799</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>100205000.0</td>\n",
       "      <td>58009000.0</td>\n",
       "      <td>158214000.0</td>\n",
       "      <td>130237000.0</td>\n",
       "      <td>2439000.0</td>\n",
       "      <td>313365000.0</td>\n",
       "      <td>174941000.0</td>\n",
       "      <td>11091000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>42217000.0</td>\n",
       "      <td>27612000.0</td>\n",
       "      <td>33030000.0</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>2126150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2126150.0</td>\n",
       "      <td>1544364.0</td>\n",
       "      <td>2796307.0</td>\n",
       "      <td>6588174.0</td>\n",
       "      <td>224505.0</td>\n",
       "      <td>7499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.076</td>\n",
       "      <td>-0.0498</td>\n",
       "      <td>238725.0</td>\n",
       "      <td>-163390.0</td>\n",
       "      <td>-743441.0</td>\n",
       "      <td>-0.0235</td>\n",
       "      <td>-0.0760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>14404500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14404500.0</td>\n",
       "      <td>27621753.0</td>\n",
       "      <td>4925625.0</td>\n",
       "      <td>48487920.0</td>\n",
       "      <td>6577834.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>24044419.0</td>\n",
       "      <td>22032207.0</td>\n",
       "      <td>16404600.0</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.12</td>\n",
       "      <td>3.266284</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>203000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>925000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11206000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-0.5093</td>\n",
       "      <td>-0.539</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>-1728000.0</td>\n",
       "      <td>-2087000.0</td>\n",
       "      <td>-2210000.0</td>\n",
       "      <td>-0.5393</td>\n",
       "      <td>-0.5393</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recession_prob  treasury_rate  CASH_CASH_EQUIVALENT  SHORT_TERM_INVESTMNET  \\\n",
       "0            0.12       3.266284            20103502.0                    0.0   \n",
       "1            0.12       3.266284           100205000.0             58009000.0   \n",
       "2            0.12       3.266284             2126150.0                    0.0   \n",
       "3            0.12       3.266284            14404500.0                    0.0   \n",
       "4            0.12       3.266284              155000.0                    0.0   \n",
       "\n",
       "   CASH_SHORT_TERM_INVST  RECEIVABLES  INVENTORIES  TOTAL_CURRENT_ASSETS  \\\n",
       "0             20103502.0    3259462.0     666485.0              222000.0   \n",
       "1            158214000.0  130237000.0    2439000.0           313365000.0   \n",
       "2              2126150.0    1544364.0    2796307.0             6588174.0   \n",
       "3             14404500.0   27621753.0    4925625.0            48487920.0   \n",
       "4               155000.0     203000.0          0.0              925000.0   \n",
       "\n",
       "   GOODWILL_INTANGIBLE_ASSETS  LONG_TERM_INVESTMENTS   ...    EBITDA_MARGIN  \\\n",
       "0                         0.0                    0.0   ...           -0.058   \n",
       "1                 174941000.0             11091000.0   ...            0.090   \n",
       "2                    224505.0                 7499.0   ...            0.024   \n",
       "3                   6577834.0                    0.0   ...            0.406   \n",
       "4                         0.0             11206000.0   ...           -0.422   \n",
       "\n",
       "   EBIT_MARGIN  PROFIT_MARGIN  FCF_MARGIN      EBITDA        EBIT  \\\n",
       "0      -0.0627         -0.080      0.0130  -1018041.0  -1093626.0   \n",
       "1       0.0588          0.041      0.1100  42217000.0  27612000.0   \n",
       "2      -0.0167         -0.076     -0.0498    238725.0   -163390.0   \n",
       "3       0.3719          0.256      0.0487  24044419.0  22032207.0   \n",
       "4      -0.5093         -0.539      0.0695  -1728000.0  -2087000.0   \n",
       "\n",
       "   CONSOLIDATED_INCOME  EARNINGS_BEFORE_MARGIN  NET_PROFIT_MARGIN  sector  \n",
       "0           -1394125.0                 -0.0627            -0.0799       3  \n",
       "1           33030000.0                  0.0583             0.0406       9  \n",
       "2            -743441.0                 -0.0235            -0.0760       1  \n",
       "3           16404600.0                  0.3581             0.2564       4  \n",
       "4           -2210000.0                 -0.5393            -0.5393       5  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "31162    1\n",
       "31163    0\n",
       "31164    0\n",
       "31165    0\n",
       "31166    0\n",
       "Name: TREND, dtype: int8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#dfmerge.info()\n",
    "X = dfmerge_param.drop(['STOCK_TIKR','year','AVG_DAILY_RET', 'ANNUAL_RETURN', 'ANN_RET_SnP', 'TREND','mktCap'],axis=1) #features\n",
    "Y = dfmerge_param['TREND'] #target\n",
    "X.head()\n",
    "Y.tail()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are running different classification models on our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "modelDtree = dtree.fit(X_train,Y_train)\n",
    "pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "acc_decision_tree = round(dtree.score(X_train,Y_train)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "modelSGD = sgd.fit(X_train, Y_train)\n",
    "pred_sgd = sgd.predict(X_test)\n",
    "\n",
    "acc_sgd = round(sgd.score(X_train,Y_train) *100,2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(classification_report(Y_test,predictions))\n",
    "# print(confusion_matrix(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression()\n",
    "modelLog = log.fit(X_train,Y_train)\n",
    "pred_log = log.predict(X_test)\n",
    "\n",
    "acc_log = round(log.score(X_train,Y_train)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "model_rfc = rfc.fit(X_train, Y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "acc_random_forest = round(rfc.score(X_train,Y_train)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "model_knn = knn.fit(X_train, Y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "model_gaussian = gaussian.fit(X_train, Y_train)\n",
    "gaussian_pred = gaussian.predict(X_test)  \n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(max_iter=5)\n",
    "model_perc = perceptron.fit(X_train, Y_train)\n",
    "perc_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the features or X for SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_tr = StandardScaler().fit(X_train)\n",
    "X_scaledtr = scaler_tr.transform(X_train)\n",
    "\n",
    "scaler_te = StandardScaler().fit(X_test)\n",
    "X_scaledte = scaler_te.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC,LinearSVC\n",
    "\n",
    "svclassifier = LinearSVC()\n",
    "model_svc = svclassifier.fit(X_scaledtr, Y_train)\n",
    "svc_pred = svclassifier.predict(X_scaledte)\n",
    "\n",
    "acc_svc = round(svclassifier.score(X_scaledtr, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgbclassifier = xgb.XGBClassifier(objective ='reg:logistic', learning_rate = 0.009,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, random_state=1)\n",
    "model_xgb = xgbclassifier.fit(X_scaledtr,Y_train)\n",
    "xgb_pred = xgbclassifier.predict(X_scaledte)\n",
    "\n",
    "acc_xgb = round(xgbclassifier.score(X_scaledtr, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compairing accuracy of all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.00</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.64</th>\n",
       "      <td>XGBooster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77.98</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.66</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53.73</th>\n",
       "      <td>Perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53.29</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52.60</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.55</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model\n",
       "Acc_Score                            \n",
       "100.00                  Random Forest\n",
       "100.00                  Decision Tree\n",
       "80.64                       XGBooster\n",
       "77.98                             KNN\n",
       "55.66         Support Vector Machines\n",
       "53.73                      Perceptron\n",
       "53.29             Logistic Regression\n",
       "52.60      Stochastic Gradient Decent\n",
       "48.55                     Naive Bayes"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', \n",
    "              'Decision Tree','XGBooster'],\n",
    "    'Acc_Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_decision_tree,acc_xgb]})\n",
    "result_df = results.sort_values(by='Acc_Score', ascending=False)\n",
    "result_df = result_df.set_index('Acc_Score')\n",
    "result_df\n",
    "result_df.to_csv('Accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that Random Forrest gives highest accuracy. But this 100% accuracy seems impractical. So we will run cross-validation method on Random forest to come up with the better validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.74243813 0.70348304 0.71952337 0.71264895 0.7263978  0.71035747\n",
      " 0.7172319  0.7042641  0.72673086 0.71880734]\n",
      "Mean: 0.7181882955836545\n",
      "Standard Deviation: 0.01110693509093855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(rf, X_train, Y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xb = xgb.XGBClassifier(n_estimators=100)\n",
    "scores = cross_val_score(xb, X_train, Y_train, cv=5, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Forrest we will also check the feature importance, to check which financial parameter impacting more on the stock trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>treasury_rate</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recession_prob</th>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NET_CASH_MARKET_CAP</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPS</th>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NET_CASH_FLOW</th>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBIT</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REVENUE_GROWTH</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPS_DILUTED</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPERATING_INCOME</th>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NET_INCOME_COM</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONSOLIDATED_INCOME</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FCF_MARGIN</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBIT_MARGIN</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREE_CASH_FLOW</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISSUANCE_SHARES_BUYBACKS</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROFIT_MARGIN</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBITDA_MARGIN</th>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          importance\n",
       "feature                             \n",
       "treasury_rate                  0.050\n",
       "recession_prob                 0.049\n",
       "NET_CASH_MARKET_CAP            0.022\n",
       "EPS                            0.021\n",
       "NET_CASH_FLOW                  0.021\n",
       "EBIT                           0.020\n",
       "REVENUE_GROWTH                 0.020\n",
       "EPS_DILUTED                    0.018\n",
       "OPERATING_INCOME               0.018\n",
       "NET_INCOME_COM                 0.017\n",
       "CONSOLIDATED_INCOME            0.016\n",
       "FCF_MARGIN                     0.016\n",
       "EBIT_MARGIN                    0.016\n",
       "FREE_CASH_FLOW                 0.016\n",
       "ISSUANCE_SHARES_BUYBACKS       0.016\n",
       "PROFIT_MARGIN                  0.015\n",
       "EBITDA_MARGIN                  0.015"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(rfc.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "importances.head(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2828b48d4a8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "importances.plot(kind='bar',figsize=(15,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run Random forrest model once again with detailed model parameters on our features/X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9918408507517419"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: 71.7 %\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       min_samples_leaf = 1, \n",
    "                                       min_samples_split = 10,   \n",
    "                                       n_estimators=100, \n",
    "                                       max_features='auto', \n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)\n",
    "\n",
    "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and other details are: 0.7229173350443803\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.75      0.74      4819\n",
      "          1       0.72      0.70      0.71      4532\n",
      "\n",
      "avg / total       0.72      0.72      0.72      9351\n",
      "\n",
      "\n",
      "\n",
      "confusion_matrix:\n",
      "[[3604 1215]\n",
      " [1376 3156]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "print('Accuracy and other details are:',accuracy_score(Y_test,Y_prediction))\n",
    "print('\\n')\n",
    "print(classification_report(Y_test,Y_prediction))\n",
    "print('\\n')\n",
    "print('confusion_matrix:')\n",
    "print(confusion_matrix(Y_test,Y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking performance with Xgbooster too as it gaves second highest accuracy in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgbclassifier = xgb.XGBClassifier(objective ='reg:logistic', learning_rate = 0.009,\n",
    "                max_depth = 10, alpha = 10, n_estimators = 50, random_state=1)\n",
    "model_xgb = xgbclassifier.fit(X_train,Y_train)\n",
    "xgb_pred = xgbclassifier.predict(X_test)\n",
    "\n",
    "acc_xgb = round(xgbclassifier.score(X_train, Y_train) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and other details are:\n",
      "0.7317933910811678\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.74      0.74      4819\n",
      "          1       0.73      0.72      0.72      4532\n",
      "\n",
      "avg / total       0.73      0.73      0.73      9351\n",
      "\n",
      "[[3586 1233]\n",
      " [1275 3257]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report,confusion_matrix, accuracy_score\n",
    "\n",
    "print('Accuracy and other details are:')\n",
    "print(accuracy_score(Y_test,xgb_pred))\n",
    "print(classification_report(Y_test,xgb_pred))\n",
    "print(confusion_matrix(Y_test,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997008942503605"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x288 with 0 Axes>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2828b6ff9b0>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7913292613619194"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2828b703a90>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2828b6fff98>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the Roc curve and calculate auc value\n",
    "from sklearn import metrics\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(Y_train, random_forest.predict_proba(X_train)[:,1])\n",
    "metrics.auc(fpr1, tpr1)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(fpr1, tpr1, label='train')\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(Y_test, random_forest.predict_proba(X_test)[:,1])\n",
    "metrics.auc(fpr2, tpr2) \n",
    "plt.plot(fpr2, tpr2, label='test', c='r')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x360 with 0 Axes>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# getting the probabilities of our predictions\n",
    "y_scores = random_forest.predict_proba(X_train)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(Y_train, y_scores)\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n",
    "    plt.xlabel(\"threshold\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also run deep neural network to check whether we are improving with performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 4s 186us/step - loss: 8.1247 - acc: 0.5146 - val_loss: 6.7150 - val_acc: 0.5153\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 5.6927 - acc: 0.5147 - val_loss: 4.6858 - val_acc: 0.5151\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 3.9873 - acc: 0.5152 - val_loss: 3.3061 - val_acc: 0.5116\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 2.8343 - acc: 0.5154 - val_loss: 2.3765 - val_acc: 0.5082\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 2.0618 - acc: 0.5147 - val_loss: 1.7587 - val_acc: 0.5083\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 1.5525 - acc: 0.5144 - val_loss: 1.3547 - val_acc: 0.5089\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 1.2217 - acc: 0.5147 - val_loss: 1.0952 - val_acc: 0.5091\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 1.0111 - acc: 0.5159 - val_loss: 0.9320 - val_acc: 0.5103\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.8801 - acc: 0.5165 - val_loss: 0.8318 - val_acc: 0.5122\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.8004 - acc: 0.5165 - val_loss: 0.7716 - val_acc: 0.5136\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.7531 - acc: 0.5164 - val_loss: 0.7363 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.7256 - acc: 0.5164 - val_loss: 0.7161 - val_acc: 0.5148\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.7101 - acc: 0.5163 - val_loss: 0.7048 - val_acc: 0.5153\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.7016 - acc: 0.5163 - val_loss: 0.6986 - val_acc: 0.5160\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6970 - acc: 0.5165 - val_loss: 0.6953 - val_acc: 0.5161\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6946 - acc: 0.5164 - val_loss: 0.6936 - val_acc: 0.5162\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6933 - acc: 0.5166 - val_loss: 0.6925 - val_acc: 0.5162\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6927 - acc: 0.5165 - val_loss: 0.6921 - val_acc: 0.5161\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6924 - acc: 0.5168 - val_loss: 0.6914 - val_acc: 0.5170\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6924 - acc: 0.5170 - val_loss: 0.6910 - val_acc: 0.5166\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6920 - acc: 0.5168 - val_loss: 0.6905 - val_acc: 0.5163\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6909 - acc: 0.5118 - val_loss: 0.6889 - val_acc: 0.5096\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6894 - acc: 0.4970 - val_loss: 0.6866 - val_acc: 0.4798\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6878 - acc: 0.4985 - val_loss: 0.6855 - val_acc: 0.5314\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6859 - acc: 0.5435 - val_loss: 0.6831 - val_acc: 0.5989\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6832 - acc: 0.5774 - val_loss: 0.6812 - val_acc: 0.5922\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6800 - acc: 0.5762 - val_loss: 0.6755 - val_acc: 0.6152\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6730 - acc: 0.6049 - val_loss: 0.6761 - val_acc: 0.6060\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6695 - acc: 0.6166 - val_loss: 0.6661 - val_acc: 0.6172\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6662 - acc: 0.6196 - val_loss: 0.6762 - val_acc: 0.6050\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6680 - acc: 0.6138 - val_loss: 0.6624 - val_acc: 0.6191\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6658 - acc: 0.6171 - val_loss: 0.6899 - val_acc: 0.5502\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6662 - acc: 0.6154 - val_loss: 0.6589 - val_acc: 0.6243\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6658 - acc: 0.6088 - val_loss: 0.6619 - val_acc: 0.6174\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6616 - acc: 0.6201 - val_loss: 0.6650 - val_acc: 0.6028\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6622 - acc: 0.6152 - val_loss: 0.6620 - val_acc: 0.6142\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6597 - acc: 0.6183 - val_loss: 0.6609 - val_acc: 0.6252\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6585 - acc: 0.6195 - val_loss: 0.6619 - val_acc: 0.6087\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6605 - acc: 0.6158 - val_loss: 0.6559 - val_acc: 0.6218\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6645 - acc: 0.6233 - val_loss: 0.7047 - val_acc: 0.5413\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6689 - acc: 0.6203 - val_loss: 0.6856 - val_acc: 0.5628\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6633 - acc: 0.6171 - val_loss: 0.6644 - val_acc: 0.6129\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6586 - acc: 0.6227 - val_loss: 0.6593 - val_acc: 0.6214\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6579 - acc: 0.6222 - val_loss: 0.6579 - val_acc: 0.6143\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6554 - acc: 0.6240 - val_loss: 0.6582 - val_acc: 0.6183\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6566 - acc: 0.6187 - val_loss: 0.6622 - val_acc: 0.5982\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6556 - acc: 0.6270 - val_loss: 0.6637 - val_acc: 0.6058\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6566 - acc: 0.6229 - val_loss: 0.6568 - val_acc: 0.6188\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6541 - acc: 0.6278 - val_loss: 0.6571 - val_acc: 0.6209\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6538 - acc: 0.6242 - val_loss: 0.6631 - val_acc: 0.6068\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6539 - acc: 0.6214 - val_loss: 0.6521 - val_acc: 0.6267\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6538 - acc: 0.6251 - val_loss: 0.6654 - val_acc: 0.5995\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6531 - acc: 0.6260 - val_loss: 0.6629 - val_acc: 0.5973\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6519 - acc: 0.6280 - val_loss: 0.6558 - val_acc: 0.6189\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6521 - acc: 0.6266 - val_loss: 0.6771 - val_acc: 0.5767\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6545 - acc: 0.6224 - val_loss: 0.6588 - val_acc: 0.6110\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6512 - acc: 0.6297 - val_loss: 0.6589 - val_acc: 0.6124\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6545 - acc: 0.6249 - val_loss: 0.6573 - val_acc: 0.6158\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6540 - acc: 0.6252 - val_loss: 0.6617 - val_acc: 0.6080\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6533 - acc: 0.6263 - val_loss: 0.6616 - val_acc: 0.6064\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6521 - acc: 0.6310 - val_loss: 0.6595 - val_acc: 0.6138\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6525 - acc: 0.6250 - val_loss: 0.6614 - val_acc: 0.6100\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6508 - acc: 0.6279 - val_loss: 0.6633 - val_acc: 0.6106\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6504 - acc: 0.6304 - val_loss: 0.6797 - val_acc: 0.5711\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6497 - acc: 0.6276 - val_loss: 0.6630 - val_acc: 0.6026\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6495 - acc: 0.6300 - val_loss: 0.6739 - val_acc: 0.5826\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6486 - acc: 0.6322 - val_loss: 0.6682 - val_acc: 0.5896\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6485 - acc: 0.6318 - val_loss: 0.6654 - val_acc: 0.5945\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6505 - acc: 0.6306 - val_loss: 0.6785 - val_acc: 0.5753\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6494 - acc: 0.6294 - val_loss: 0.6841 - val_acc: 0.5556\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6510 - acc: 0.6258 - val_loss: 0.6742 - val_acc: 0.5795\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6499 - acc: 0.6284 - val_loss: 0.6504 - val_acc: 0.6298\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6535 - acc: 0.6242 - val_loss: 0.6746 - val_acc: 0.5795\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6517 - acc: 0.6248 - val_loss: 0.6718 - val_acc: 0.5880\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6496 - acc: 0.6318 - val_loss: 0.6645 - val_acc: 0.5974\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6496 - acc: 0.6304 - val_loss: 0.6653 - val_acc: 0.5941\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6486 - acc: 0.6305 - val_loss: 0.6631 - val_acc: 0.5970\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6482 - acc: 0.6308 - val_loss: 0.6778 - val_acc: 0.5791\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6475 - acc: 0.6302 - val_loss: 0.6709 - val_acc: 0.5879\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6488 - acc: 0.6310 - val_loss: 0.6821 - val_acc: 0.5630\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6487 - acc: 0.6301 - val_loss: 0.6808 - val_acc: 0.5671\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6498 - acc: 0.6275 - val_loss: 0.6658 - val_acc: 0.6038\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6473 - acc: 0.6323 - val_loss: 0.6843 - val_acc: 0.5560\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6485 - acc: 0.6294 - val_loss: 0.6765 - val_acc: 0.5805\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6474 - acc: 0.6337 - val_loss: 0.6852 - val_acc: 0.5540\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6465 - acc: 0.6336 - val_loss: 0.6689 - val_acc: 0.5893\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6481 - acc: 0.6299 - val_loss: 0.6672 - val_acc: 0.5910\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6472 - acc: 0.6305 - val_loss: 0.6839 - val_acc: 0.5578\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6482 - acc: 0.6301 - val_loss: 0.6931 - val_acc: 0.5397\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6483 - acc: 0.6276 - val_loss: 0.6777 - val_acc: 0.5743\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6466 - acc: 0.6335 - val_loss: 0.6867 - val_acc: 0.5509\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6464 - acc: 0.6325 - val_loss: 0.6650 - val_acc: 0.5919\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6483 - acc: 0.6307 - val_loss: 0.6816 - val_acc: 0.5659\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6484 - acc: 0.6304 - val_loss: 0.6716 - val_acc: 0.5884\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6496 - acc: 0.6309 - val_loss: 0.6877 - val_acc: 0.5501\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6483 - acc: 0.6338 - val_loss: 0.6936 - val_acc: 0.5421\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6471 - acc: 0.6325 - val_loss: 0.6787 - val_acc: 0.5689\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6484 - acc: 0.6305 - val_loss: 0.7018 - val_acc: 0.5343\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6482 - acc: 0.6313 - val_loss: 0.6788 - val_acc: 0.5720\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6485 - acc: 0.6298 - val_loss: 0.6750 - val_acc: 0.5827\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6463 - acc: 0.6324 - val_loss: 0.6905 - val_acc: 0.5460\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6487 - acc: 0.6278 - val_loss: 0.6849 - val_acc: 0.5595\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6480 - acc: 0.6311 - val_loss: 0.6726 - val_acc: 0.5835\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6467 - acc: 0.6311 - val_loss: 0.6971 - val_acc: 0.5386\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6460 - acc: 0.6335 - val_loss: 0.6611 - val_acc: 0.6053\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6472 - acc: 0.6322 - val_loss: 0.6877 - val_acc: 0.5510\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6460 - acc: 0.6338 - val_loss: 0.6679 - val_acc: 0.5892\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6470 - acc: 0.6322 - val_loss: 0.6821 - val_acc: 0.5617\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6439 - acc: 0.6364 - val_loss: 0.6814 - val_acc: 0.5597\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6457 - acc: 0.6311 - val_loss: 0.6871 - val_acc: 0.5529\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6480 - acc: 0.6305 - val_loss: 0.6894 - val_acc: 0.5473\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6475 - acc: 0.6305 - val_loss: 0.6857 - val_acc: 0.5624\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6448 - acc: 0.6352 - val_loss: 0.6844 - val_acc: 0.5565\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6461 - acc: 0.6330 - val_loss: 0.6728 - val_acc: 0.5908\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6453 - acc: 0.6355 - val_loss: 0.6751 - val_acc: 0.5792\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6440 - acc: 0.6380 - val_loss: 0.6777 - val_acc: 0.5691\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6460 - acc: 0.6325 - val_loss: 0.6797 - val_acc: 0.5716\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 7us/step - loss: 0.6459 - acc: 0.6325 - val_loss: 0.6905 - val_acc: 0.5463\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6461 - acc: 0.6336 - val_loss: 0.6784 - val_acc: 0.5733\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 1s 37us/step - loss: 0.6444 - acc: 0.6365 - val_loss: 0.6881 - val_acc: 0.5511\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6454 - acc: 0.6361 - val_loss: 0.6985 - val_acc: 0.5365\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6467 - acc: 0.6313 - val_loss: 0.6814 - val_acc: 0.5649\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6432 - acc: 0.6361 - val_loss: 0.6905 - val_acc: 0.5455\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6429 - acc: 0.6353 - val_loss: 0.6876 - val_acc: 0.5511\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6421 - acc: 0.6380 - val_loss: 0.6886 - val_acc: 0.5506\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6450 - acc: 0.6354 - val_loss: 0.6825 - val_acc: 0.5572\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6432 - acc: 0.6369 - val_loss: 0.6961 - val_acc: 0.5398\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6453 - acc: 0.6328 - val_loss: 0.6807 - val_acc: 0.5676\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6441 - acc: 0.6362 - val_loss: 0.6909 - val_acc: 0.5482\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6428 - acc: 0.6379 - val_loss: 0.6815 - val_acc: 0.5655\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.6424 - acc: 0.6382 - val_loss: 0.6908 - val_acc: 0.5504\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6432 - acc: 0.6370 - val_loss: 0.6985 - val_acc: 0.5386\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6433 - acc: 0.6368 - val_loss: 0.6977 - val_acc: 0.5443\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6423 - acc: 0.6386 - val_loss: 0.6928 - val_acc: 0.5458\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6434 - acc: 0.6393 - val_loss: 0.6959 - val_acc: 0.5434\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6424 - acc: 0.6396 - val_loss: 0.6885 - val_acc: 0.5515\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6418 - acc: 0.6395 - val_loss: 0.7003 - val_acc: 0.5344\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6425 - acc: 0.6421 - val_loss: 0.6956 - val_acc: 0.5417\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6452 - acc: 0.6357 - val_loss: 0.6972 - val_acc: 0.5446\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6430 - acc: 0.6377 - val_loss: 0.6991 - val_acc: 0.5450\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6427 - acc: 0.6386 - val_loss: 0.7022 - val_acc: 0.5376\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6450 - acc: 0.6332 - val_loss: 0.6911 - val_acc: 0.5541\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6410 - acc: 0.6439 - val_loss: 0.6944 - val_acc: 0.5458\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6402 - acc: 0.6414 - val_loss: 0.6971 - val_acc: 0.5395\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6417 - acc: 0.6404 - val_loss: 0.6931 - val_acc: 0.5469\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6424 - acc: 0.6379 - val_loss: 0.7017 - val_acc: 0.5398\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6400 - acc: 0.6410 - val_loss: 0.6998 - val_acc: 0.5382\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6425 - acc: 0.6373 - val_loss: 0.6974 - val_acc: 0.5389\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6411 - acc: 0.6394 - val_loss: 0.6995 - val_acc: 0.5391\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6390 - acc: 0.6438 - val_loss: 0.6992 - val_acc: 0.5387\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6393 - acc: 0.6434 - val_loss: 0.6924 - val_acc: 0.5468\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6403 - acc: 0.6416 - val_loss: 0.6915 - val_acc: 0.5506\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6415 - acc: 0.6434 - val_loss: 0.7010 - val_acc: 0.5344\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6403 - acc: 0.6432 - val_loss: 0.6995 - val_acc: 0.5394\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 18us/step - loss: 0.6420 - acc: 0.6416 - val_loss: 0.6947 - val_acc: 0.5457\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6406 - acc: 0.6437 - val_loss: 0.6967 - val_acc: 0.5474\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6427 - acc: 0.6365 - val_loss: 0.6940 - val_acc: 0.5511\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6422 - acc: 0.6397 - val_loss: 0.6884 - val_acc: 0.5545\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6414 - acc: 0.6390 - val_loss: 0.6986 - val_acc: 0.5397\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6396 - acc: 0.6425 - val_loss: 0.7010 - val_acc: 0.5363\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6396 - acc: 0.6428 - val_loss: 0.6983 - val_acc: 0.5392\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6370 - acc: 0.6457 - val_loss: 0.6983 - val_acc: 0.5393\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6378 - acc: 0.6452 - val_loss: 0.6999 - val_acc: 0.5381\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6390 - acc: 0.6415 - val_loss: 0.7000 - val_acc: 0.5414\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6390 - acc: 0.6431 - val_loss: 0.6970 - val_acc: 0.5421\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6379 - acc: 0.6421 - val_loss: 0.7046 - val_acc: 0.5288\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6381 - acc: 0.6431 - val_loss: 0.7072 - val_acc: 0.5292\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6399 - acc: 0.6408 - val_loss: 0.6946 - val_acc: 0.5474\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6395 - acc: 0.6437 - val_loss: 0.7013 - val_acc: 0.5387\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6404 - acc: 0.6385 - val_loss: 0.7013 - val_acc: 0.5367\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6397 - acc: 0.6405 - val_loss: 0.7032 - val_acc: 0.5363\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6409 - acc: 0.6408 - val_loss: 0.7023 - val_acc: 0.5356\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6392 - acc: 0.6415 - val_loss: 0.7032 - val_acc: 0.5366\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6388 - acc: 0.6407 - val_loss: 0.7032 - val_acc: 0.5350\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6373 - acc: 0.6448 - val_loss: 0.6992 - val_acc: 0.5398\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6357 - acc: 0.6459 - val_loss: 0.7019 - val_acc: 0.5349\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6380 - acc: 0.6442 - val_loss: 0.7035 - val_acc: 0.5341\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6378 - acc: 0.6443 - val_loss: 0.7015 - val_acc: 0.5386\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6366 - acc: 0.6457 - val_loss: 0.7008 - val_acc: 0.5357\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6394 - acc: 0.6399 - val_loss: 0.7085 - val_acc: 0.5260\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6401 - acc: 0.6420 - val_loss: 0.7042 - val_acc: 0.5344\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6366 - acc: 0.6458 - val_loss: 0.7033 - val_acc: 0.5342\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6386 - acc: 0.6421 - val_loss: 0.7049 - val_acc: 0.5305\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6389 - acc: 0.6421 - val_loss: 0.7056 - val_acc: 0.5299\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6388 - acc: 0.6432 - val_loss: 0.7030 - val_acc: 0.5332\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6383 - acc: 0.6429 - val_loss: 0.7032 - val_acc: 0.5346\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6362 - acc: 0.6442 - val_loss: 0.7041 - val_acc: 0.5328\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6403 - acc: 0.6427 - val_loss: 0.7226 - val_acc: 0.5301\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6443 - acc: 0.6410 - val_loss: 0.7224 - val_acc: 0.5306\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6386 - acc: 0.6444 - val_loss: 0.7147 - val_acc: 0.5319\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6389 - acc: 0.6423 - val_loss: 0.7072 - val_acc: 0.5365\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6374 - acc: 0.6443 - val_loss: 0.7080 - val_acc: 0.5361\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6387 - acc: 0.6431 - val_loss: 0.7093 - val_acc: 0.5257\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6389 - acc: 0.6422 - val_loss: 0.7044 - val_acc: 0.5352\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6382 - acc: 0.6421 - val_loss: 0.7038 - val_acc: 0.5336\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6408 - acc: 0.6390 - val_loss: 0.7025 - val_acc: 0.5375\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6374 - acc: 0.6459 - val_loss: 0.7059 - val_acc: 0.5344\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6430 - acc: 0.6366 - val_loss: 0.6997 - val_acc: 0.5422\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6378 - acc: 0.6424 - val_loss: 0.6999 - val_acc: 0.5379\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6373 - acc: 0.6446 - val_loss: 0.7000 - val_acc: 0.5384\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6376 - acc: 0.6426 - val_loss: 0.7010 - val_acc: 0.5388\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6368 - acc: 0.6469 - val_loss: 0.7033 - val_acc: 0.5353\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6373 - acc: 0.6427 - val_loss: 0.7023 - val_acc: 0.5342\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6343 - acc: 0.6467 - val_loss: 0.7040 - val_acc: 0.5337\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6377 - acc: 0.6426 - val_loss: 0.7059 - val_acc: 0.5297\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6388 - acc: 0.6411 - val_loss: 0.7049 - val_acc: 0.5314\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6378 - acc: 0.6411 - val_loss: 0.7088 - val_acc: 0.5276\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6379 - acc: 0.6443 - val_loss: 0.7074 - val_acc: 0.5278\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6394 - acc: 0.6415 - val_loss: 0.7061 - val_acc: 0.5316\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6389 - acc: 0.6403 - val_loss: 0.6995 - val_acc: 0.5402\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6407 - acc: 0.6400 - val_loss: 0.7023 - val_acc: 0.5350\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6385 - acc: 0.6427 - val_loss: 0.6956 - val_acc: 0.5448\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6414 - acc: 0.6383 - val_loss: 0.7021 - val_acc: 0.5371\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6364 - acc: 0.6465 - val_loss: 0.7030 - val_acc: 0.5358\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6375 - acc: 0.6429 - val_loss: 0.7069 - val_acc: 0.5353\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6361 - acc: 0.6463 - val_loss: 0.7022 - val_acc: 0.5371\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6369 - acc: 0.6443 - val_loss: 0.7032 - val_acc: 0.5365\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6361 - acc: 0.6457 - val_loss: 0.7065 - val_acc: 0.5329\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6357 - acc: 0.6480 - val_loss: 0.7066 - val_acc: 0.5341\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6352 - acc: 0.6482 - val_loss: 0.7031 - val_acc: 0.5349\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 16us/step - loss: 0.6355 - acc: 0.6454 - val_loss: 0.7026 - val_acc: 0.5359\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 1s 51us/step - loss: 0.6359 - acc: 0.6478 - val_loss: 0.7049 - val_acc: 0.5359\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 1s 45us/step - loss: 0.6355 - acc: 0.6462 - val_loss: 0.7030 - val_acc: 0.5348\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6398 - acc: 0.6370 - val_loss: 0.7021 - val_acc: 0.5393\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6407 - acc: 0.6423 - val_loss: 0.6987 - val_acc: 0.5457\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6380 - acc: 0.6444 - val_loss: 0.7021 - val_acc: 0.5384\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6362 - acc: 0.6447 - val_loss: 0.7058 - val_acc: 0.5342\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6355 - acc: 0.6461 - val_loss: 0.7049 - val_acc: 0.5378\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6357 - acc: 0.6474 - val_loss: 0.7018 - val_acc: 0.5369\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6342 - acc: 0.6454 - val_loss: 0.7009 - val_acc: 0.5371\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6362 - acc: 0.6431 - val_loss: 0.7039 - val_acc: 0.5361\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6363 - acc: 0.6459 - val_loss: 0.6991 - val_acc: 0.5409\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6365 - acc: 0.6452 - val_loss: 0.7024 - val_acc: 0.5368\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6364 - acc: 0.6445 - val_loss: 0.7061 - val_acc: 0.5307\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6454 - acc: 0.6324 - val_loss: 0.6952 - val_acc: 0.5470\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6423 - acc: 0.6388 - val_loss: 0.7042 - val_acc: 0.5331\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6377 - acc: 0.6400 - val_loss: 0.6998 - val_acc: 0.5403\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6364 - acc: 0.6441 - val_loss: 0.7005 - val_acc: 0.5398\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6380 - acc: 0.6437 - val_loss: 0.7072 - val_acc: 0.5273\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 16us/step - loss: 0.6361 - acc: 0.6433 - val_loss: 0.7063 - val_acc: 0.5295\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6357 - acc: 0.6460 - val_loss: 0.7050 - val_acc: 0.5318\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6344 - acc: 0.6448 - val_loss: 0.7040 - val_acc: 0.5320\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6373 - acc: 0.6450 - val_loss: 0.7054 - val_acc: 0.5289\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6363 - acc: 0.6447 - val_loss: 0.7066 - val_acc: 0.5286\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6348 - acc: 0.6472 - val_loss: 0.7061 - val_acc: 0.5295\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6383 - acc: 0.6444 - val_loss: 0.7052 - val_acc: 0.5314\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6347 - acc: 0.6476 - val_loss: 0.7050 - val_acc: 0.5307\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6363 - acc: 0.6457 - val_loss: 0.7040 - val_acc: 0.5341\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6360 - acc: 0.6462 - val_loss: 0.7038 - val_acc: 0.5335\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6366 - acc: 0.6451 - val_loss: 0.7048 - val_acc: 0.5315\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6341 - acc: 0.6479 - val_loss: 0.7066 - val_acc: 0.5292\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6379 - acc: 0.6423 - val_loss: 0.7040 - val_acc: 0.5343\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6369 - acc: 0.6455 - val_loss: 0.7051 - val_acc: 0.5316\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6388 - acc: 0.6415 - val_loss: 0.7071 - val_acc: 0.5294\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6391 - acc: 0.6398 - val_loss: 0.7066 - val_acc: 0.5299\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6413 - acc: 0.6410 - val_loss: 0.6993 - val_acc: 0.5407\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 1s 29us/step - loss: 0.6340 - acc: 0.6470 - val_loss: 0.7063 - val_acc: 0.5366\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6342 - acc: 0.6464 - val_loss: 0.7063 - val_acc: 0.5368\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6356 - acc: 0.6442 - val_loss: 0.7038 - val_acc: 0.5405\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6368 - acc: 0.6428 - val_loss: 0.7043 - val_acc: 0.5338\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6343 - acc: 0.6470 - val_loss: 0.7080 - val_acc: 0.5275\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6345 - acc: 0.6478 - val_loss: 0.7036 - val_acc: 0.5369\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6369 - acc: 0.6421 - val_loss: 0.7045 - val_acc: 0.5328\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6338 - acc: 0.6472 - val_loss: 0.7040 - val_acc: 0.5358\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6359 - acc: 0.6466 - val_loss: 0.7128 - val_acc: 0.5335\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6369 - acc: 0.6455 - val_loss: 0.7073 - val_acc: 0.5375\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6372 - acc: 0.6438 - val_loss: 0.7059 - val_acc: 0.5352\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6379 - acc: 0.6416 - val_loss: 0.7040 - val_acc: 0.5410\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6343 - acc: 0.6478 - val_loss: 0.7050 - val_acc: 0.5337\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6340 - acc: 0.6464 - val_loss: 0.7060 - val_acc: 0.5311\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6332 - acc: 0.6481 - val_loss: 0.7039 - val_acc: 0.5337\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6343 - acc: 0.6477 - val_loss: 0.7083 - val_acc: 0.5330\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6339 - acc: 0.6468 - val_loss: 0.7079 - val_acc: 0.5363\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6355 - acc: 0.6452 - val_loss: 0.7053 - val_acc: 0.5435\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6367 - acc: 0.6439 - val_loss: 0.7097 - val_acc: 0.5244\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6361 - acc: 0.6427 - val_loss: 0.7070 - val_acc: 0.5320\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6338 - acc: 0.6473 - val_loss: 0.7048 - val_acc: 0.5356\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6347 - acc: 0.6453 - val_loss: 0.7051 - val_acc: 0.5342\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6355 - acc: 0.6441 - val_loss: 0.7046 - val_acc: 0.5321\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6329 - acc: 0.6481 - val_loss: 0.7042 - val_acc: 0.5335\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6354 - acc: 0.6427 - val_loss: 0.7073 - val_acc: 0.5335\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6352 - acc: 0.6457 - val_loss: 0.7080 - val_acc: 0.5343\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6338 - acc: 0.6470 - val_loss: 0.7037 - val_acc: 0.5351\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.6332 - acc: 0.6492 - val_loss: 0.7086 - val_acc: 0.5323\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 17us/step - loss: 0.6336 - acc: 0.6461 - val_loss: 0.7064 - val_acc: 0.5366\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 19us/step - loss: 0.6329 - acc: 0.6491 - val_loss: 0.7054 - val_acc: 0.5335\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6326 - acc: 0.6496 - val_loss: 0.7055 - val_acc: 0.5372\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6341 - acc: 0.6462 - val_loss: 0.7045 - val_acc: 0.5335\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6333 - acc: 0.6490 - val_loss: 0.7050 - val_acc: 0.5353\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6343 - acc: 0.6446 - val_loss: 0.7047 - val_acc: 0.5346\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6352 - acc: 0.6445 - val_loss: 0.7075 - val_acc: 0.5335\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6353 - acc: 0.6471 - val_loss: 0.7148 - val_acc: 0.5338\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6365 - acc: 0.6454 - val_loss: 0.7097 - val_acc: 0.5377\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6361 - acc: 0.6462 - val_loss: 0.7156 - val_acc: 0.5352\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6331 - acc: 0.6497 - val_loss: 0.7054 - val_acc: 0.5357\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6349 - acc: 0.6485 - val_loss: 0.7019 - val_acc: 0.5391\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6352 - acc: 0.6448 - val_loss: 0.7060 - val_acc: 0.5381\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6318 - acc: 0.6514 - val_loss: 0.7096 - val_acc: 0.5358\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6324 - acc: 0.6515 - val_loss: 0.7238 - val_acc: 0.5340\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6347 - acc: 0.6491 - val_loss: 0.7178 - val_acc: 0.5341\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model3=keras.Sequential()\n",
    "model3.add(keras.layers.Dense(100, input_dim=77, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "model3.add(keras.layers.Dense(50, activation='relu'))\n",
    "model3.add(keras.layers.Dense(25, activation='relu'))\n",
    "model3.add(keras.layers.Dense(12, activation='relu'))\n",
    "model3.add(keras.layers.Dense(6, activation='relu'))\n",
    "model3.add(keras.layers.Dense(3, activation='sigmoid'))\n",
    "model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model3.fit(X_scaledtr, Y_train, epochs=300, batch_size=1000, validation_data=(X_scaledte, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x432 with 0 Axes>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28287adb2b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28287adb2e8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28287db1ac8>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Model accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28287dbdc88>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28287dbd048>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28287dbd5c0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28287f97198>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Model loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epoch')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28287e83a90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy and loss\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see lot of overfitting, we will try with K fold cross validation on DNN too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold # {1}\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 2s 108us/step - loss: 8.2466 - acc: 0.5146 - val_loss: 6.8424 - val_acc: 0.5153\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 5.8081 - acc: 0.5146 - val_loss: 4.7873 - val_acc: 0.5153\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 4.0766 - acc: 0.5148 - val_loss: 3.3822 - val_acc: 0.5137\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.9007 - acc: 0.5156 - val_loss: 2.4330 - val_acc: 0.5128\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.1107 - acc: 0.5165 - val_loss: 1.7993 - val_acc: 0.5125\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.5863 - acc: 0.5171 - val_loss: 1.3820 - val_acc: 0.5143\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 1.2440 - acc: 0.5166 - val_loss: 1.1128 - val_acc: 0.5150\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 1.0254 - acc: 0.5166 - val_loss: 0.9429 - val_acc: 0.5151\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.8887 - acc: 0.5169 - val_loss: 0.8381 - val_acc: 0.5151\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.8051 - acc: 0.5169 - val_loss: 0.7747 - val_acc: 0.5164\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.7553 - acc: 0.5170 - val_loss: 0.7371 - val_acc: 0.5174\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.7258 - acc: 0.5160 - val_loss: 0.7150 - val_acc: 0.5153\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.7081 - acc: 0.4964 - val_loss: 0.7009 - val_acc: 0.4926\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6973 - acc: 0.5017 - val_loss: 0.6935 - val_acc: 0.5937\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6911 - acc: 0.5715 - val_loss: 0.6888 - val_acc: 0.6067\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6874 - acc: 0.5887 - val_loss: 0.6860 - val_acc: 0.6124\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6849 - acc: 0.5844 - val_loss: 0.6831 - val_acc: 0.6126\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6824 - acc: 0.5957 - val_loss: 0.6827 - val_acc: 0.6142\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6803 - acc: 0.6035 - val_loss: 0.6787 - val_acc: 0.6200\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6759 - acc: 0.6372 - val_loss: 0.6753 - val_acc: 0.6623\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6712 - acc: 0.6728 - val_loss: 0.6703 - val_acc: 0.6629\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6679 - acc: 0.6746 - val_loss: 0.6682 - val_acc: 0.6694\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6658 - acc: 0.6748 - val_loss: 0.6675 - val_acc: 0.6690\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6641 - acc: 0.6746 - val_loss: 0.6654 - val_acc: 0.6689\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6623 - acc: 0.6758 - val_loss: 0.6623 - val_acc: 0.6696\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6614 - acc: 0.6751 - val_loss: 0.6639 - val_acc: 0.6637\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6610 - acc: 0.6740 - val_loss: 0.6616 - val_acc: 0.6686\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6605 - acc: 0.6715 - val_loss: 0.6636 - val_acc: 0.6579\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6584 - acc: 0.6747 - val_loss: 0.6590 - val_acc: 0.6708\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6566 - acc: 0.6745 - val_loss: 0.6585 - val_acc: 0.6697\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6559 - acc: 0.6773 - val_loss: 0.6580 - val_acc: 0.6671\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.6559 - acc: 0.6746 - val_loss: 0.6578 - val_acc: 0.6647\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6552 - acc: 0.6732 - val_loss: 0.6556 - val_acc: 0.6674\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6530 - acc: 0.6770 - val_loss: 0.6567 - val_acc: 0.6612\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6539 - acc: 0.6723 - val_loss: 0.6544 - val_acc: 0.6683\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6528 - acc: 0.6723 - val_loss: 0.6537 - val_acc: 0.6667\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6506 - acc: 0.6769 - val_loss: 0.6529 - val_acc: 0.6685\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6505 - acc: 0.6769 - val_loss: 0.6828 - val_acc: 0.5741\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6500 - acc: 0.6763 - val_loss: 0.6518 - val_acc: 0.6672\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6508 - acc: 0.6712 - val_loss: 0.6602 - val_acc: 0.6453\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6510 - acc: 0.6709 - val_loss: 0.6512 - val_acc: 0.6668\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6473 - acc: 0.6759 - val_loss: 0.6500 - val_acc: 0.6679\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6464 - acc: 0.6773 - val_loss: 0.6495 - val_acc: 0.6712\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6479 - acc: 0.6733 - val_loss: 0.6496 - val_acc: 0.6665\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6629 - acc: 0.6755 - val_loss: 0.7434 - val_acc: 0.4844\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6655 - acc: 0.6735 - val_loss: 0.7054 - val_acc: 0.5485\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6533 - acc: 0.6725 - val_loss: 0.6798 - val_acc: 0.5873\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6494 - acc: 0.6720 - val_loss: 0.6733 - val_acc: 0.6108\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6443 - acc: 0.6777 - val_loss: 0.6568 - val_acc: 0.6497\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6417 - acc: 0.6788 - val_loss: 0.6497 - val_acc: 0.6625\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6422 - acc: 0.6757 - val_loss: 0.6490 - val_acc: 0.6651\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6414 - acc: 0.6751 - val_loss: 0.6514 - val_acc: 0.6577\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6432 - acc: 0.6717 - val_loss: 0.6550 - val_acc: 0.6505\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6420 - acc: 0.6740 - val_loss: 0.6485 - val_acc: 0.6617\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6412 - acc: 0.6745 - val_loss: 0.6465 - val_acc: 0.6639\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6386 - acc: 0.6774 - val_loss: 0.6431 - val_acc: 0.6674\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6375 - acc: 0.6771 - val_loss: 0.6452 - val_acc: 0.6648\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6369 - acc: 0.6801 - val_loss: 0.6450 - val_acc: 0.6599\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6387 - acc: 0.6750 - val_loss: 0.6439 - val_acc: 0.6645\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6383 - acc: 0.6747 - val_loss: 0.6417 - val_acc: 0.6678\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6377 - acc: 0.6753 - val_loss: 0.6417 - val_acc: 0.6663\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6378 - acc: 0.6739 - val_loss: 0.6402 - val_acc: 0.6707\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6373 - acc: 0.6740 - val_loss: 0.6388 - val_acc: 0.6737\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6357 - acc: 0.6791 - val_loss: 0.6461 - val_acc: 0.6604\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6386 - acc: 0.6746 - val_loss: 0.6432 - val_acc: 0.6663\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6369 - acc: 0.6758 - val_loss: 0.6432 - val_acc: 0.6657\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6338 - acc: 0.6803 - val_loss: 0.6393 - val_acc: 0.6693\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6337 - acc: 0.6779 - val_loss: 0.6386 - val_acc: 0.6715\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6341 - acc: 0.6779 - val_loss: 0.6455 - val_acc: 0.6578\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6360 - acc: 0.6749 - val_loss: 0.6419 - val_acc: 0.6643\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6341 - acc: 0.6776 - val_loss: 0.6521 - val_acc: 0.6396\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6376 - acc: 0.6729 - val_loss: 0.6445 - val_acc: 0.6622\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6361 - acc: 0.6770 - val_loss: 0.6380 - val_acc: 0.6670\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6328 - acc: 0.6795 - val_loss: 0.6337 - val_acc: 0.6769\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6311 - acc: 0.6792 - val_loss: 0.6368 - val_acc: 0.6698\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6319 - acc: 0.6784 - val_loss: 0.6418 - val_acc: 0.6679\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6321 - acc: 0.6766 - val_loss: 0.6429 - val_acc: 0.6591\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6417 - acc: 0.6792 - val_loss: 0.7600 - val_acc: 0.5056\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6517 - acc: 0.6773 - val_loss: 0.7045 - val_acc: 0.5865\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6406 - acc: 0.6772 - val_loss: 0.6694 - val_acc: 0.6278\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6331 - acc: 0.6824 - val_loss: 0.6507 - val_acc: 0.6514\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6299 - acc: 0.6805 - val_loss: 0.6460 - val_acc: 0.6507\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6295 - acc: 0.6784 - val_loss: 0.6436 - val_acc: 0.6581\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6296 - acc: 0.6801 - val_loss: 0.6385 - val_acc: 0.6650\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6294 - acc: 0.6784 - val_loss: 0.6364 - val_acc: 0.6678\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 16us/step - loss: 0.6265 - acc: 0.6812 - val_loss: 0.6326 - val_acc: 0.6712\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6239 - acc: 0.6843 - val_loss: 0.6374 - val_acc: 0.6619\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6262 - acc: 0.6808 - val_loss: 0.6356 - val_acc: 0.6653\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6266 - acc: 0.6812 - val_loss: 0.6361 - val_acc: 0.6667\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6261 - acc: 0.6823 - val_loss: 0.6313 - val_acc: 0.6725\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6249 - acc: 0.6818 - val_loss: 0.6316 - val_acc: 0.6752\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6242 - acc: 0.6818 - val_loss: 0.6278 - val_acc: 0.6779\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6240 - acc: 0.6797 - val_loss: 0.6319 - val_acc: 0.6715\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6242 - acc: 0.6810 - val_loss: 0.6311 - val_acc: 0.6692\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6235 - acc: 0.6823 - val_loss: 0.6295 - val_acc: 0.6785\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6228 - acc: 0.6825 - val_loss: 0.6311 - val_acc: 0.6742\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6230 - acc: 0.6844 - val_loss: 0.6319 - val_acc: 0.6720\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6240 - acc: 0.6818 - val_loss: 0.6317 - val_acc: 0.6736\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6215 - acc: 0.6869 - val_loss: 0.6354 - val_acc: 0.6672\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6240 - acc: 0.6821 - val_loss: 0.6373 - val_acc: 0.6611\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6231 - acc: 0.6833 - val_loss: 0.6417 - val_acc: 0.6547\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6193 - acc: 0.6882 - val_loss: 0.6365 - val_acc: 0.6646\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6189 - acc: 0.6887 - val_loss: 0.6342 - val_acc: 0.6644\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6191 - acc: 0.6879 - val_loss: 0.6411 - val_acc: 0.6592\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6210 - acc: 0.6870 - val_loss: 0.6334 - val_acc: 0.6689\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6221 - acc: 0.6823 - val_loss: 0.6265 - val_acc: 0.6744\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6204 - acc: 0.6837 - val_loss: 0.6304 - val_acc: 0.6696\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6185 - acc: 0.6883 - val_loss: 0.6415 - val_acc: 0.6577\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6210 - acc: 0.6830 - val_loss: 0.6324 - val_acc: 0.6660\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6204 - acc: 0.6859 - val_loss: 0.6538 - val_acc: 0.6358\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6165 - acc: 0.6890 - val_loss: 0.6255 - val_acc: 0.6739\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6156 - acc: 0.6911 - val_loss: 0.6263 - val_acc: 0.6716\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6169 - acc: 0.6874 - val_loss: 0.6214 - val_acc: 0.6795\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6172 - acc: 0.6877 - val_loss: 0.6257 - val_acc: 0.6785\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6159 - acc: 0.6899 - val_loss: 0.6494 - val_acc: 0.6374\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6147 - acc: 0.6926 - val_loss: 0.6373 - val_acc: 0.6589\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6159 - acc: 0.6888 - val_loss: 0.6443 - val_acc: 0.6493\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6157 - acc: 0.6872 - val_loss: 0.6534 - val_acc: 0.6358\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6169 - acc: 0.6869 - val_loss: 0.6376 - val_acc: 0.6537\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6133 - acc: 0.6920 - val_loss: 0.6389 - val_acc: 0.6458\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6121 - acc: 0.6906 - val_loss: 0.6454 - val_acc: 0.6439\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6130 - acc: 0.6916 - val_loss: 0.6432 - val_acc: 0.6461\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6110 - acc: 0.6943 - val_loss: 0.6211 - val_acc: 0.6778\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6113 - acc: 0.6917 - val_loss: 0.6320 - val_acc: 0.6604\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6119 - acc: 0.6906 - val_loss: 0.6350 - val_acc: 0.6555\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6106 - acc: 0.6955 - val_loss: 0.6419 - val_acc: 0.6438\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6109 - acc: 0.6935 - val_loss: 0.6498 - val_acc: 0.6384\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6098 - acc: 0.6926 - val_loss: 0.6349 - val_acc: 0.6554\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6106 - acc: 0.6901 - val_loss: 0.6616 - val_acc: 0.6301\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6115 - acc: 0.6900 - val_loss: 0.6239 - val_acc: 0.6747\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6083 - acc: 0.6944 - val_loss: 0.6571 - val_acc: 0.6293\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6077 - acc: 0.6963 - val_loss: 0.6423 - val_acc: 0.6453\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6087 - acc: 0.6942 - val_loss: 0.6642 - val_acc: 0.6223\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6075 - acc: 0.6974 - val_loss: 0.6287 - val_acc: 0.6653\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6113 - acc: 0.6910 - val_loss: 0.6329 - val_acc: 0.6647\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6075 - acc: 0.6944 - val_loss: 0.6999 - val_acc: 0.5927\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6337 - acc: 0.6989 - val_loss: 0.7763 - val_acc: 0.5346\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6210 - acc: 0.6960 - val_loss: 0.7341 - val_acc: 0.5763\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6097 - acc: 0.6976 - val_loss: 0.7409 - val_acc: 0.5486\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6069 - acc: 0.7005 - val_loss: 0.7006 - val_acc: 0.5930\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6060 - acc: 0.6985 - val_loss: 0.6775 - val_acc: 0.6065\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6048 - acc: 0.6987 - val_loss: 0.6734 - val_acc: 0.6123\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6044 - acc: 0.7005 - val_loss: 0.6605 - val_acc: 0.6280\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6056 - acc: 0.6987 - val_loss: 0.6516 - val_acc: 0.6383\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6050 - acc: 0.6996 - val_loss: 0.6691 - val_acc: 0.6134\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6109 - acc: 0.6950 - val_loss: 0.7586 - val_acc: 0.5341\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6073 - acc: 0.6999 - val_loss: 0.6949 - val_acc: 0.5952\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6093 - acc: 0.6922 - val_loss: 0.7066 - val_acc: 0.5887\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6060 - acc: 0.6982 - val_loss: 0.6982 - val_acc: 0.5884\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 0.6042 - acc: 0.6991 - val_loss: 0.6750 - val_acc: 0.6071\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6017 - acc: 0.7027 - val_loss: 0.6958 - val_acc: 0.5925\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6030 - acc: 0.7009 - val_loss: 0.6947 - val_acc: 0.5921\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6014 - acc: 0.7054 - val_loss: 0.6748 - val_acc: 0.6158\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6028 - acc: 0.7013 - val_loss: 0.6742 - val_acc: 0.6102\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6040 - acc: 0.6981 - val_loss: 0.6693 - val_acc: 0.6128\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6051 - acc: 0.6974 - val_loss: 0.6635 - val_acc: 0.6234\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6017 - acc: 0.7024 - val_loss: 0.6853 - val_acc: 0.6038\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6032 - acc: 0.7010 - val_loss: 0.7023 - val_acc: 0.5929\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6022 - acc: 0.6998 - val_loss: 0.6593 - val_acc: 0.6270\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6029 - acc: 0.7000 - val_loss: 0.6987 - val_acc: 0.5937\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6041 - acc: 0.6960 - val_loss: 0.6968 - val_acc: 0.5923\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6050 - acc: 0.6959 - val_loss: 0.6532 - val_acc: 0.6363\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5994 - acc: 0.7035 - val_loss: 0.6844 - val_acc: 0.6026\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6013 - acc: 0.7005 - val_loss: 0.6463 - val_acc: 0.6451\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6008 - acc: 0.7015 - val_loss: 0.6629 - val_acc: 0.6249\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5997 - acc: 0.7022 - val_loss: 0.6621 - val_acc: 0.6198\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6009 - acc: 0.7028 - val_loss: 0.6621 - val_acc: 0.6286\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5988 - acc: 0.7025 - val_loss: 0.6561 - val_acc: 0.6318\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6107 - acc: 0.7032 - val_loss: 0.7812 - val_acc: 0.5455\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6121 - acc: 0.7032 - val_loss: 0.7501 - val_acc: 0.5769\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6066 - acc: 0.7029 - val_loss: 0.7420 - val_acc: 0.5778\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6011 - acc: 0.7065 - val_loss: 0.7212 - val_acc: 0.5862\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6024 - acc: 0.6982 - val_loss: 0.7208 - val_acc: 0.5849\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5985 - acc: 0.7044 - val_loss: 0.7087 - val_acc: 0.5929\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5983 - acc: 0.7023 - val_loss: 0.7023 - val_acc: 0.5917\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5982 - acc: 0.7053 - val_loss: 0.7114 - val_acc: 0.5895\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6001 - acc: 0.7012 - val_loss: 0.7173 - val_acc: 0.5843\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6005 - acc: 0.7018 - val_loss: 0.6936 - val_acc: 0.5991\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5966 - acc: 0.7059 - val_loss: 0.7178 - val_acc: 0.5876\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5998 - acc: 0.7054 - val_loss: 0.7085 - val_acc: 0.5911\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6018 - acc: 0.7008 - val_loss: 0.6820 - val_acc: 0.6046\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5975 - acc: 0.7057 - val_loss: 0.6781 - val_acc: 0.6078\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5977 - acc: 0.7026 - val_loss: 0.6842 - val_acc: 0.6056\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5981 - acc: 0.7042 - val_loss: 0.6951 - val_acc: 0.5963\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5964 - acc: 0.7050 - val_loss: 0.7000 - val_acc: 0.5982\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5970 - acc: 0.7062 - val_loss: 0.6868 - val_acc: 0.6053\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5979 - acc: 0.7007 - val_loss: 0.7075 - val_acc: 0.5945\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5974 - acc: 0.7042 - val_loss: 0.6760 - val_acc: 0.6196\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5986 - acc: 0.7046 - val_loss: 0.6821 - val_acc: 0.6080\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5965 - acc: 0.7063 - val_loss: 0.6958 - val_acc: 0.5967\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6004 - acc: 0.7018 - val_loss: 0.6760 - val_acc: 0.6163\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5963 - acc: 0.7059 - val_loss: 0.7008 - val_acc: 0.5950\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5982 - acc: 0.7042 - val_loss: 0.6584 - val_acc: 0.6271\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5995 - acc: 0.7006 - val_loss: 0.7103 - val_acc: 0.5898\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5969 - acc: 0.7079 - val_loss: 0.7014 - val_acc: 0.5967\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5945 - acc: 0.7087 - val_loss: 0.7269 - val_acc: 0.5844\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5960 - acc: 0.7047 - val_loss: 0.6926 - val_acc: 0.5995\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5959 - acc: 0.7057 - val_loss: 0.6946 - val_acc: 0.5948\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5950 - acc: 0.7065 - val_loss: 0.6997 - val_acc: 0.5960\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5954 - acc: 0.7061 - val_loss: 0.6842 - val_acc: 0.6045\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5931 - acc: 0.7122 - val_loss: 0.6681 - val_acc: 0.6210\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5942 - acc: 0.7060 - val_loss: 0.6591 - val_acc: 0.6266\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5929 - acc: 0.7077 - val_loss: 0.6555 - val_acc: 0.6320\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5929 - acc: 0.7081 - val_loss: 0.6918 - val_acc: 0.6011\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5969 - acc: 0.7051 - val_loss: 0.6813 - val_acc: 0.6067\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5930 - acc: 0.7065 - val_loss: 0.6786 - val_acc: 0.6116\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5957 - acc: 0.7058 - val_loss: 0.7013 - val_acc: 0.5952\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5931 - acc: 0.7077 - val_loss: 0.6868 - val_acc: 0.6041\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5940 - acc: 0.7059 - val_loss: 0.6972 - val_acc: 0.5978\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5923 - acc: 0.7093 - val_loss: 0.6930 - val_acc: 0.6004\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5924 - acc: 0.7093 - val_loss: 0.6758 - val_acc: 0.6136\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5920 - acc: 0.7094 - val_loss: 0.6936 - val_acc: 0.6003\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5923 - acc: 0.7086 - val_loss: 0.7111 - val_acc: 0.5932\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5936 - acc: 0.7060 - val_loss: 0.7067 - val_acc: 0.5954\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6043 - acc: 0.7086 - val_loss: 0.6672 - val_acc: 0.6407\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5991 - acc: 0.7071 - val_loss: 0.6315 - val_acc: 0.6631\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5971 - acc: 0.7073 - val_loss: 0.6249 - val_acc: 0.6722\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6007 - acc: 0.6970 - val_loss: 0.6463 - val_acc: 0.6463\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5949 - acc: 0.7063 - val_loss: 0.6912 - val_acc: 0.6065\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5930 - acc: 0.7072 - val_loss: 0.6798 - val_acc: 0.6126\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5933 - acc: 0.7075 - val_loss: 0.6633 - val_acc: 0.6227\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5935 - acc: 0.7077 - val_loss: 0.6801 - val_acc: 0.6074\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5977 - acc: 0.7020 - val_loss: 0.7042 - val_acc: 0.5953\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5959 - acc: 0.7057 - val_loss: 0.6892 - val_acc: 0.6018\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5934 - acc: 0.7097 - val_loss: 0.6725 - val_acc: 0.6177\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5949 - acc: 0.7061 - val_loss: 0.6943 - val_acc: 0.5996\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5939 - acc: 0.7066 - val_loss: 0.6807 - val_acc: 0.6072\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5928 - acc: 0.7090 - val_loss: 0.6991 - val_acc: 0.5982\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5924 - acc: 0.7088 - val_loss: 0.6885 - val_acc: 0.6034\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5912 - acc: 0.7103 - val_loss: 0.6728 - val_acc: 0.6135\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5923 - acc: 0.7084 - val_loss: 0.6883 - val_acc: 0.6050\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7081 - val_loss: 0.6813 - val_acc: 0.6066\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5910 - acc: 0.7106 - val_loss: 0.6969 - val_acc: 0.5961\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5923 - acc: 0.7078 - val_loss: 0.6648 - val_acc: 0.6212\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 17us/step - loss: 0.5932 - acc: 0.7066 - val_loss: 0.7018 - val_acc: 0.5991\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5933 - acc: 0.7066 - val_loss: 0.6843 - val_acc: 0.6096\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5918 - acc: 0.7072 - val_loss: 0.7011 - val_acc: 0.5967\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5923 - acc: 0.7074 - val_loss: 0.7243 - val_acc: 0.5888\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5928 - acc: 0.7073 - val_loss: 0.7215 - val_acc: 0.5874\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5913 - acc: 0.7089 - val_loss: 0.7014 - val_acc: 0.5954\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5902 - acc: 0.7099 - val_loss: 0.7092 - val_acc: 0.5931\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5900 - acc: 0.7098 - val_loss: 0.7018 - val_acc: 0.5981\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5900 - acc: 0.7068 - val_loss: 0.6861 - val_acc: 0.6035\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5899 - acc: 0.7088 - val_loss: 0.7152 - val_acc: 0.5927\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5901 - acc: 0.7098 - val_loss: 0.7242 - val_acc: 0.5891\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5926 - acc: 0.7055 - val_loss: 0.7104 - val_acc: 0.5916\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5921 - acc: 0.7087 - val_loss: 0.7042 - val_acc: 0.5948\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5908 - acc: 0.7081 - val_loss: 0.6982 - val_acc: 0.6000\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5899 - acc: 0.7098 - val_loss: 0.7132 - val_acc: 0.5922\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5889 - acc: 0.7120 - val_loss: 0.7149 - val_acc: 0.5943\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5919 - acc: 0.7052 - val_loss: 0.7101 - val_acc: 0.5928\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5931 - acc: 0.7087 - val_loss: 0.7199 - val_acc: 0.5879\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5943 - acc: 0.7053 - val_loss: 0.7065 - val_acc: 0.5937\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5907 - acc: 0.7124 - val_loss: 0.6975 - val_acc: 0.5979\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5888 - acc: 0.7128 - val_loss: 0.7097 - val_acc: 0.5924\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5893 - acc: 0.7106 - val_loss: 0.7170 - val_acc: 0.5891\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5991 - acc: 0.7000 - val_loss: 0.7417 - val_acc: 0.5855\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5959 - acc: 0.7067 - val_loss: 0.7267 - val_acc: 0.5869\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5955 - acc: 0.7045 - val_loss: 0.7276 - val_acc: 0.5844\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5915 - acc: 0.7076 - val_loss: 0.7101 - val_acc: 0.5942\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5899 - acc: 0.7100 - val_loss: 0.7020 - val_acc: 0.5966\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5906 - acc: 0.7109 - val_loss: 0.6805 - val_acc: 0.6092\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5885 - acc: 0.7114 - val_loss: 0.7248 - val_acc: 0.5880\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5896 - acc: 0.7093 - val_loss: 0.7244 - val_acc: 0.5906\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5906 - acc: 0.7082 - val_loss: 0.7047 - val_acc: 0.5937\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5902 - acc: 0.7078 - val_loss: 0.7164 - val_acc: 0.5915\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5905 - acc: 0.7068 - val_loss: 0.6575 - val_acc: 0.6251\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5914 - acc: 0.7070 - val_loss: 0.6837 - val_acc: 0.6051\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5894 - acc: 0.7101 - val_loss: 0.6823 - val_acc: 0.6076\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5896 - acc: 0.7103 - val_loss: 0.7121 - val_acc: 0.5915\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5890 - acc: 0.7101 - val_loss: 0.6954 - val_acc: 0.5967\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5865 - acc: 0.7124 - val_loss: 0.7163 - val_acc: 0.5926\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5881 - acc: 0.7111 - val_loss: 0.7182 - val_acc: 0.5932\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5878 - acc: 0.7117 - val_loss: 0.6976 - val_acc: 0.5998\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5897 - acc: 0.7102 - val_loss: 0.6909 - val_acc: 0.5988\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5883 - acc: 0.7104 - val_loss: 0.6746 - val_acc: 0.6144\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5896 - acc: 0.7067 - val_loss: 0.6884 - val_acc: 0.6018\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5910 - acc: 0.7078 - val_loss: 0.6722 - val_acc: 0.6166\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5893 - acc: 0.7100 - val_loss: 0.7030 - val_acc: 0.5951\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5883 - acc: 0.7125 - val_loss: 0.6950 - val_acc: 0.5997\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5890 - acc: 0.7114 - val_loss: 0.6942 - val_acc: 0.6021\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5888 - acc: 0.7109 - val_loss: 0.7096 - val_acc: 0.5966\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5917 - acc: 0.7062 - val_loss: 0.6916 - val_acc: 0.6052\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5908 - acc: 0.7091 - val_loss: 0.7075 - val_acc: 0.5956\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5985 - acc: 0.7010 - val_loss: 0.7571 - val_acc: 0.5644\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5965 - acc: 0.7088 - val_loss: 0.7121 - val_acc: 0.5766\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5906 - acc: 0.7109 - val_loss: 0.6872 - val_acc: 0.6011\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5880 - acc: 0.7102 - val_loss: 0.6859 - val_acc: 0.5970\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5883 - acc: 0.7101 - val_loss: 0.7059 - val_acc: 0.5882\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5894 - acc: 0.7090 - val_loss: 0.7044 - val_acc: 0.5951\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5885 - acc: 0.7108 - val_loss: 0.7061 - val_acc: 0.5946\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5880 - acc: 0.7109 - val_loss: 0.7229 - val_acc: 0.5919\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5884 - acc: 0.7091 - val_loss: 0.6915 - val_acc: 0.6052\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5913 - acc: 0.7066 - val_loss: 0.6999 - val_acc: 0.6004\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5925 - acc: 0.7065 - val_loss: 0.6940 - val_acc: 0.5987\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5887 - acc: 0.7097 - val_loss: 0.7111 - val_acc: 0.5938\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5889 - acc: 0.7101 - val_loss: 0.7129 - val_acc: 0.5886\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5899 - acc: 0.7099 - val_loss: 0.7207 - val_acc: 0.5921\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5887 - acc: 0.7097 - val_loss: 0.7387 - val_acc: 0.5823\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5899 - acc: 0.7087 - val_loss: 0.7238 - val_acc: 0.5884\n",
      "Fold # {2}\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 3s 117us/step - loss: 8.1390 - acc: 0.5153 - val_loss: 6.7615 - val_acc: 0.5113\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 5.7514 - acc: 0.5261 - val_loss: 4.7547 - val_acc: 0.5494\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 4.0508 - acc: 0.6051 - val_loss: 3.3631 - val_acc: 0.6110\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.8781 - acc: 0.6189 - val_loss: 2.4108 - val_acc: 0.6239\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.0793 - acc: 0.6477 - val_loss: 1.7656 - val_acc: 0.6536\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.5408 - acc: 0.6788 - val_loss: 1.3374 - val_acc: 0.6675\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 1.1867 - acc: 0.6834 - val_loss: 1.0586 - val_acc: 0.6743\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.9585 - acc: 0.6898 - val_loss: 0.8839 - val_acc: 0.6731\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.8159 - acc: 0.6909 - val_loss: 0.7692 - val_acc: 0.6825\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.7295 - acc: 0.6917 - val_loss: 0.7066 - val_acc: 0.6776\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6771 - acc: 0.6918 - val_loss: 0.6735 - val_acc: 0.6707\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6482 - acc: 0.6906 - val_loss: 0.6396 - val_acc: 0.6888\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6278 - acc: 0.6927 - val_loss: 0.6281 - val_acc: 0.6797\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6190 - acc: 0.6927 - val_loss: 0.6194 - val_acc: 0.6907\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6133 - acc: 0.6950 - val_loss: 0.6191 - val_acc: 0.6886\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6115 - acc: 0.6928 - val_loss: 0.6201 - val_acc: 0.6810\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6075 - acc: 0.6955 - val_loss: 0.6180 - val_acc: 0.6801\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6051 - acc: 0.6982 - val_loss: 0.6204 - val_acc: 0.6795\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6034 - acc: 0.6982 - val_loss: 0.6141 - val_acc: 0.6822\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6037 - acc: 0.6980 - val_loss: 0.6096 - val_acc: 0.6930\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6036 - acc: 0.6989 - val_loss: 0.6147 - val_acc: 0.6848\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6035 - acc: 0.6972 - val_loss: 0.6098 - val_acc: 0.6924\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6009 - acc: 0.6977 - val_loss: 0.6118 - val_acc: 0.6863\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6032 - acc: 0.6960 - val_loss: 0.6032 - val_acc: 0.6959\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6066 - acc: 0.6912 - val_loss: 0.6832 - val_acc: 0.6092\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6130 - acc: 0.7016 - val_loss: 0.6916 - val_acc: 0.6064\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6052 - acc: 0.6993 - val_loss: 0.6541 - val_acc: 0.6367\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5992 - acc: 0.7020 - val_loss: 0.6256 - val_acc: 0.6687\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5981 - acc: 0.6995 - val_loss: 0.6381 - val_acc: 0.6586\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5969 - acc: 0.7018 - val_loss: 0.6653 - val_acc: 0.6367\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5979 - acc: 0.7016 - val_loss: 0.6252 - val_acc: 0.6654\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5981 - acc: 0.6986 - val_loss: 0.6492 - val_acc: 0.6431\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5975 - acc: 0.7011 - val_loss: 0.6341 - val_acc: 0.6583\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5977 - acc: 0.7009 - val_loss: 0.6459 - val_acc: 0.6461\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5984 - acc: 0.6981 - val_loss: 0.6080 - val_acc: 0.6954\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6005 - acc: 0.6989 - val_loss: 0.6309 - val_acc: 0.6628\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5965 - acc: 0.7016 - val_loss: 0.7137 - val_acc: 0.5882\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6002 - acc: 0.7059 - val_loss: 0.7667 - val_acc: 0.5657\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5966 - acc: 0.7038 - val_loss: 0.7031 - val_acc: 0.5946\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5947 - acc: 0.7048 - val_loss: 0.6759 - val_acc: 0.6128\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5925 - acc: 0.7052 - val_loss: 0.6300 - val_acc: 0.6641\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5948 - acc: 0.7042 - val_loss: 0.6314 - val_acc: 0.6616\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5932 - acc: 0.7036 - val_loss: 0.6541 - val_acc: 0.6421\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5909 - acc: 0.7064 - val_loss: 0.6471 - val_acc: 0.6477\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5913 - acc: 0.7073 - val_loss: 0.6567 - val_acc: 0.6352\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5920 - acc: 0.7060 - val_loss: 0.6548 - val_acc: 0.6432\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5928 - acc: 0.7051 - val_loss: 0.6763 - val_acc: 0.6240\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5932 - acc: 0.7049 - val_loss: 0.6368 - val_acc: 0.6612\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5916 - acc: 0.7048 - val_loss: 0.6628 - val_acc: 0.6316\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5927 - acc: 0.7028 - val_loss: 0.6695 - val_acc: 0.6312\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5928 - acc: 0.7046 - val_loss: 0.6594 - val_acc: 0.6452\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5921 - acc: 0.7055 - val_loss: 0.8072 - val_acc: 0.5620\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6064 - acc: 0.7063 - val_loss: 0.8500 - val_acc: 0.5504\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5990 - acc: 0.7062 - val_loss: 0.7351 - val_acc: 0.5809\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5951 - acc: 0.7055 - val_loss: 0.7439 - val_acc: 0.5814\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5915 - acc: 0.7083 - val_loss: 0.7056 - val_acc: 0.5987\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5900 - acc: 0.7087 - val_loss: 0.7352 - val_acc: 0.5843\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5919 - acc: 0.7036 - val_loss: 0.7188 - val_acc: 0.5926\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5932 - acc: 0.7048 - val_loss: 0.7364 - val_acc: 0.5883\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5910 - acc: 0.7047 - val_loss: 0.7069 - val_acc: 0.6066\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5899 - acc: 0.7088 - val_loss: 0.6745 - val_acc: 0.6330\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5886 - acc: 0.7103 - val_loss: 0.6745 - val_acc: 0.6292\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5904 - acc: 0.7061 - val_loss: 0.6463 - val_acc: 0.6499\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5894 - acc: 0.7088 - val_loss: 0.6801 - val_acc: 0.6244\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5894 - acc: 0.7076 - val_loss: 0.6906 - val_acc: 0.6131\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5877 - acc: 0.7086 - val_loss: 0.6820 - val_acc: 0.6130\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5881 - acc: 0.7094 - val_loss: 0.7124 - val_acc: 0.5969\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5859 - acc: 0.7099 - val_loss: 0.7148 - val_acc: 0.6003\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 16us/step - loss: 0.5902 - acc: 0.7068 - val_loss: 0.7281 - val_acc: 0.5965\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5890 - acc: 0.7096 - val_loss: 0.6762 - val_acc: 0.6236\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5859 - acc: 0.7114 - val_loss: 0.7041 - val_acc: 0.6092\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5857 - acc: 0.7109 - val_loss: 0.7278 - val_acc: 0.5895\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5883 - acc: 0.7071 - val_loss: 0.7255 - val_acc: 0.5879\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5858 - acc: 0.7116 - val_loss: 0.7360 - val_acc: 0.5910\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5864 - acc: 0.7102 - val_loss: 0.6978 - val_acc: 0.6127\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5872 - acc: 0.7108 - val_loss: 0.7664 - val_acc: 0.5735\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5886 - acc: 0.7098 - val_loss: 0.8026 - val_acc: 0.5650\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5896 - acc: 0.7114 - val_loss: 0.7947 - val_acc: 0.5699\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5863 - acc: 0.7098 - val_loss: 0.7324 - val_acc: 0.5914\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5853 - acc: 0.7093 - val_loss: 0.7448 - val_acc: 0.5890\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5844 - acc: 0.7115 - val_loss: 0.7883 - val_acc: 0.5711\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5869 - acc: 0.7086 - val_loss: 0.7215 - val_acc: 0.5927\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5825 - acc: 0.7131 - val_loss: 0.7780 - val_acc: 0.5804\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5869 - acc: 0.7097 - val_loss: 0.7569 - val_acc: 0.5829\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5859 - acc: 0.7128 - val_loss: 0.7547 - val_acc: 0.5812\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5858 - acc: 0.7108 - val_loss: 0.7715 - val_acc: 0.5782\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5822 - acc: 0.7158 - val_loss: 0.7581 - val_acc: 0.5776\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5836 - acc: 0.7131 - val_loss: 0.7284 - val_acc: 0.5945\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5855 - acc: 0.7133 - val_loss: 0.8565 - val_acc: 0.5544\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5869 - acc: 0.7098 - val_loss: 0.8237 - val_acc: 0.5655\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5866 - acc: 0.7111 - val_loss: 0.8204 - val_acc: 0.5633\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5861 - acc: 0.7090 - val_loss: 0.7976 - val_acc: 0.5735\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5830 - acc: 0.7143 - val_loss: 0.7714 - val_acc: 0.5791\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5827 - acc: 0.7123 - val_loss: 0.7676 - val_acc: 0.5871\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5845 - acc: 0.7163 - val_loss: 0.8394 - val_acc: 0.5608\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5835 - acc: 0.7171 - val_loss: 0.7499 - val_acc: 0.5929\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5816 - acc: 0.7164 - val_loss: 0.8190 - val_acc: 0.5655\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5831 - acc: 0.7119 - val_loss: 0.8260 - val_acc: 0.5659\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5840 - acc: 0.7128 - val_loss: 0.8315 - val_acc: 0.5631\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5860 - acc: 0.7108 - val_loss: 0.8981 - val_acc: 0.5504\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6198 - acc: 0.7120 - val_loss: 0.9483 - val_acc: 0.5407\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5997 - acc: 0.7167 - val_loss: 0.9098 - val_acc: 0.5477\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5899 - acc: 0.7124 - val_loss: 0.8865 - val_acc: 0.5506\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5842 - acc: 0.7154 - val_loss: 0.8617 - val_acc: 0.5572\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5819 - acc: 0.7155 - val_loss: 0.8448 - val_acc: 0.5625\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5789 - acc: 0.7170 - val_loss: 0.8429 - val_acc: 0.5602\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5813 - acc: 0.7156 - val_loss: 0.8218 - val_acc: 0.5662\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5838 - acc: 0.7101 - val_loss: 0.8411 - val_acc: 0.5551\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5802 - acc: 0.7168 - val_loss: 0.8102 - val_acc: 0.5671\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5805 - acc: 0.7136 - val_loss: 0.8295 - val_acc: 0.5630\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5816 - acc: 0.7143 - val_loss: 0.8622 - val_acc: 0.5571\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5812 - acc: 0.7169 - val_loss: 0.8750 - val_acc: 0.5525\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5809 - acc: 0.7156 - val_loss: 0.8395 - val_acc: 0.5623\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5795 - acc: 0.7164 - val_loss: 0.8210 - val_acc: 0.5666\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5830 - acc: 0.7132 - val_loss: 0.7999 - val_acc: 0.5764\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5845 - acc: 0.7126 - val_loss: 0.8045 - val_acc: 0.5731\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5825 - acc: 0.7144 - val_loss: 0.7728 - val_acc: 0.5797\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5803 - acc: 0.7148 - val_loss: 0.8177 - val_acc: 0.5674\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5772 - acc: 0.7196 - val_loss: 0.8186 - val_acc: 0.5659\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5796 - acc: 0.7140 - val_loss: 0.8000 - val_acc: 0.5744\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5822 - acc: 0.7145 - val_loss: 0.7783 - val_acc: 0.5837\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5780 - acc: 0.7180 - val_loss: 0.8196 - val_acc: 0.5696\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5816 - acc: 0.7137 - val_loss: 0.8353 - val_acc: 0.5635\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5828 - acc: 0.7114 - val_loss: 0.8291 - val_acc: 0.5658\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5783 - acc: 0.7151 - val_loss: 0.8342 - val_acc: 0.5645\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5784 - acc: 0.7192 - val_loss: 0.8044 - val_acc: 0.5704\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5775 - acc: 0.7161 - val_loss: 0.8395 - val_acc: 0.5600\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5788 - acc: 0.7167 - val_loss: 0.8231 - val_acc: 0.5659\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5768 - acc: 0.7189 - val_loss: 0.8250 - val_acc: 0.5653\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5778 - acc: 0.7173 - val_loss: 0.8293 - val_acc: 0.5680\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5801 - acc: 0.7147 - val_loss: 0.8172 - val_acc: 0.5673\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5782 - acc: 0.7188 - val_loss: 0.8475 - val_acc: 0.5643\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5764 - acc: 0.7202 - val_loss: 0.8279 - val_acc: 0.5688\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5830 - acc: 0.7121 - val_loss: 0.8090 - val_acc: 0.5710\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5810 - acc: 0.7167 - val_loss: 0.8064 - val_acc: 0.5735\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5798 - acc: 0.7159 - val_loss: 0.8537 - val_acc: 0.5610\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5768 - acc: 0.7183 - val_loss: 0.8505 - val_acc: 0.5574\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5785 - acc: 0.7181 - val_loss: 0.8364 - val_acc: 0.5652\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5780 - acc: 0.7170 - val_loss: 0.8581 - val_acc: 0.5591\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5760 - acc: 0.7175 - val_loss: 0.8454 - val_acc: 0.5641\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5745 - acc: 0.7200 - val_loss: 0.8350 - val_acc: 0.5646\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5790 - acc: 0.7170 - val_loss: 0.8374 - val_acc: 0.5639\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5781 - acc: 0.7175 - val_loss: 0.8349 - val_acc: 0.5653\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5766 - acc: 0.7190 - val_loss: 0.8521 - val_acc: 0.5617\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5753 - acc: 0.7191 - val_loss: 0.8463 - val_acc: 0.5644\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5764 - acc: 0.7191 - val_loss: 0.8410 - val_acc: 0.5657\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5767 - acc: 0.7174 - val_loss: 0.8381 - val_acc: 0.5660\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5752 - acc: 0.7201 - val_loss: 0.8709 - val_acc: 0.5571\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5817 - acc: 0.7173 - val_loss: 0.8667 - val_acc: 0.5600\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5777 - acc: 0.7172 - val_loss: 0.9051 - val_acc: 0.5487\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5844 - acc: 0.7199 - val_loss: 0.9208 - val_acc: 0.5461\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5813 - acc: 0.7197 - val_loss: 0.9217 - val_acc: 0.5474\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5821 - acc: 0.7138 - val_loss: 0.8971 - val_acc: 0.5536\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5823 - acc: 0.7150 - val_loss: 0.9009 - val_acc: 0.5518\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5778 - acc: 0.7194 - val_loss: 0.8863 - val_acc: 0.5552\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5767 - acc: 0.7178 - val_loss: 0.8722 - val_acc: 0.5600\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5759 - acc: 0.7200 - val_loss: 0.8560 - val_acc: 0.5626\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5757 - acc: 0.7187 - val_loss: 0.8648 - val_acc: 0.5588\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5755 - acc: 0.7193 - val_loss: 0.9035 - val_acc: 0.5522\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5800 - acc: 0.7192 - val_loss: 0.8997 - val_acc: 0.5527\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5754 - acc: 0.7216 - val_loss: 0.8773 - val_acc: 0.5604\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5737 - acc: 0.7190 - val_loss: 0.8689 - val_acc: 0.5614\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5761 - acc: 0.7193 - val_loss: 0.8768 - val_acc: 0.5569\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5745 - acc: 0.7198 - val_loss: 0.8654 - val_acc: 0.5621\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5784 - acc: 0.7141 - val_loss: 0.8660 - val_acc: 0.5592\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5724 - acc: 0.7237 - val_loss: 0.8727 - val_acc: 0.5568\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5732 - acc: 0.7243 - val_loss: 0.8703 - val_acc: 0.5602\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5791 - acc: 0.7130 - val_loss: 0.8187 - val_acc: 0.5723\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5858 - acc: 0.7152 - val_loss: 0.8781 - val_acc: 0.5525\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5793 - acc: 0.7166 - val_loss: 0.8692 - val_acc: 0.5618\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5749 - acc: 0.7208 - val_loss: 0.8322 - val_acc: 0.5705\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5740 - acc: 0.7209 - val_loss: 0.9022 - val_acc: 0.5499\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5833 - acc: 0.7142 - val_loss: 0.9051 - val_acc: 0.5495\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5773 - acc: 0.7174 - val_loss: 0.8827 - val_acc: 0.5547\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5754 - acc: 0.7181 - val_loss: 0.8785 - val_acc: 0.5562\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5736 - acc: 0.7178 - val_loss: 0.8504 - val_acc: 0.5670\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5728 - acc: 0.7212 - val_loss: 0.8685 - val_acc: 0.5597\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7163 - val_loss: 0.8616 - val_acc: 0.5620\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5728 - acc: 0.7205 - val_loss: 0.8788 - val_acc: 0.5571\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5722 - acc: 0.7192 - val_loss: 0.8790 - val_acc: 0.5582\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5737 - acc: 0.7208 - val_loss: 0.8819 - val_acc: 0.5569\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5703 - acc: 0.7242 - val_loss: 0.8712 - val_acc: 0.5574\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5697 - acc: 0.7234 - val_loss: 0.8666 - val_acc: 0.5625\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5755 - acc: 0.7209 - val_loss: 0.8682 - val_acc: 0.5631\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5727 - acc: 0.7205 - val_loss: 0.8575 - val_acc: 0.5660\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5710 - acc: 0.7230 - val_loss: 0.8836 - val_acc: 0.5564\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5728 - acc: 0.7213 - val_loss: 0.8585 - val_acc: 0.5622\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5717 - acc: 0.7225 - val_loss: 0.8749 - val_acc: 0.5576\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5721 - acc: 0.7217 - val_loss: 0.9325 - val_acc: 0.5465\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5853 - acc: 0.7205 - val_loss: 0.9437 - val_acc: 0.5441\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5753 - acc: 0.7222 - val_loss: 0.9312 - val_acc: 0.5477\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5719 - acc: 0.7230 - val_loss: 0.9275 - val_acc: 0.5474\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5687 - acc: 0.7251 - val_loss: 0.9178 - val_acc: 0.5505\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5725 - acc: 0.7215 - val_loss: 0.9222 - val_acc: 0.5488\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5738 - acc: 0.7207 - val_loss: 0.9150 - val_acc: 0.5515\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5761 - acc: 0.7203 - val_loss: 0.9181 - val_acc: 0.5499\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5756 - acc: 0.7204 - val_loss: 0.9086 - val_acc: 0.5503\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5727 - acc: 0.7223 - val_loss: 0.8954 - val_acc: 0.5558\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5717 - acc: 0.7233 - val_loss: 0.9022 - val_acc: 0.5541\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5870 - acc: 0.7223 - val_loss: 0.9735 - val_acc: 0.5419\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5842 - acc: 0.7240 - val_loss: 0.9589 - val_acc: 0.5423\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5781 - acc: 0.7212 - val_loss: 0.9431 - val_acc: 0.5452\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5737 - acc: 0.7227 - val_loss: 0.9377 - val_acc: 0.5464\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5734 - acc: 0.7205 - val_loss: 0.9321 - val_acc: 0.5473\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5743 - acc: 0.7192 - val_loss: 0.9241 - val_acc: 0.5502\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5715 - acc: 0.7225 - val_loss: 0.9258 - val_acc: 0.5500\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5720 - acc: 0.7221 - val_loss: 0.9231 - val_acc: 0.5506\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5705 - acc: 0.7230 - val_loss: 0.9238 - val_acc: 0.5494\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5723 - acc: 0.7189 - val_loss: 0.9119 - val_acc: 0.5530\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5691 - acc: 0.7241 - val_loss: 0.9163 - val_acc: 0.5506\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5690 - acc: 0.7240 - val_loss: 0.9199 - val_acc: 0.5515\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5705 - acc: 0.7228 - val_loss: 0.9209 - val_acc: 0.5476\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5727 - acc: 0.7195 - val_loss: 0.9019 - val_acc: 0.5531\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5737 - acc: 0.7239 - val_loss: 0.9027 - val_acc: 0.5527\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5700 - acc: 0.7233 - val_loss: 0.8863 - val_acc: 0.5583\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5710 - acc: 0.7221 - val_loss: 0.9036 - val_acc: 0.5522\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5700 - acc: 0.7202 - val_loss: 0.8924 - val_acc: 0.5592\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5708 - acc: 0.7232 - val_loss: 0.9060 - val_acc: 0.5542\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5702 - acc: 0.7208 - val_loss: 0.8852 - val_acc: 0.5600\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5690 - acc: 0.7239 - val_loss: 0.8925 - val_acc: 0.5552\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5706 - acc: 0.7212 - val_loss: 0.8981 - val_acc: 0.5573\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5714 - acc: 0.7213 - val_loss: 0.8784 - val_acc: 0.5591\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5729 - acc: 0.7195 - val_loss: 0.8746 - val_acc: 0.5607\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5687 - acc: 0.7237 - val_loss: 0.8845 - val_acc: 0.5584\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5722 - acc: 0.7223 - val_loss: 0.9314 - val_acc: 0.5465\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5701 - acc: 0.7252 - val_loss: 0.9251 - val_acc: 0.5463\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5673 - acc: 0.7258 - val_loss: 0.9198 - val_acc: 0.5498\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5737 - acc: 0.7222 - val_loss: 0.8981 - val_acc: 0.5556\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5706 - acc: 0.7237 - val_loss: 0.9206 - val_acc: 0.5495\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5701 - acc: 0.7237 - val_loss: 0.9082 - val_acc: 0.5532\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5698 - acc: 0.7233 - val_loss: 0.8964 - val_acc: 0.5550\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5710 - acc: 0.7212 - val_loss: 0.8909 - val_acc: 0.5573\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5734 - acc: 0.7165 - val_loss: 0.8876 - val_acc: 0.5582\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5674 - acc: 0.7246 - val_loss: 0.9016 - val_acc: 0.5548\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5654 - acc: 0.7269 - val_loss: 0.8922 - val_acc: 0.5564\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5670 - acc: 0.7254 - val_loss: 0.8873 - val_acc: 0.5588\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5671 - acc: 0.7268 - val_loss: 0.9032 - val_acc: 0.5545\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5681 - acc: 0.7239 - val_loss: 0.9011 - val_acc: 0.5560\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5677 - acc: 0.7246 - val_loss: 0.9011 - val_acc: 0.5558\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5658 - acc: 0.7280 - val_loss: 0.9001 - val_acc: 0.5559\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5689 - acc: 0.7223 - val_loss: 0.9023 - val_acc: 0.5513\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5688 - acc: 0.7256 - val_loss: 0.8997 - val_acc: 0.5544\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5677 - acc: 0.7234 - val_loss: 0.8980 - val_acc: 0.5546\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5664 - acc: 0.7238 - val_loss: 0.8836 - val_acc: 0.5587\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5708 - acc: 0.7200 - val_loss: 0.8880 - val_acc: 0.5592\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5680 - acc: 0.7237 - val_loss: 0.9017 - val_acc: 0.5520\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5660 - acc: 0.7261 - val_loss: 0.8972 - val_acc: 0.5562\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5712 - acc: 0.7202 - val_loss: 0.8888 - val_acc: 0.5577\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5722 - acc: 0.7208 - val_loss: 0.9266 - val_acc: 0.5480\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5691 - acc: 0.7263 - val_loss: 0.9190 - val_acc: 0.5491\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5652 - acc: 0.7268 - val_loss: 0.9118 - val_acc: 0.5530\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5722 - acc: 0.7198 - val_loss: 0.8957 - val_acc: 0.5561\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5696 - acc: 0.7192 - val_loss: 0.9025 - val_acc: 0.5536\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5664 - acc: 0.7239 - val_loss: 0.9190 - val_acc: 0.5509\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5723 - acc: 0.7213 - val_loss: 0.8995 - val_acc: 0.5563\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5707 - acc: 0.7230 - val_loss: 0.9002 - val_acc: 0.5525\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5675 - acc: 0.7241 - val_loss: 0.8869 - val_acc: 0.5567\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5674 - acc: 0.7243 - val_loss: 0.9061 - val_acc: 0.5550\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5743 - acc: 0.7235 - val_loss: 0.8901 - val_acc: 0.5553\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5689 - acc: 0.7222 - val_loss: 0.8987 - val_acc: 0.5545\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5728 - acc: 0.7214 - val_loss: 0.8888 - val_acc: 0.5590\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5659 - acc: 0.7253 - val_loss: 0.8646 - val_acc: 0.5628\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5698 - acc: 0.7205 - val_loss: 0.8851 - val_acc: 0.5559\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5664 - acc: 0.7269 - val_loss: 0.8954 - val_acc: 0.5560\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5661 - acc: 0.7274 - val_loss: 0.8908 - val_acc: 0.5573\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5648 - acc: 0.7286 - val_loss: 0.8965 - val_acc: 0.5554\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5642 - acc: 0.7296 - val_loss: 0.9049 - val_acc: 0.5510\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5640 - acc: 0.7265 - val_loss: 0.9035 - val_acc: 0.5557\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5662 - acc: 0.7254 - val_loss: 0.9079 - val_acc: 0.5549\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5705 - acc: 0.7225 - val_loss: 0.9085 - val_acc: 0.5528\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5701 - acc: 0.7197 - val_loss: 0.9051 - val_acc: 0.5561\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5635 - acc: 0.7254 - val_loss: 0.9022 - val_acc: 0.5554\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5652 - acc: 0.7271 - val_loss: 0.9093 - val_acc: 0.5546\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5639 - acc: 0.7255 - val_loss: 0.9079 - val_acc: 0.5552\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5656 - acc: 0.7244 - val_loss: 0.9047 - val_acc: 0.5564\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5709 - acc: 0.7217 - val_loss: 0.8905 - val_acc: 0.5593\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5646 - acc: 0.7264 - val_loss: 0.9002 - val_acc: 0.5579\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5631 - acc: 0.7274 - val_loss: 0.9099 - val_acc: 0.5546\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5649 - acc: 0.7286 - val_loss: 0.9047 - val_acc: 0.5568\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5638 - acc: 0.7271 - val_loss: 0.9024 - val_acc: 0.5575\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5674 - acc: 0.7263 - val_loss: 0.9191 - val_acc: 0.5488\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5677 - acc: 0.7301 - val_loss: 0.9078 - val_acc: 0.5511\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5629 - acc: 0.7267 - val_loss: 0.8939 - val_acc: 0.5582\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5654 - acc: 0.7253 - val_loss: 0.9111 - val_acc: 0.5526\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5700 - acc: 0.7224 - val_loss: 0.8878 - val_acc: 0.5572\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5708 - acc: 0.7219 - val_loss: 0.8974 - val_acc: 0.5578\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5637 - acc: 0.7295 - val_loss: 0.8886 - val_acc: 0.5547\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5699 - acc: 0.7238 - val_loss: 0.9064 - val_acc: 0.5534\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5704 - acc: 0.7204 - val_loss: 0.9019 - val_acc: 0.5589\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5637 - acc: 0.7264 - val_loss: 0.9061 - val_acc: 0.5549\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5625 - acc: 0.7281 - val_loss: 0.9120 - val_acc: 0.5535\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5652 - acc: 0.7259 - val_loss: 0.9063 - val_acc: 0.5550\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5668 - acc: 0.7244 - val_loss: 0.8989 - val_acc: 0.5575\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5617 - acc: 0.7283 - val_loss: 0.8949 - val_acc: 0.5596\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5638 - acc: 0.7265 - val_loss: 0.9060 - val_acc: 0.5528\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5624 - acc: 0.7286 - val_loss: 0.9192 - val_acc: 0.5548\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5630 - acc: 0.7295 - val_loss: 0.9152 - val_acc: 0.5550\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5644 - acc: 0.7245 - val_loss: 0.9062 - val_acc: 0.5573\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5632 - acc: 0.7263 - val_loss: 0.9227 - val_acc: 0.5535\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5660 - acc: 0.7267 - val_loss: 0.9141 - val_acc: 0.5534\n",
      "Fold # {3}\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 2s 113us/step - loss: 7.9700 - acc: 0.5155 - val_loss: 6.6092 - val_acc: 0.5120\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 8us/step - loss: 5.6178 - acc: 0.5148 - val_loss: 4.6430 - val_acc: 0.5090\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 3.9545 - acc: 0.5285 - val_loss: 3.2828 - val_acc: 0.5637\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.8148 - acc: 0.5722 - val_loss: 2.3604 - val_acc: 0.5949\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.0470 - acc: 0.5956 - val_loss: 1.7444 - val_acc: 0.6085\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 1.5362 - acc: 0.6164 - val_loss: 1.3384 - val_acc: 0.6237\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.1983 - acc: 0.6472 - val_loss: 1.0722 - val_acc: 0.6328\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.9779 - acc: 0.6706 - val_loss: 0.9051 - val_acc: 0.6461\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.8379 - acc: 0.6784 - val_loss: 0.7930 - val_acc: 0.6704\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.7500 - acc: 0.6840 - val_loss: 0.7232 - val_acc: 0.6690\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6978 - acc: 0.6829 - val_loss: 0.6879 - val_acc: 0.6637\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6652 - acc: 0.6867 - val_loss: 0.6590 - val_acc: 0.6816\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6466 - acc: 0.6864 - val_loss: 0.6447 - val_acc: 0.6799\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6346 - acc: 0.6894 - val_loss: 0.6483 - val_acc: 0.6577\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6268 - acc: 0.6915 - val_loss: 0.6429 - val_acc: 0.6553\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6242 - acc: 0.6902 - val_loss: 0.6337 - val_acc: 0.6638\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6222 - acc: 0.6887 - val_loss: 0.6340 - val_acc: 0.6629\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6183 - acc: 0.6916 - val_loss: 0.6309 - val_acc: 0.6696\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6237 - acc: 0.6917 - val_loss: 0.7407 - val_acc: 0.5484\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6232 - acc: 0.6957 - val_loss: 0.7184 - val_acc: 0.5640\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6174 - acc: 0.6924 - val_loss: 0.7000 - val_acc: 0.5793\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6172 - acc: 0.6882 - val_loss: 0.6768 - val_acc: 0.6056\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6131 - acc: 0.6929 - val_loss: 0.6498 - val_acc: 0.6394\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6144 - acc: 0.6924 - val_loss: 0.6525 - val_acc: 0.6389\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6123 - acc: 0.6945 - val_loss: 0.6353 - val_acc: 0.6614\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6162 - acc: 0.6905 - val_loss: 0.6595 - val_acc: 0.6323\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6116 - acc: 0.6948 - val_loss: 0.6410 - val_acc: 0.6526\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6072 - acc: 0.6971 - val_loss: 0.6676 - val_acc: 0.6189\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6059 - acc: 0.7004 - val_loss: 0.6447 - val_acc: 0.6465\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6095 - acc: 0.6960 - val_loss: 0.6471 - val_acc: 0.6394\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6111 - acc: 0.6938 - val_loss: 0.6681 - val_acc: 0.6209\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6083 - acc: 0.6955 - val_loss: 0.6779 - val_acc: 0.6151\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6109 - acc: 0.6911 - val_loss: 0.6859 - val_acc: 0.6042\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6073 - acc: 0.6992 - val_loss: 0.7298 - val_acc: 0.5735\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6138 - acc: 0.6958 - val_loss: 0.7359 - val_acc: 0.5703\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6119 - acc: 0.6930 - val_loss: 0.7033 - val_acc: 0.5964\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6072 - acc: 0.6991 - val_loss: 0.6636 - val_acc: 0.6308\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6072 - acc: 0.6954 - val_loss: 0.6701 - val_acc: 0.6230\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6037 - acc: 0.6996 - val_loss: 0.7116 - val_acc: 0.5760\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6001 - acc: 0.7055 - val_loss: 0.6630 - val_acc: 0.6165\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6031 - acc: 0.6999 - val_loss: 0.7266 - val_acc: 0.5703\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6015 - acc: 0.7010 - val_loss: 0.7050 - val_acc: 0.5835\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6018 - acc: 0.7004 - val_loss: 0.7138 - val_acc: 0.5952\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6055 - acc: 0.6965 - val_loss: 0.7209 - val_acc: 0.5723\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6040 - acc: 0.6989 - val_loss: 0.6947 - val_acc: 0.6049\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6041 - acc: 0.6978 - val_loss: 0.7240 - val_acc: 0.5867\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6145 - acc: 0.6884 - val_loss: 0.6352 - val_acc: 0.6576\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6062 - acc: 0.6973 - val_loss: 0.7066 - val_acc: 0.5839\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.6027 - acc: 0.6991 - val_loss: 0.6934 - val_acc: 0.6027\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6011 - acc: 0.7019 - val_loss: 0.6971 - val_acc: 0.5960\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6012 - acc: 0.7026 - val_loss: 0.7395 - val_acc: 0.5644\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6063 - acc: 0.6951 - val_loss: 0.7150 - val_acc: 0.5850\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6013 - acc: 0.7010 - val_loss: 0.6878 - val_acc: 0.5963\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5996 - acc: 0.7038 - val_loss: 0.6708 - val_acc: 0.6196\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5977 - acc: 0.7041 - val_loss: 0.7689 - val_acc: 0.5520\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5983 - acc: 0.7046 - val_loss: 0.7063 - val_acc: 0.5872\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6005 - acc: 0.7030 - val_loss: 0.7204 - val_acc: 0.5760\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6018 - acc: 0.6993 - val_loss: 0.7018 - val_acc: 0.5941\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6026 - acc: 0.6991 - val_loss: 0.6878 - val_acc: 0.5966\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6007 - acc: 0.7006 - val_loss: 0.7253 - val_acc: 0.5766\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5985 - acc: 0.7036 - val_loss: 0.7146 - val_acc: 0.5886\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6037 - acc: 0.6995 - val_loss: 0.7270 - val_acc: 0.5862\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6017 - acc: 0.6999 - val_loss: 0.6767 - val_acc: 0.6176\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5982 - acc: 0.7045 - val_loss: 0.7287 - val_acc: 0.5762\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5976 - acc: 0.7047 - val_loss: 0.6716 - val_acc: 0.6236\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5978 - acc: 0.7031 - val_loss: 0.6897 - val_acc: 0.6043\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5975 - acc: 0.7068 - val_loss: 0.7198 - val_acc: 0.5856\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6019 - acc: 0.6976 - val_loss: 0.6980 - val_acc: 0.6042\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5973 - acc: 0.7054 - val_loss: 0.7456 - val_acc: 0.5650\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5995 - acc: 0.7009 - val_loss: 0.6801 - val_acc: 0.6142\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5977 - acc: 0.7052 - val_loss: 0.7155 - val_acc: 0.5839\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5979 - acc: 0.7027 - val_loss: 0.6888 - val_acc: 0.6019\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6024 - acc: 0.6979 - val_loss: 0.7097 - val_acc: 0.5893\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6000 - acc: 0.7024 - val_loss: 0.7055 - val_acc: 0.5843\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5976 - acc: 0.7047 - val_loss: 0.7127 - val_acc: 0.5823\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5969 - acc: 0.7032 - val_loss: 0.7435 - val_acc: 0.5692\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6000 - acc: 0.7029 - val_loss: 0.7223 - val_acc: 0.5785\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5984 - acc: 0.7014 - val_loss: 0.7111 - val_acc: 0.5873\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5988 - acc: 0.7021 - val_loss: 0.6878 - val_acc: 0.6068\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5965 - acc: 0.7083 - val_loss: 0.7087 - val_acc: 0.5999\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5974 - acc: 0.7026 - val_loss: 0.7662 - val_acc: 0.5609\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5988 - acc: 0.7048 - val_loss: 0.7537 - val_acc: 0.5665\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5981 - acc: 0.7027 - val_loss: 0.7175 - val_acc: 0.5809\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5969 - acc: 0.7057 - val_loss: 0.6897 - val_acc: 0.6087\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5931 - acc: 0.7067 - val_loss: 0.7340 - val_acc: 0.5730\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5959 - acc: 0.7026 - val_loss: 0.7530 - val_acc: 0.5662\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5936 - acc: 0.7076 - val_loss: 0.7459 - val_acc: 0.5690\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5915 - acc: 0.7074 - val_loss: 0.7366 - val_acc: 0.5708\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5946 - acc: 0.7045 - val_loss: 0.7037 - val_acc: 0.6053\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5956 - acc: 0.7071 - val_loss: 0.7248 - val_acc: 0.5934\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5996 - acc: 0.7034 - val_loss: 0.6945 - val_acc: 0.6029\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5941 - acc: 0.7057 - val_loss: 0.7268 - val_acc: 0.5834\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5958 - acc: 0.7061 - val_loss: 0.7016 - val_acc: 0.6044\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5968 - acc: 0.7060 - val_loss: 0.7067 - val_acc: 0.5999\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5965 - acc: 0.7013 - val_loss: 0.7241 - val_acc: 0.5789\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5924 - acc: 0.7071 - val_loss: 0.7229 - val_acc: 0.5798\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5908 - acc: 0.7081 - val_loss: 0.7300 - val_acc: 0.5771\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5935 - acc: 0.7050 - val_loss: 0.7311 - val_acc: 0.5768\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5915 - acc: 0.7101 - val_loss: 0.7506 - val_acc: 0.5698\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5955 - acc: 0.7029 - val_loss: 0.7341 - val_acc: 0.5704\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5915 - acc: 0.7057 - val_loss: 0.7240 - val_acc: 0.5785\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5920 - acc: 0.7090 - val_loss: 0.7495 - val_acc: 0.5670\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5925 - acc: 0.7039 - val_loss: 0.7403 - val_acc: 0.5697\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6022 - acc: 0.7079 - val_loss: 0.8450 - val_acc: 0.5352\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6090 - acc: 0.7075 - val_loss: 0.8260 - val_acc: 0.5382\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5990 - acc: 0.7068 - val_loss: 0.8109 - val_acc: 0.5412\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5929 - acc: 0.7098 - val_loss: 0.8074 - val_acc: 0.5436\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5938 - acc: 0.7056 - val_loss: 0.7988 - val_acc: 0.5470\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5949 - acc: 0.7070 - val_loss: 0.7980 - val_acc: 0.5475\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5918 - acc: 0.7087 - val_loss: 0.7906 - val_acc: 0.5510\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5936 - acc: 0.7076 - val_loss: 0.7784 - val_acc: 0.5583\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5936 - acc: 0.7043 - val_loss: 0.7810 - val_acc: 0.5573\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5903 - acc: 0.7092 - val_loss: 0.7892 - val_acc: 0.5518\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5955 - acc: 0.7021 - val_loss: 0.7775 - val_acc: 0.5590\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5895 - acc: 0.7092 - val_loss: 0.7779 - val_acc: 0.5571\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5915 - acc: 0.7094 - val_loss: 0.8025 - val_acc: 0.5498\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6026 - acc: 0.7073 - val_loss: 0.8118 - val_acc: 0.5481\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5961 - acc: 0.7075 - val_loss: 0.8005 - val_acc: 0.5486\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5922 - acc: 0.7082 - val_loss: 0.7847 - val_acc: 0.5556\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5914 - acc: 0.7087 - val_loss: 0.7583 - val_acc: 0.5683\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5962 - acc: 0.7061 - val_loss: 0.7814 - val_acc: 0.5561\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5943 - acc: 0.7056 - val_loss: 0.7416 - val_acc: 0.5771\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5891 - acc: 0.7099 - val_loss: 0.7668 - val_acc: 0.5614\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5866 - acc: 0.7110 - val_loss: 0.7707 - val_acc: 0.5624\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5885 - acc: 0.7108 - val_loss: 0.7628 - val_acc: 0.5656\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5926 - acc: 0.7120 - val_loss: 0.8151 - val_acc: 0.5444\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5930 - acc: 0.7084 - val_loss: 0.7804 - val_acc: 0.5591\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5915 - acc: 0.7089 - val_loss: 0.7414 - val_acc: 0.5782\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5929 - acc: 0.7074 - val_loss: 0.7467 - val_acc: 0.5741\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5928 - acc: 0.7063 - val_loss: 0.7990 - val_acc: 0.5533\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5979 - acc: 0.7066 - val_loss: 0.8099 - val_acc: 0.5477\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5908 - acc: 0.7096 - val_loss: 0.7902 - val_acc: 0.5552\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5875 - acc: 0.7142 - val_loss: 0.7871 - val_acc: 0.5554\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5882 - acc: 0.7111 - val_loss: 0.7900 - val_acc: 0.5552\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5905 - acc: 0.7074 - val_loss: 0.7893 - val_acc: 0.5562\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5938 - acc: 0.7052 - val_loss: 0.7871 - val_acc: 0.5568\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5902 - acc: 0.7099 - val_loss: 0.7855 - val_acc: 0.5565\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7050 - val_loss: 0.7818 - val_acc: 0.5588\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5917 - acc: 0.7076 - val_loss: 0.7563 - val_acc: 0.5731\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5873 - acc: 0.7089 - val_loss: 0.7653 - val_acc: 0.5684\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5874 - acc: 0.7109 - val_loss: 0.8372 - val_acc: 0.5448\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6387 - acc: 0.7086 - val_loss: 0.8762 - val_acc: 0.5390\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6249 - acc: 0.7044 - val_loss: 0.8423 - val_acc: 0.5422\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5998 - acc: 0.7141 - val_loss: 0.8298 - val_acc: 0.5422\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5938 - acc: 0.7115 - val_loss: 0.8159 - val_acc: 0.5484\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5953 - acc: 0.7079 - val_loss: 0.8141 - val_acc: 0.5464\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5945 - acc: 0.7059 - val_loss: 0.7940 - val_acc: 0.5583\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5896 - acc: 0.7109 - val_loss: 0.7974 - val_acc: 0.5551\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5877 - acc: 0.7142 - val_loss: 0.7957 - val_acc: 0.5553\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5887 - acc: 0.7103 - val_loss: 0.7663 - val_acc: 0.5703\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5891 - acc: 0.7104 - val_loss: 0.7887 - val_acc: 0.5580\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5847 - acc: 0.7149 - val_loss: 0.7874 - val_acc: 0.5582\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5876 - acc: 0.7108 - val_loss: 0.7589 - val_acc: 0.5718\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5897 - acc: 0.7099 - val_loss: 0.7615 - val_acc: 0.5705\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5865 - acc: 0.7145 - val_loss: 0.7820 - val_acc: 0.5594\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5872 - acc: 0.7135 - val_loss: 0.7757 - val_acc: 0.5636\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5842 - acc: 0.7127 - val_loss: 0.7778 - val_acc: 0.5619\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5849 - acc: 0.7155 - val_loss: 0.7783 - val_acc: 0.5639\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5877 - acc: 0.7137 - val_loss: 0.7826 - val_acc: 0.5610\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5872 - acc: 0.7102 - val_loss: 0.7773 - val_acc: 0.5621\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5859 - acc: 0.7113 - val_loss: 0.7651 - val_acc: 0.5688\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5856 - acc: 0.7115 - val_loss: 0.7773 - val_acc: 0.5640\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5854 - acc: 0.7136 - val_loss: 0.7781 - val_acc: 0.5652\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5836 - acc: 0.7141 - val_loss: 0.8132 - val_acc: 0.5487\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5931 - acc: 0.7113 - val_loss: 0.8140 - val_acc: 0.5489\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5892 - acc: 0.7106 - val_loss: 0.8001 - val_acc: 0.5529\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5860 - acc: 0.7132 - val_loss: 0.7910 - val_acc: 0.5567\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5835 - acc: 0.7168 - val_loss: 0.7974 - val_acc: 0.5540\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5858 - acc: 0.7106 - val_loss: 0.7919 - val_acc: 0.5591\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5843 - acc: 0.7129 - val_loss: 0.7936 - val_acc: 0.5544\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5869 - acc: 0.7096 - val_loss: 0.7736 - val_acc: 0.5664\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5847 - acc: 0.7131 - val_loss: 0.7827 - val_acc: 0.5629\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5849 - acc: 0.7129 - val_loss: 0.7941 - val_acc: 0.5569\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5842 - acc: 0.7139 - val_loss: 0.7869 - val_acc: 0.5594\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5831 - acc: 0.7131 - val_loss: 0.7730 - val_acc: 0.5668\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5839 - acc: 0.7156 - val_loss: 0.7901 - val_acc: 0.5584\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5840 - acc: 0.7136 - val_loss: 0.7768 - val_acc: 0.5656\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5837 - acc: 0.7120 - val_loss: 0.7713 - val_acc: 0.5691\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5842 - acc: 0.7130 - val_loss: 0.7837 - val_acc: 0.5619\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5840 - acc: 0.7130 - val_loss: 0.7867 - val_acc: 0.5613\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5840 - acc: 0.7141 - val_loss: 0.8105 - val_acc: 0.5512\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5889 - acc: 0.7174 - val_loss: 0.8309 - val_acc: 0.5433\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5875 - acc: 0.7122 - val_loss: 0.8180 - val_acc: 0.5441\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5848 - acc: 0.7154 - val_loss: 0.8127 - val_acc: 0.5487\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5899 - acc: 0.7095 - val_loss: 0.8044 - val_acc: 0.5526\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5876 - acc: 0.7123 - val_loss: 0.7963 - val_acc: 0.5578\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5860 - acc: 0.7137 - val_loss: 0.7976 - val_acc: 0.5550\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5851 - acc: 0.7129 - val_loss: 0.8052 - val_acc: 0.5520\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5837 - acc: 0.7131 - val_loss: 0.7996 - val_acc: 0.5554\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5813 - acc: 0.7164 - val_loss: 0.7927 - val_acc: 0.5580\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5827 - acc: 0.7149 - val_loss: 0.7965 - val_acc: 0.5540\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5816 - acc: 0.7155 - val_loss: 0.7949 - val_acc: 0.5529\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5882 - acc: 0.7116 - val_loss: 0.7834 - val_acc: 0.5606\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5817 - acc: 0.7159 - val_loss: 0.7927 - val_acc: 0.5580\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5827 - acc: 0.7151 - val_loss: 0.7828 - val_acc: 0.5622\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5805 - acc: 0.7148 - val_loss: 0.7811 - val_acc: 0.5646\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5898 - acc: 0.7159 - val_loss: 0.8752 - val_acc: 0.5375\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6173 - acc: 0.7155 - val_loss: 0.8713 - val_acc: 0.5367\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6037 - acc: 0.7138 - val_loss: 0.8542 - val_acc: 0.5376\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5940 - acc: 0.7155 - val_loss: 0.8397 - val_acc: 0.5438\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5903 - acc: 0.7151 - val_loss: 0.8274 - val_acc: 0.5494\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5886 - acc: 0.7142 - val_loss: 0.8234 - val_acc: 0.5480\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5840 - acc: 0.7156 - val_loss: 0.8212 - val_acc: 0.5467\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5849 - acc: 0.7137 - val_loss: 0.8143 - val_acc: 0.5486\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5843 - acc: 0.7170 - val_loss: 0.8056 - val_acc: 0.5549\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5842 - acc: 0.7148 - val_loss: 0.8007 - val_acc: 0.5590\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5878 - acc: 0.7115 - val_loss: 0.8019 - val_acc: 0.5561\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5844 - acc: 0.7130 - val_loss: 0.7891 - val_acc: 0.5610\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5873 - acc: 0.7091 - val_loss: 0.7945 - val_acc: 0.5577\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5852 - acc: 0.7113 - val_loss: 0.7972 - val_acc: 0.5569\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5816 - acc: 0.7146 - val_loss: 0.7822 - val_acc: 0.5642\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5808 - acc: 0.7168 - val_loss: 0.7928 - val_acc: 0.5588\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5802 - acc: 0.7165 - val_loss: 0.7672 - val_acc: 0.5708\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5811 - acc: 0.7166 - val_loss: 0.7835 - val_acc: 0.5637\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5808 - acc: 0.7166 - val_loss: 0.7957 - val_acc: 0.5575\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5808 - acc: 0.7151 - val_loss: 0.7957 - val_acc: 0.5585\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5810 - acc: 0.7141 - val_loss: 0.7773 - val_acc: 0.5689\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5844 - acc: 0.7118 - val_loss: 0.7809 - val_acc: 0.5657\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5802 - acc: 0.7181 - val_loss: 0.7833 - val_acc: 0.5640\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5828 - acc: 0.7181 - val_loss: 0.8276 - val_acc: 0.5521\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5915 - acc: 0.7140 - val_loss: 0.8251 - val_acc: 0.5491\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5841 - acc: 0.7180 - val_loss: 0.8100 - val_acc: 0.5549\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5855 - acc: 0.7153 - val_loss: 0.8085 - val_acc: 0.5568\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5864 - acc: 0.7143 - val_loss: 0.8073 - val_acc: 0.5549\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5846 - acc: 0.7128 - val_loss: 0.8004 - val_acc: 0.5575\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5784 - acc: 0.7186 - val_loss: 0.7963 - val_acc: 0.5588\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5779 - acc: 0.7194 - val_loss: 0.8000 - val_acc: 0.5592\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5787 - acc: 0.7179 - val_loss: 0.7963 - val_acc: 0.5628\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5788 - acc: 0.7192 - val_loss: 0.7985 - val_acc: 0.5602\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5813 - acc: 0.7158 - val_loss: 0.7930 - val_acc: 0.5619\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5830 - acc: 0.7157 - val_loss: 0.8264 - val_acc: 0.5468\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5917 - acc: 0.7173 - val_loss: 0.8482 - val_acc: 0.5394\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5884 - acc: 0.7164 - val_loss: 0.8362 - val_acc: 0.5412\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5868 - acc: 0.7157 - val_loss: 0.8293 - val_acc: 0.5442\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5809 - acc: 0.7193 - val_loss: 0.8259 - val_acc: 0.5453\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5794 - acc: 0.7184 - val_loss: 0.8216 - val_acc: 0.5453\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5813 - acc: 0.7174 - val_loss: 0.8162 - val_acc: 0.5502\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5800 - acc: 0.7156 - val_loss: 0.8109 - val_acc: 0.5517\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5800 - acc: 0.7150 - val_loss: 0.8141 - val_acc: 0.5516\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5803 - acc: 0.7159 - val_loss: 0.8101 - val_acc: 0.5528\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5818 - acc: 0.7153 - val_loss: 0.8044 - val_acc: 0.5575\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5792 - acc: 0.7170 - val_loss: 0.8077 - val_acc: 0.5548\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5786 - acc: 0.7159 - val_loss: 0.8100 - val_acc: 0.5534\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5795 - acc: 0.7170 - val_loss: 0.8076 - val_acc: 0.5532\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5786 - acc: 0.7192 - val_loss: 0.8053 - val_acc: 0.5546\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 17us/step - loss: 0.5794 - acc: 0.7172 - val_loss: 0.8010 - val_acc: 0.5578\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5847 - acc: 0.7155 - val_loss: 0.8176 - val_acc: 0.5526\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5818 - acc: 0.7172 - val_loss: 0.8126 - val_acc: 0.5540\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5821 - acc: 0.7161 - val_loss: 0.8008 - val_acc: 0.5605\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5794 - acc: 0.7161 - val_loss: 0.8100 - val_acc: 0.5526\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5783 - acc: 0.7182 - val_loss: 0.8068 - val_acc: 0.5547\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5782 - acc: 0.7176 - val_loss: 0.8043 - val_acc: 0.5572\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7164 - val_loss: 0.8010 - val_acc: 0.5573\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5802 - acc: 0.7151 - val_loss: 0.8002 - val_acc: 0.5600\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7157 - val_loss: 0.7852 - val_acc: 0.5657\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5788 - acc: 0.7157 - val_loss: 0.7925 - val_acc: 0.5613\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5800 - acc: 0.7165 - val_loss: 0.7974 - val_acc: 0.5609\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 16us/step - loss: 0.5776 - acc: 0.7189 - val_loss: 0.8246 - val_acc: 0.5509\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5895 - acc: 0.7172 - val_loss: 0.8246 - val_acc: 0.5510\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5828 - acc: 0.7181 - val_loss: 0.8182 - val_acc: 0.5502\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5827 - acc: 0.7155 - val_loss: 0.8037 - val_acc: 0.5577\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5806 - acc: 0.7165 - val_loss: 0.8048 - val_acc: 0.5564\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5783 - acc: 0.7170 - val_loss: 0.8087 - val_acc: 0.5550\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5762 - acc: 0.7197 - val_loss: 0.8081 - val_acc: 0.5538\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5771 - acc: 0.7196 - val_loss: 0.8109 - val_acc: 0.5520\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5783 - acc: 0.7179 - val_loss: 0.8090 - val_acc: 0.5565\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5766 - acc: 0.7171 - val_loss: 0.8046 - val_acc: 0.5591\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5781 - acc: 0.7176 - val_loss: 0.8019 - val_acc: 0.5614\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5757 - acc: 0.7214 - val_loss: 0.7989 - val_acc: 0.5606\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7153 - val_loss: 0.8072 - val_acc: 0.5562\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5765 - acc: 0.7200 - val_loss: 0.8036 - val_acc: 0.5572\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5797 - acc: 0.7174 - val_loss: 0.8267 - val_acc: 0.5477\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5837 - acc: 0.7171 - val_loss: 0.8273 - val_acc: 0.5491\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5882 - acc: 0.7128 - val_loss: 0.8223 - val_acc: 0.5505\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5812 - acc: 0.7149 - val_loss: 0.7974 - val_acc: 0.5623\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5792 - acc: 0.7170 - val_loss: 0.7958 - val_acc: 0.5645\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5793 - acc: 0.7175 - val_loss: 0.8001 - val_acc: 0.5608\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5810 - acc: 0.7135 - val_loss: 0.7983 - val_acc: 0.5606\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5763 - acc: 0.7189 - val_loss: 0.8040 - val_acc: 0.5582\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5765 - acc: 0.7182 - val_loss: 0.8012 - val_acc: 0.5608\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5778 - acc: 0.7180 - val_loss: 0.7894 - val_acc: 0.5638\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5785 - acc: 0.7186 - val_loss: 0.8043 - val_acc: 0.5611\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5814 - acc: 0.7160 - val_loss: 0.7940 - val_acc: 0.5635\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5861 - acc: 0.7142 - val_loss: 0.8241 - val_acc: 0.5503\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5843 - acc: 0.7159 - val_loss: 0.8218 - val_acc: 0.5497\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5776 - acc: 0.7182 - val_loss: 0.8192 - val_acc: 0.5530\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5767 - acc: 0.7189 - val_loss: 0.8165 - val_acc: 0.5529\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5788 - acc: 0.7168 - val_loss: 0.8033 - val_acc: 0.5598\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5781 - acc: 0.7165 - val_loss: 0.8121 - val_acc: 0.5529\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5767 - acc: 0.7192 - val_loss: 0.8115 - val_acc: 0.5543\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5805 - acc: 0.7143 - val_loss: 0.8093 - val_acc: 0.5550\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5783 - acc: 0.7171 - val_loss: 0.8089 - val_acc: 0.5553\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5824 - acc: 0.7149 - val_loss: 0.8061 - val_acc: 0.5588\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5780 - acc: 0.7162 - val_loss: 0.7994 - val_acc: 0.5617\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5755 - acc: 0.7161 - val_loss: 0.7999 - val_acc: 0.5624\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5746 - acc: 0.7178 - val_loss: 0.8033 - val_acc: 0.5590\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5768 - acc: 0.7186 - val_loss: 0.8128 - val_acc: 0.5536\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5788 - acc: 0.7177 - val_loss: 0.8320 - val_acc: 0.5523\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5882 - acc: 0.7157 - val_loss: 0.8304 - val_acc: 0.5534\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5833 - acc: 0.7206 - val_loss: 0.8196 - val_acc: 0.5568\n",
      "Fold # {4}\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 3s 123us/step - loss: 8.1322 - acc: 0.5085 - val_loss: 6.7531 - val_acc: 0.5157\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 5.7444 - acc: 0.5161 - val_loss: 4.7454 - val_acc: 0.5162\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 4.0427 - acc: 0.5165 - val_loss: 3.3537 - val_acc: 0.5659\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.8729 - acc: 0.6091 - val_loss: 2.4040 - val_acc: 0.6370\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 2.0781 - acc: 0.6658 - val_loss: 1.7643 - val_acc: 0.6554\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.5454 - acc: 0.6739 - val_loss: 1.3413 - val_acc: 0.6575\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.1972 - acc: 0.6772 - val_loss: 1.0688 - val_acc: 0.6609\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.9739 - acc: 0.6775 - val_loss: 0.8961 - val_acc: 0.6619\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.8339 - acc: 0.6777 - val_loss: 0.7885 - val_acc: 0.6624\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.7480 - acc: 0.6790 - val_loss: 0.7245 - val_acc: 0.6613\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.6953 - acc: 0.6801 - val_loss: 0.6810 - val_acc: 0.6705\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6644 - acc: 0.6812 - val_loss: 0.6580 - val_acc: 0.6678\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6477 - acc: 0.6773 - val_loss: 0.6459 - val_acc: 0.6689\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6359 - acc: 0.6819 - val_loss: 0.6377 - val_acc: 0.6691\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6275 - acc: 0.6850 - val_loss: 0.6315 - val_acc: 0.6747\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6244 - acc: 0.6835 - val_loss: 0.6272 - val_acc: 0.6769\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6210 - acc: 0.6879 - val_loss: 0.6278 - val_acc: 0.6758\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6195 - acc: 0.6876 - val_loss: 0.6280 - val_acc: 0.6712\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6191 - acc: 0.6856 - val_loss: 0.6315 - val_acc: 0.6586\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6182 - acc: 0.6864 - val_loss: 0.6270 - val_acc: 0.6753\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6185 - acc: 0.6846 - val_loss: 0.6494 - val_acc: 0.6399\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6178 - acc: 0.6856 - val_loss: 0.6555 - val_acc: 0.6343\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6144 - acc: 0.6908 - val_loss: 0.6196 - val_acc: 0.6824\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6132 - acc: 0.6890 - val_loss: 0.6244 - val_acc: 0.6712\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6129 - acc: 0.6894 - val_loss: 0.7101 - val_acc: 0.5816\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6280 - acc: 0.6895 - val_loss: 0.7373 - val_acc: 0.5585\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6207 - acc: 0.6875 - val_loss: 0.6943 - val_acc: 0.5925\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6124 - acc: 0.6937 - val_loss: 0.6692 - val_acc: 0.6264\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6111 - acc: 0.6930 - val_loss: 0.6484 - val_acc: 0.6451\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6093 - acc: 0.6913 - val_loss: 0.6337 - val_acc: 0.6580\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6075 - acc: 0.6936 - val_loss: 0.6686 - val_acc: 0.6317\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6115 - acc: 0.6865 - val_loss: 0.6170 - val_acc: 0.6866\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6096 - acc: 0.6921 - val_loss: 0.6328 - val_acc: 0.6596\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6079 - acc: 0.6936 - val_loss: 0.6659 - val_acc: 0.6244\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6082 - acc: 0.6896 - val_loss: 0.6407 - val_acc: 0.6523\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6076 - acc: 0.6909 - val_loss: 0.6459 - val_acc: 0.6423\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6078 - acc: 0.6926 - val_loss: 0.6638 - val_acc: 0.6338\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6066 - acc: 0.6933 - val_loss: 0.6191 - val_acc: 0.6773\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6066 - acc: 0.6925 - val_loss: 0.6500 - val_acc: 0.6403\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6037 - acc: 0.6961 - val_loss: 0.6578 - val_acc: 0.6397\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6058 - acc: 0.6925 - val_loss: 0.6167 - val_acc: 0.6754\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6036 - acc: 0.6954 - val_loss: 0.6414 - val_acc: 0.6497\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6036 - acc: 0.6954 - val_loss: 0.6499 - val_acc: 0.6437\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6027 - acc: 0.6962 - val_loss: 0.6215 - val_acc: 0.6677\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6046 - acc: 0.6929 - val_loss: 0.6934 - val_acc: 0.6067\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6035 - acc: 0.6928 - val_loss: 0.6722 - val_acc: 0.6254\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6072 - acc: 0.6904 - val_loss: 0.6375 - val_acc: 0.6533\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6013 - acc: 0.6947 - val_loss: 0.6379 - val_acc: 0.6564\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6010 - acc: 0.6980 - val_loss: 0.6364 - val_acc: 0.6594\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6021 - acc: 0.6962 - val_loss: 0.6576 - val_acc: 0.6415\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6009 - acc: 0.6975 - val_loss: 0.6991 - val_acc: 0.6038\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6024 - acc: 0.6967 - val_loss: 0.6804 - val_acc: 0.6137\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.6024 - acc: 0.6960 - val_loss: 0.6423 - val_acc: 0.6496\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6020 - acc: 0.6945 - val_loss: 0.6881 - val_acc: 0.6084\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5999 - acc: 0.6986 - val_loss: 0.6841 - val_acc: 0.6183\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5986 - acc: 0.7002 - val_loss: 0.6545 - val_acc: 0.6408\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5986 - acc: 0.6971 - val_loss: 0.6797 - val_acc: 0.6152\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5998 - acc: 0.6960 - val_loss: 0.6774 - val_acc: 0.6276\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6016 - acc: 0.6927 - val_loss: 0.6789 - val_acc: 0.6236\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6025 - acc: 0.6932 - val_loss: 0.7140 - val_acc: 0.5840\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5983 - acc: 0.6993 - val_loss: 0.6589 - val_acc: 0.6351\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5973 - acc: 0.6997 - val_loss: 0.6926 - val_acc: 0.6087\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6018 - acc: 0.6955 - val_loss: 0.7034 - val_acc: 0.6052\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5986 - acc: 0.6985 - val_loss: 0.6505 - val_acc: 0.6454\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5962 - acc: 0.6967 - val_loss: 0.6564 - val_acc: 0.6443\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5969 - acc: 0.6971 - val_loss: 0.6966 - val_acc: 0.6095\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5966 - acc: 0.6966 - val_loss: 0.6905 - val_acc: 0.6148\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5966 - acc: 0.6977 - val_loss: 0.6780 - val_acc: 0.6199\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5947 - acc: 0.7022 - val_loss: 0.7065 - val_acc: 0.5876\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5954 - acc: 0.6978 - val_loss: 0.6547 - val_acc: 0.6401\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6014 - acc: 0.6955 - val_loss: 0.6863 - val_acc: 0.6265\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5964 - acc: 0.6984 - val_loss: 0.6870 - val_acc: 0.5981\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5954 - acc: 0.6993 - val_loss: 0.7068 - val_acc: 0.6041\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5952 - acc: 0.6984 - val_loss: 0.7095 - val_acc: 0.6057\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5941 - acc: 0.7011 - val_loss: 0.7294 - val_acc: 0.5876\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5960 - acc: 0.7011 - val_loss: 0.7516 - val_acc: 0.5766\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5957 - acc: 0.6994 - val_loss: 0.7448 - val_acc: 0.5714\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5947 - acc: 0.7000 - val_loss: 0.7304 - val_acc: 0.5868\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5953 - acc: 0.7010 - val_loss: 0.6997 - val_acc: 0.6068\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5927 - acc: 0.7006 - val_loss: 0.6878 - val_acc: 0.6068\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5919 - acc: 0.7029 - val_loss: 0.7063 - val_acc: 0.5920\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5932 - acc: 0.7031 - val_loss: 0.7130 - val_acc: 0.5964\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5921 - acc: 0.7025 - val_loss: 0.7450 - val_acc: 0.5759\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7030 - val_loss: 0.7589 - val_acc: 0.5749\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5959 - acc: 0.6974 - val_loss: 0.7383 - val_acc: 0.5941\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5947 - acc: 0.7000 - val_loss: 0.7095 - val_acc: 0.6031\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5911 - acc: 0.7041 - val_loss: 0.7285 - val_acc: 0.5796\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5904 - acc: 0.7036 - val_loss: 0.7069 - val_acc: 0.6062\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5952 - acc: 0.7027 - val_loss: 0.8144 - val_acc: 0.5414\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5931 - acc: 0.7027 - val_loss: 0.7815 - val_acc: 0.5584\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5913 - acc: 0.7047 - val_loss: 0.7900 - val_acc: 0.5609\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5990 - acc: 0.6980 - val_loss: 0.7652 - val_acc: 0.5888\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5909 - acc: 0.7030 - val_loss: 0.7477 - val_acc: 0.5815\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5903 - acc: 0.7035 - val_loss: 0.8147 - val_acc: 0.5457\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7036 - val_loss: 0.7756 - val_acc: 0.5659\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5912 - acc: 0.7021 - val_loss: 0.7454 - val_acc: 0.5804\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5946 - acc: 0.6985 - val_loss: 0.7569 - val_acc: 0.5718\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5907 - acc: 0.7024 - val_loss: 0.7430 - val_acc: 0.5896\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7048 - val_loss: 0.7187 - val_acc: 0.6044\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5903 - acc: 0.7043 - val_loss: 0.7867 - val_acc: 0.5660\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5925 - acc: 0.7014 - val_loss: 0.7690 - val_acc: 0.5658\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5979 - acc: 0.6964 - val_loss: 0.7771 - val_acc: 0.5866\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5956 - acc: 0.6961 - val_loss: 0.7466 - val_acc: 0.5722\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5894 - acc: 0.7049 - val_loss: 0.6893 - val_acc: 0.6132\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5864 - acc: 0.7067 - val_loss: 0.7472 - val_acc: 0.5828\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5882 - acc: 0.7045 - val_loss: 0.7293 - val_acc: 0.5891\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5964 - acc: 0.7035 - val_loss: 0.7695 - val_acc: 0.5625\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5926 - acc: 0.7041 - val_loss: 0.7323 - val_acc: 0.5827\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5883 - acc: 0.7051 - val_loss: 0.7627 - val_acc: 0.5651\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5884 - acc: 0.7014 - val_loss: 0.7899 - val_acc: 0.5634\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5887 - acc: 0.7042 - val_loss: 0.7612 - val_acc: 0.5910\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5886 - acc: 0.7054 - val_loss: 0.7254 - val_acc: 0.5919\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5879 - acc: 0.7048 - val_loss: 0.7433 - val_acc: 0.5884\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5874 - acc: 0.7053 - val_loss: 0.7562 - val_acc: 0.5728\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5861 - acc: 0.7042 - val_loss: 0.7710 - val_acc: 0.5730\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5846 - acc: 0.7056 - val_loss: 0.7776 - val_acc: 0.5718\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5869 - acc: 0.7050 - val_loss: 0.8076 - val_acc: 0.5591\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5873 - acc: 0.7061 - val_loss: 0.7818 - val_acc: 0.5650\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5910 - acc: 0.6997 - val_loss: 0.7052 - val_acc: 0.5911\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5867 - acc: 0.7041 - val_loss: 0.7624 - val_acc: 0.5746\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5899 - acc: 0.7037 - val_loss: 0.7514 - val_acc: 0.5783\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5853 - acc: 0.7070 - val_loss: 0.7493 - val_acc: 0.5844\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5854 - acc: 0.7079 - val_loss: 0.7675 - val_acc: 0.5765\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5845 - acc: 0.7072 - val_loss: 0.7515 - val_acc: 0.5806\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5860 - acc: 0.7073 - val_loss: 0.7497 - val_acc: 0.5748\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5841 - acc: 0.7070 - val_loss: 0.8050 - val_acc: 0.5620\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5848 - acc: 0.7080 - val_loss: 0.8383 - val_acc: 0.5382\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5904 - acc: 0.7079 - val_loss: 0.8618 - val_acc: 0.5355\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5876 - acc: 0.7048 - val_loss: 0.8418 - val_acc: 0.5476\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5887 - acc: 0.7054 - val_loss: 0.8688 - val_acc: 0.5280\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5974 - acc: 0.7030 - val_loss: 0.8496 - val_acc: 0.5371\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5909 - acc: 0.7026 - val_loss: 0.8108 - val_acc: 0.5588\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5849 - acc: 0.7042 - val_loss: 0.7958 - val_acc: 0.5648\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5827 - acc: 0.7091 - val_loss: 0.7988 - val_acc: 0.5631\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5922 - acc: 0.6997 - val_loss: 0.8284 - val_acc: 0.5457\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5908 - acc: 0.7028 - val_loss: 0.8340 - val_acc: 0.5484\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5839 - acc: 0.7070 - val_loss: 0.8079 - val_acc: 0.5583\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5836 - acc: 0.7075 - val_loss: 0.7916 - val_acc: 0.5689\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5835 - acc: 0.7058 - val_loss: 0.7827 - val_acc: 0.5594\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6117 - acc: 0.7036 - val_loss: 0.8738 - val_acc: 0.5271\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5976 - acc: 0.7070 - val_loss: 0.8514 - val_acc: 0.5366\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5897 - acc: 0.7075 - val_loss: 0.8356 - val_acc: 0.5434\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5865 - acc: 0.7056 - val_loss: 0.8140 - val_acc: 0.5529\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5832 - acc: 0.7083 - val_loss: 0.8011 - val_acc: 0.5597\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5827 - acc: 0.7072 - val_loss: 0.8084 - val_acc: 0.5615\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5816 - acc: 0.7082 - val_loss: 0.8126 - val_acc: 0.5611\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5806 - acc: 0.7121 - val_loss: 0.7955 - val_acc: 0.5627\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5841 - acc: 0.7059 - val_loss: 0.8015 - val_acc: 0.5600\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5847 - acc: 0.7076 - val_loss: 0.7712 - val_acc: 0.5714\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5816 - acc: 0.7087 - val_loss: 0.7988 - val_acc: 0.5643\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5822 - acc: 0.7086 - val_loss: 0.8038 - val_acc: 0.5571\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5843 - acc: 0.7081 - val_loss: 0.8234 - val_acc: 0.5496\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5821 - acc: 0.7091 - val_loss: 0.8101 - val_acc: 0.5627\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5839 - acc: 0.7049 - val_loss: 0.8253 - val_acc: 0.5603\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5792 - acc: 0.7128 - val_loss: 0.8238 - val_acc: 0.5529\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5798 - acc: 0.7065 - val_loss: 0.8204 - val_acc: 0.5636\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5808 - acc: 0.7114 - val_loss: 0.8198 - val_acc: 0.5577\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5819 - acc: 0.7074 - val_loss: 0.8060 - val_acc: 0.5711\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5854 - acc: 0.7031 - val_loss: 0.7934 - val_acc: 0.5640\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5824 - acc: 0.7083 - val_loss: 0.8100 - val_acc: 0.5617\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5815 - acc: 0.7072 - val_loss: 0.8467 - val_acc: 0.5402\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5902 - acc: 0.7049 - val_loss: 0.8577 - val_acc: 0.5347\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5836 - acc: 0.7084 - val_loss: 0.8357 - val_acc: 0.5498\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5779 - acc: 0.7128 - val_loss: 0.8182 - val_acc: 0.5612\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5788 - acc: 0.7121 - val_loss: 0.8339 - val_acc: 0.5573\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5826 - acc: 0.7078 - val_loss: 0.8058 - val_acc: 0.5685\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5797 - acc: 0.7089 - val_loss: 0.8207 - val_acc: 0.5602\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5815 - acc: 0.7070 - val_loss: 0.8239 - val_acc: 0.5605\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5797 - acc: 0.7104 - val_loss: 0.8225 - val_acc: 0.5617\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5811 - acc: 0.7071 - val_loss: 0.8354 - val_acc: 0.5572\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7102 - val_loss: 0.8817 - val_acc: 0.5372\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5928 - acc: 0.7076 - val_loss: 0.8906 - val_acc: 0.5330\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5833 - acc: 0.7105 - val_loss: 0.8754 - val_acc: 0.5438\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5834 - acc: 0.7074 - val_loss: 0.8677 - val_acc: 0.5458\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5832 - acc: 0.7086 - val_loss: 0.8604 - val_acc: 0.5521\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5784 - acc: 0.7113 - val_loss: 0.8696 - val_acc: 0.5489\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5808 - acc: 0.7092 - val_loss: 0.8617 - val_acc: 0.5510\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5783 - acc: 0.7112 - val_loss: 0.8498 - val_acc: 0.5541\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7117 - val_loss: 0.8657 - val_acc: 0.5532\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5905 - acc: 0.7097 - val_loss: 0.8912 - val_acc: 0.5455\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5833 - acc: 0.7130 - val_loss: 0.8722 - val_acc: 0.5484\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5850 - acc: 0.7072 - val_loss: 0.8577 - val_acc: 0.5512\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5806 - acc: 0.7094 - val_loss: 0.8586 - val_acc: 0.5526\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5789 - acc: 0.7112 - val_loss: 0.8570 - val_acc: 0.5546\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5805 - acc: 0.7102 - val_loss: 0.8477 - val_acc: 0.5537\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5767 - acc: 0.7142 - val_loss: 0.8528 - val_acc: 0.5527\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5773 - acc: 0.7124 - val_loss: 0.8548 - val_acc: 0.5535\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5825 - acc: 0.7068 - val_loss: 0.8400 - val_acc: 0.5594\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5820 - acc: 0.7122 - val_loss: 0.8302 - val_acc: 0.5629\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7141 - val_loss: 0.8383 - val_acc: 0.5596\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5799 - acc: 0.7148 - val_loss: 0.8419 - val_acc: 0.5561\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5776 - acc: 0.7167 - val_loss: 0.8424 - val_acc: 0.5609\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5939 - acc: 0.7135 - val_loss: 0.8838 - val_acc: 0.5387\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5897 - acc: 0.7175 - val_loss: 0.8766 - val_acc: 0.5425\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5832 - acc: 0.7160 - val_loss: 0.8614 - val_acc: 0.5527\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5784 - acc: 0.7144 - val_loss: 0.8324 - val_acc: 0.5611\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5779 - acc: 0.7137 - val_loss: 0.8285 - val_acc: 0.5662\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5774 - acc: 0.7149 - val_loss: 0.8413 - val_acc: 0.5620\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5791 - acc: 0.7137 - val_loss: 0.8293 - val_acc: 0.5656\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5779 - acc: 0.7153 - val_loss: 0.8426 - val_acc: 0.5600\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5795 - acc: 0.7130 - val_loss: 0.8460 - val_acc: 0.5620\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5767 - acc: 0.7190 - val_loss: 0.8289 - val_acc: 0.5664\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5755 - acc: 0.7176 - val_loss: 0.8457 - val_acc: 0.5593\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5764 - acc: 0.7177 - val_loss: 0.8453 - val_acc: 0.5589\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5751 - acc: 0.7175 - val_loss: 0.8479 - val_acc: 0.5598\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5756 - acc: 0.7175 - val_loss: 0.8344 - val_acc: 0.5640\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5754 - acc: 0.7176 - val_loss: 0.8510 - val_acc: 0.5575\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5781 - acc: 0.7162 - val_loss: 0.8438 - val_acc: 0.5609\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5784 - acc: 0.7159 - val_loss: 0.8426 - val_acc: 0.5625\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5770 - acc: 0.7186 - val_loss: 0.8488 - val_acc: 0.5641\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5794 - acc: 0.7158 - val_loss: 0.8378 - val_acc: 0.5630\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5758 - acc: 0.7188 - val_loss: 0.8478 - val_acc: 0.5603\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5751 - acc: 0.7181 - val_loss: 0.8491 - val_acc: 0.5600\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5774 - acc: 0.7168 - val_loss: 0.8515 - val_acc: 0.5600\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5801 - acc: 0.7132 - val_loss: 0.8272 - val_acc: 0.5658\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5773 - acc: 0.7127 - val_loss: 0.8570 - val_acc: 0.5620\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5889 - acc: 0.7153 - val_loss: 0.8623 - val_acc: 0.5588\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5781 - acc: 0.7193 - val_loss: 0.8324 - val_acc: 0.5666\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5768 - acc: 0.7169 - val_loss: 0.8476 - val_acc: 0.5592\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5781 - acc: 0.7173 - val_loss: 0.8494 - val_acc: 0.5605\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5787 - acc: 0.7150 - val_loss: 0.8657 - val_acc: 0.5589\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5782 - acc: 0.7163 - val_loss: 0.8448 - val_acc: 0.5613\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5780 - acc: 0.7159 - val_loss: 0.8311 - val_acc: 0.5666\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5761 - acc: 0.7179 - val_loss: 0.8341 - val_acc: 0.5665\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5746 - acc: 0.7190 - val_loss: 0.8528 - val_acc: 0.5587\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5776 - acc: 0.7205 - val_loss: 0.8382 - val_acc: 0.5637\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5762 - acc: 0.7179 - val_loss: 0.8654 - val_acc: 0.5562\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5787 - acc: 0.7158 - val_loss: 0.8712 - val_acc: 0.5552\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.7193 - val_loss: 0.9025 - val_acc: 0.5501\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5882 - acc: 0.7154 - val_loss: 0.8806 - val_acc: 0.5534\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5751 - acc: 0.7206 - val_loss: 0.8674 - val_acc: 0.5574\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5776 - acc: 0.7138 - val_loss: 0.8517 - val_acc: 0.5620\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5772 - acc: 0.7185 - val_loss: 0.8681 - val_acc: 0.5576\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5740 - acc: 0.7200 - val_loss: 0.8613 - val_acc: 0.5605\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5745 - acc: 0.7177 - val_loss: 0.8558 - val_acc: 0.5583\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5730 - acc: 0.7198 - val_loss: 0.8551 - val_acc: 0.5594\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5750 - acc: 0.7170 - val_loss: 0.8544 - val_acc: 0.5599\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5762 - acc: 0.7168 - val_loss: 0.8440 - val_acc: 0.5623\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7153 - val_loss: 0.8835 - val_acc: 0.5482\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5774 - acc: 0.7170 - val_loss: 0.8812 - val_acc: 0.5526\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5763 - acc: 0.7170 - val_loss: 0.8741 - val_acc: 0.5548\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5743 - acc: 0.7185 - val_loss: 0.8694 - val_acc: 0.5568\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5767 - acc: 0.7161 - val_loss: 0.8692 - val_acc: 0.5563\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5739 - acc: 0.7172 - val_loss: 0.8737 - val_acc: 0.5573\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5729 - acc: 0.7188 - val_loss: 0.8699 - val_acc: 0.5580\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5753 - acc: 0.7184 - val_loss: 0.8684 - val_acc: 0.5564\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5726 - acc: 0.7202 - val_loss: 0.8818 - val_acc: 0.5525\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5732 - acc: 0.7177 - val_loss: 0.8662 - val_acc: 0.5577\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5759 - acc: 0.7170 - val_loss: 0.8631 - val_acc: 0.5596\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5744 - acc: 0.7190 - val_loss: 0.8624 - val_acc: 0.5589\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5769 - acc: 0.7172 - val_loss: 0.8653 - val_acc: 0.5578\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5752 - acc: 0.7196 - val_loss: 0.8645 - val_acc: 0.5604\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5785 - acc: 0.7161 - val_loss: 0.8933 - val_acc: 0.5499\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5783 - acc: 0.7195 - val_loss: 0.8711 - val_acc: 0.5562\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5794 - acc: 0.7145 - val_loss: 0.8598 - val_acc: 0.5613\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5781 - acc: 0.7157 - val_loss: 0.8627 - val_acc: 0.5575\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5758 - acc: 0.7177 - val_loss: 0.8634 - val_acc: 0.5588\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5754 - acc: 0.7184 - val_loss: 0.8591 - val_acc: 0.5592\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5725 - acc: 0.7201 - val_loss: 0.8746 - val_acc: 0.5556\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5749 - acc: 0.7189 - val_loss: 0.8629 - val_acc: 0.5575\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5756 - acc: 0.7185 - val_loss: 0.8540 - val_acc: 0.5595\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5772 - acc: 0.7150 - val_loss: 0.8526 - val_acc: 0.5604\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5757 - acc: 0.7181 - val_loss: 0.8584 - val_acc: 0.5605\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5713 - acc: 0.7208 - val_loss: 0.8460 - val_acc: 0.5640\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5833 - acc: 0.7204 - val_loss: 0.9384 - val_acc: 0.5319\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5974 - acc: 0.7212 - val_loss: 0.9218 - val_acc: 0.5355\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5833 - acc: 0.7166 - val_loss: 0.9073 - val_acc: 0.5445\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5787 - acc: 0.7191 - val_loss: 0.8986 - val_acc: 0.5490\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7179 - val_loss: 0.8932 - val_acc: 0.5526\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5757 - acc: 0.7199 - val_loss: 0.8940 - val_acc: 0.5501\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5748 - acc: 0.7209 - val_loss: 0.8895 - val_acc: 0.5525\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5728 - acc: 0.7201 - val_loss: 0.8856 - val_acc: 0.5542\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5735 - acc: 0.7192 - val_loss: 0.8872 - val_acc: 0.5514\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5714 - acc: 0.7234 - val_loss: 0.8857 - val_acc: 0.5532\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5700 - acc: 0.7247 - val_loss: 0.8832 - val_acc: 0.5553\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5740 - acc: 0.7203 - val_loss: 0.8909 - val_acc: 0.5528\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5736 - acc: 0.7205 - val_loss: 0.8951 - val_acc: 0.5467\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5832 - acc: 0.7160 - val_loss: 0.8887 - val_acc: 0.5494\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5783 - acc: 0.7157 - val_loss: 0.8868 - val_acc: 0.5515\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5753 - acc: 0.7192 - val_loss: 0.8765 - val_acc: 0.5559\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5722 - acc: 0.7200 - val_loss: 0.8753 - val_acc: 0.5554\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5720 - acc: 0.7213 - val_loss: 0.8721 - val_acc: 0.5566\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5697 - acc: 0.7238 - val_loss: 0.8823 - val_acc: 0.5542\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5712 - acc: 0.7212 - val_loss: 0.8799 - val_acc: 0.5552\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5729 - acc: 0.7189 - val_loss: 0.8759 - val_acc: 0.5564\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5918 - acc: 0.7161 - val_loss: 0.9287 - val_acc: 0.5436\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5959 - acc: 0.7215 - val_loss: 0.9124 - val_acc: 0.5466\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5824 - acc: 0.7202 - val_loss: 0.8942 - val_acc: 0.5518\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5756 - acc: 0.7211 - val_loss: 0.8899 - val_acc: 0.5532\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5740 - acc: 0.7186 - val_loss: 0.8783 - val_acc: 0.5547\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5734 - acc: 0.7159 - val_loss: 0.8796 - val_acc: 0.5542\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5742 - acc: 0.7171 - val_loss: 0.8743 - val_acc: 0.5569\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5711 - acc: 0.7210 - val_loss: 0.8807 - val_acc: 0.5543\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5698 - acc: 0.7224 - val_loss: 0.8774 - val_acc: 0.5547\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5718 - acc: 0.7206 - val_loss: 0.8715 - val_acc: 0.5578\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5707 - acc: 0.7217 - val_loss: 0.8706 - val_acc: 0.5572\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5772 - acc: 0.7164 - val_loss: 0.8481 - val_acc: 0.5636\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5752 - acc: 0.7192 - val_loss: 0.8567 - val_acc: 0.5618\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5741 - acc: 0.7179 - val_loss: 0.8705 - val_acc: 0.5569\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5698 - acc: 0.7215 - val_loss: 0.8725 - val_acc: 0.5526\n",
      "Fold # {5}\n",
      "Train on 21816 samples, validate on 9351 samples\n",
      "Epoch 1/300\n",
      "21816/21816 [==============================] - 3s 133us/step - loss: 8.0771 - acc: 0.5028 - val_loss: 6.7080 - val_acc: 0.5251\n",
      "Epoch 2/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 5.7045 - acc: 0.5714 - val_loss: 4.7121 - val_acc: 0.5911\n",
      "Epoch 3/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 4.0138 - acc: 0.6303 - val_loss: 3.3300 - val_acc: 0.6410\n",
      "Epoch 4/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 2.8482 - acc: 0.6700 - val_loss: 2.3844 - val_acc: 0.6544\n",
      "Epoch 5/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 2.0511 - acc: 0.6733 - val_loss: 1.7429 - val_acc: 0.6567\n",
      "Epoch 6/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 1.5168 - acc: 0.6777 - val_loss: 1.3210 - val_acc: 0.6586\n",
      "Epoch 7/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 1.1687 - acc: 0.6798 - val_loss: 1.0487 - val_acc: 0.6677\n",
      "Epoch 8/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.9474 - acc: 0.6873 - val_loss: 0.8802 - val_acc: 0.6730\n",
      "Epoch 9/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.8096 - acc: 0.6887 - val_loss: 0.7693 - val_acc: 0.6743\n",
      "Epoch 10/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.7248 - acc: 0.6919 - val_loss: 0.7052 - val_acc: 0.6766\n",
      "Epoch 11/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6750 - acc: 0.6915 - val_loss: 0.6647 - val_acc: 0.6827\n",
      "Epoch 12/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6437 - acc: 0.6937 - val_loss: 0.6485 - val_acc: 0.6826\n",
      "Epoch 13/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6299 - acc: 0.6909 - val_loss: 0.6325 - val_acc: 0.6881\n",
      "Epoch 14/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6203 - acc: 0.6927 - val_loss: 0.6232 - val_acc: 0.6816\n",
      "Epoch 15/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6145 - acc: 0.6924 - val_loss: 0.6382 - val_acc: 0.6585\n",
      "Epoch 16/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6138 - acc: 0.6894 - val_loss: 0.6169 - val_acc: 0.6839\n",
      "Epoch 17/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6081 - acc: 0.6930 - val_loss: 0.6129 - val_acc: 0.6903\n",
      "Epoch 18/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6045 - acc: 0.6959 - val_loss: 0.6136 - val_acc: 0.6858\n",
      "Epoch 19/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6046 - acc: 0.6956 - val_loss: 0.6089 - val_acc: 0.6916\n",
      "Epoch 20/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6049 - acc: 0.6953 - val_loss: 0.6136 - val_acc: 0.6842\n",
      "Epoch 21/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6061 - acc: 0.6952 - val_loss: 0.6338 - val_acc: 0.6568\n",
      "Epoch 22/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.6037 - acc: 0.6950 - val_loss: 0.6117 - val_acc: 0.6921\n",
      "Epoch 23/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6024 - acc: 0.6965 - val_loss: 0.6194 - val_acc: 0.6800\n",
      "Epoch 24/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6047 - acc: 0.6971 - val_loss: 0.7363 - val_acc: 0.5763\n",
      "Epoch 25/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6069 - acc: 0.7008 - val_loss: 0.6595 - val_acc: 0.6397\n",
      "Epoch 26/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6029 - acc: 0.6982 - val_loss: 0.6507 - val_acc: 0.6488\n",
      "Epoch 27/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6005 - acc: 0.6993 - val_loss: 0.6236 - val_acc: 0.6679\n",
      "Epoch 28/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6033 - acc: 0.6941 - val_loss: 0.6319 - val_acc: 0.6725\n",
      "Epoch 29/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.6046 - acc: 0.6941 - val_loss: 0.6294 - val_acc: 0.6658\n",
      "Epoch 30/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6007 - acc: 0.6992 - val_loss: 0.6066 - val_acc: 0.6959\n",
      "Epoch 31/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5982 - acc: 0.7015 - val_loss: 0.6120 - val_acc: 0.6854\n",
      "Epoch 32/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5977 - acc: 0.7020 - val_loss: 0.6309 - val_acc: 0.6632\n",
      "Epoch 33/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5992 - acc: 0.6999 - val_loss: 0.6399 - val_acc: 0.6672\n",
      "Epoch 34/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5973 - acc: 0.7023 - val_loss: 0.6366 - val_acc: 0.6503\n",
      "Epoch 35/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5964 - acc: 0.6998 - val_loss: 0.6190 - val_acc: 0.6796\n",
      "Epoch 36/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5990 - acc: 0.6979 - val_loss: 0.6199 - val_acc: 0.6717\n",
      "Epoch 37/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5972 - acc: 0.6999 - val_loss: 0.6349 - val_acc: 0.6614\n",
      "Epoch 38/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5963 - acc: 0.7049 - val_loss: 0.6499 - val_acc: 0.6386\n",
      "Epoch 39/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5942 - acc: 0.7054 - val_loss: 0.6291 - val_acc: 0.6603\n",
      "Epoch 40/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5945 - acc: 0.7027 - val_loss: 0.6506 - val_acc: 0.6511\n",
      "Epoch 41/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6015 - acc: 0.7010 - val_loss: 0.8011 - val_acc: 0.5646\n",
      "Epoch 42/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6048 - acc: 0.7015 - val_loss: 0.7854 - val_acc: 0.5630\n",
      "Epoch 43/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5985 - acc: 0.7007 - val_loss: 0.6286 - val_acc: 0.6673\n",
      "Epoch 44/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5960 - acc: 0.6996 - val_loss: 0.7409 - val_acc: 0.5821\n",
      "Epoch 45/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5996 - acc: 0.7011 - val_loss: 0.6649 - val_acc: 0.6280\n",
      "Epoch 46/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.7069 - val_loss: 0.6448 - val_acc: 0.6475\n",
      "Epoch 47/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5934 - acc: 0.7044 - val_loss: 0.7802 - val_acc: 0.5675\n",
      "Epoch 48/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.6040 - acc: 0.7039 - val_loss: 0.7986 - val_acc: 0.5626\n",
      "Epoch 49/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5950 - acc: 0.7065 - val_loss: 0.6838 - val_acc: 0.6185\n",
      "Epoch 50/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5921 - acc: 0.7053 - val_loss: 0.6814 - val_acc: 0.6225\n",
      "Epoch 51/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5906 - acc: 0.7085 - val_loss: 0.6646 - val_acc: 0.6335\n",
      "Epoch 52/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5916 - acc: 0.7055 - val_loss: 0.7662 - val_acc: 0.5730\n",
      "Epoch 53/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5967 - acc: 0.7041 - val_loss: 0.7281 - val_acc: 0.5919\n",
      "Epoch 54/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.7051 - val_loss: 0.6716 - val_acc: 0.6342\n",
      "Epoch 55/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5905 - acc: 0.7071 - val_loss: 0.7092 - val_acc: 0.5926\n",
      "Epoch 56/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5894 - acc: 0.7056 - val_loss: 0.6938 - val_acc: 0.6084\n",
      "Epoch 57/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5926 - acc: 0.7059 - val_loss: 0.7517 - val_acc: 0.5810\n",
      "Epoch 58/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5922 - acc: 0.7037 - val_loss: 0.7336 - val_acc: 0.5850\n",
      "Epoch 59/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5908 - acc: 0.7077 - val_loss: 0.6903 - val_acc: 0.6086\n",
      "Epoch 60/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5918 - acc: 0.7070 - val_loss: 0.6748 - val_acc: 0.6206\n",
      "Epoch 61/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5937 - acc: 0.7084 - val_loss: 0.8625 - val_acc: 0.5503\n",
      "Epoch 62/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5921 - acc: 0.7081 - val_loss: 0.8210 - val_acc: 0.5630\n",
      "Epoch 63/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5945 - acc: 0.7059 - val_loss: 0.7707 - val_acc: 0.5753\n",
      "Epoch 64/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5950 - acc: 0.7018 - val_loss: 0.7000 - val_acc: 0.6026\n",
      "Epoch 65/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5899 - acc: 0.7104 - val_loss: 0.7057 - val_acc: 0.5980\n",
      "Epoch 66/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5867 - acc: 0.7106 - val_loss: 0.7780 - val_acc: 0.5696\n",
      "Epoch 67/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5880 - acc: 0.7090 - val_loss: 0.7123 - val_acc: 0.5995\n",
      "Epoch 68/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5931 - acc: 0.7126 - val_loss: 0.8156 - val_acc: 0.5636\n",
      "Epoch 69/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5917 - acc: 0.7067 - val_loss: 0.7520 - val_acc: 0.5831\n",
      "Epoch 70/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5913 - acc: 0.7052 - val_loss: 0.6993 - val_acc: 0.6084\n",
      "Epoch 71/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5860 - acc: 0.7090 - val_loss: 0.7441 - val_acc: 0.5787\n",
      "Epoch 72/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5876 - acc: 0.7097 - val_loss: 0.8407 - val_acc: 0.5575\n",
      "Epoch 73/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5997 - acc: 0.7076 - val_loss: 0.8157 - val_acc: 0.5644\n",
      "Epoch 74/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5923 - acc: 0.7082 - val_loss: 0.7989 - val_acc: 0.5633\n",
      "Epoch 75/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5901 - acc: 0.7074 - val_loss: 0.8271 - val_acc: 0.5609\n",
      "Epoch 76/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5853 - acc: 0.7109 - val_loss: 0.7866 - val_acc: 0.5722\n",
      "Epoch 77/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5853 - acc: 0.7109 - val_loss: 0.7814 - val_acc: 0.5737\n",
      "Epoch 78/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.7023 - val_loss: 0.8378 - val_acc: 0.5563\n",
      "Epoch 79/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5932 - acc: 0.7035 - val_loss: 0.7751 - val_acc: 0.5726\n",
      "Epoch 80/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5891 - acc: 0.7059 - val_loss: 0.7474 - val_acc: 0.5858\n",
      "Epoch 81/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5869 - acc: 0.7108 - val_loss: 0.7508 - val_acc: 0.5836\n",
      "Epoch 82/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5861 - acc: 0.7104 - val_loss: 0.7492 - val_acc: 0.5871\n",
      "Epoch 83/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5848 - acc: 0.7130 - val_loss: 0.7869 - val_acc: 0.5682\n",
      "Epoch 84/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5960 - acc: 0.7081 - val_loss: 0.8005 - val_acc: 0.5646\n",
      "Epoch 85/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5930 - acc: 0.7079 - val_loss: 0.7690 - val_acc: 0.5711\n",
      "Epoch 86/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5918 - acc: 0.7066 - val_loss: 0.7130 - val_acc: 0.5934\n",
      "Epoch 87/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5884 - acc: 0.7086 - val_loss: 0.6988 - val_acc: 0.6157\n",
      "Epoch 88/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5924 - acc: 0.7044 - val_loss: 0.7434 - val_acc: 0.5873\n",
      "Epoch 89/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5876 - acc: 0.7076 - val_loss: 0.7913 - val_acc: 0.5671\n",
      "Epoch 90/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5868 - acc: 0.7081 - val_loss: 0.7434 - val_acc: 0.5821\n",
      "Epoch 91/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5862 - acc: 0.7098 - val_loss: 0.7775 - val_acc: 0.5706\n",
      "Epoch 92/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5914 - acc: 0.7120 - val_loss: 0.8639 - val_acc: 0.5500\n",
      "Epoch 93/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5914 - acc: 0.7115 - val_loss: 0.8374 - val_acc: 0.5587\n",
      "Epoch 94/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5871 - acc: 0.7103 - val_loss: 0.8258 - val_acc: 0.5590\n",
      "Epoch 95/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5829 - acc: 0.7137 - val_loss: 0.8002 - val_acc: 0.5690\n",
      "Epoch 96/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5818 - acc: 0.7142 - val_loss: 0.7973 - val_acc: 0.5676\n",
      "Epoch 97/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5848 - acc: 0.7079 - val_loss: 0.7981 - val_acc: 0.5635\n",
      "Epoch 98/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5839 - acc: 0.7100 - val_loss: 0.7802 - val_acc: 0.5712\n",
      "Epoch 99/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5823 - acc: 0.7138 - val_loss: 0.7598 - val_acc: 0.5797\n",
      "Epoch 100/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5862 - acc: 0.7115 - val_loss: 0.7772 - val_acc: 0.5734\n",
      "Epoch 101/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5820 - acc: 0.7153 - val_loss: 0.7987 - val_acc: 0.5679\n",
      "Epoch 102/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5837 - acc: 0.7126 - val_loss: 0.7737 - val_acc: 0.5735\n",
      "Epoch 103/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5828 - acc: 0.7114 - val_loss: 0.7374 - val_acc: 0.5865\n",
      "Epoch 104/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5845 - acc: 0.7117 - val_loss: 0.7417 - val_acc: 0.5889\n",
      "Epoch 105/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5825 - acc: 0.7159 - val_loss: 0.7192 - val_acc: 0.6005\n",
      "Epoch 106/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5886 - acc: 0.7087 - val_loss: 0.6942 - val_acc: 0.6087\n",
      "Epoch 107/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5890 - acc: 0.7106 - val_loss: 0.8217 - val_acc: 0.5600\n",
      "Epoch 108/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5830 - acc: 0.7157 - val_loss: 0.8107 - val_acc: 0.5634\n",
      "Epoch 109/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5810 - acc: 0.7136 - val_loss: 0.7818 - val_acc: 0.5710\n",
      "Epoch 110/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5807 - acc: 0.7130 - val_loss: 0.7906 - val_acc: 0.5706\n",
      "Epoch 111/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5857 - acc: 0.7103 - val_loss: 0.8034 - val_acc: 0.5626\n",
      "Epoch 112/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5940 - acc: 0.7039 - val_loss: 0.8020 - val_acc: 0.5654\n",
      "Epoch 113/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5851 - acc: 0.7120 - val_loss: 0.7900 - val_acc: 0.5682\n",
      "Epoch 114/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5838 - acc: 0.7106 - val_loss: 0.7768 - val_acc: 0.5763\n",
      "Epoch 115/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5801 - acc: 0.7153 - val_loss: 0.7716 - val_acc: 0.5733\n",
      "Epoch 116/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5808 - acc: 0.7168 - val_loss: 0.8364 - val_acc: 0.5545\n",
      "Epoch 117/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5854 - acc: 0.7148 - val_loss: 0.7887 - val_acc: 0.5668\n",
      "Epoch 118/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5802 - acc: 0.7156 - val_loss: 0.7855 - val_acc: 0.5677\n",
      "Epoch 119/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5798 - acc: 0.7157 - val_loss: 0.7677 - val_acc: 0.5758\n",
      "Epoch 120/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5792 - acc: 0.7173 - val_loss: 0.7948 - val_acc: 0.5681\n",
      "Epoch 121/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5790 - acc: 0.7170 - val_loss: 0.7994 - val_acc: 0.5640\n",
      "Epoch 122/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5832 - acc: 0.7134 - val_loss: 0.7906 - val_acc: 0.5661\n",
      "Epoch 123/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5796 - acc: 0.7151 - val_loss: 0.7579 - val_acc: 0.5860\n",
      "Epoch 124/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5798 - acc: 0.7156 - val_loss: 0.7623 - val_acc: 0.5706\n",
      "Epoch 125/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5779 - acc: 0.7165 - val_loss: 0.7863 - val_acc: 0.5677\n",
      "Epoch 126/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5783 - acc: 0.7171 - val_loss: 0.7691 - val_acc: 0.5728\n",
      "Epoch 127/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5874 - acc: 0.7096 - val_loss: 0.7417 - val_acc: 0.5990\n",
      "Epoch 128/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5911 - acc: 0.7119 - val_loss: 0.7784 - val_acc: 0.5674\n",
      "Epoch 129/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5797 - acc: 0.7130 - val_loss: 0.7649 - val_acc: 0.5802\n",
      "Epoch 130/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5789 - acc: 0.7152 - val_loss: 0.7265 - val_acc: 0.6020\n",
      "Epoch 131/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5824 - acc: 0.7120 - val_loss: 0.7175 - val_acc: 0.5931\n",
      "Epoch 132/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5868 - acc: 0.7094 - val_loss: 0.8059 - val_acc: 0.5543\n",
      "Epoch 133/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5811 - acc: 0.7151 - val_loss: 0.8136 - val_acc: 0.5553\n",
      "Epoch 134/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5789 - acc: 0.7172 - val_loss: 0.8099 - val_acc: 0.5602\n",
      "Epoch 135/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5783 - acc: 0.7163 - val_loss: 0.7922 - val_acc: 0.5643\n",
      "Epoch 136/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5776 - acc: 0.7192 - val_loss: 0.7979 - val_acc: 0.5633\n",
      "Epoch 137/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7166 - val_loss: 0.7940 - val_acc: 0.5628\n",
      "Epoch 138/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5801 - acc: 0.7162 - val_loss: 0.8028 - val_acc: 0.5587\n",
      "Epoch 139/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5766 - acc: 0.7193 - val_loss: 0.8043 - val_acc: 0.5596\n",
      "Epoch 140/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5790 - acc: 0.7149 - val_loss: 0.7931 - val_acc: 0.5692\n",
      "Epoch 141/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5810 - acc: 0.7129 - val_loss: 0.7889 - val_acc: 0.5651\n",
      "Epoch 142/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5811 - acc: 0.7142 - val_loss: 0.7699 - val_acc: 0.5708\n",
      "Epoch 143/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5767 - acc: 0.7168 - val_loss: 0.7697 - val_acc: 0.5748\n",
      "Epoch 144/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5765 - acc: 0.7167 - val_loss: 0.8179 - val_acc: 0.5609\n",
      "Epoch 145/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5880 - acc: 0.7187 - val_loss: 0.8301 - val_acc: 0.5618\n",
      "Epoch 146/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5808 - acc: 0.7162 - val_loss: 0.7805 - val_acc: 0.5721\n",
      "Epoch 147/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5758 - acc: 0.7185 - val_loss: 0.8077 - val_acc: 0.5634\n",
      "Epoch 148/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5757 - acc: 0.7173 - val_loss: 0.8172 - val_acc: 0.5607\n",
      "Epoch 149/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5805 - acc: 0.7134 - val_loss: 0.7915 - val_acc: 0.5662\n",
      "Epoch 150/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5754 - acc: 0.7203 - val_loss: 0.8086 - val_acc: 0.5600\n",
      "Epoch 151/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5769 - acc: 0.7177 - val_loss: 0.7621 - val_acc: 0.5776\n",
      "Epoch 152/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5828 - acc: 0.7133 - val_loss: 0.7746 - val_acc: 0.5689\n",
      "Epoch 153/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5784 - acc: 0.7183 - val_loss: 0.7895 - val_acc: 0.5661\n",
      "Epoch 154/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5750 - acc: 0.7177 - val_loss: 0.8263 - val_acc: 0.5582\n",
      "Epoch 155/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5825 - acc: 0.7174 - val_loss: 0.8201 - val_acc: 0.5580\n",
      "Epoch 156/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5813 - acc: 0.7154 - val_loss: 0.7648 - val_acc: 0.5735\n",
      "Epoch 157/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5738 - acc: 0.7185 - val_loss: 0.7821 - val_acc: 0.5698\n",
      "Epoch 158/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5756 - acc: 0.7203 - val_loss: 0.7838 - val_acc: 0.5689\n",
      "Epoch 159/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5756 - acc: 0.7196 - val_loss: 0.8328 - val_acc: 0.5571\n",
      "Epoch 160/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5813 - acc: 0.7144 - val_loss: 0.8304 - val_acc: 0.5543\n",
      "Epoch 161/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5750 - acc: 0.7186 - val_loss: 0.8259 - val_acc: 0.5603\n",
      "Epoch 162/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5770 - acc: 0.7172 - val_loss: 0.7939 - val_acc: 0.5633\n",
      "Epoch 163/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5760 - acc: 0.7198 - val_loss: 0.8161 - val_acc: 0.5580\n",
      "Epoch 164/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5742 - acc: 0.7187 - val_loss: 0.7803 - val_acc: 0.5685\n",
      "Epoch 165/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5736 - acc: 0.7205 - val_loss: 0.7974 - val_acc: 0.5638\n",
      "Epoch 166/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5746 - acc: 0.7181 - val_loss: 0.8115 - val_acc: 0.5589\n",
      "Epoch 167/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5736 - acc: 0.7182 - val_loss: 0.8158 - val_acc: 0.5598\n",
      "Epoch 168/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5820 - acc: 0.7200 - val_loss: 0.8557 - val_acc: 0.5591\n",
      "Epoch 169/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5907 - acc: 0.7195 - val_loss: 0.8280 - val_acc: 0.5573\n",
      "Epoch 170/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5757 - acc: 0.7208 - val_loss: 0.8477 - val_acc: 0.5552\n",
      "Epoch 171/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5769 - acc: 0.7164 - val_loss: 0.8322 - val_acc: 0.5561\n",
      "Epoch 172/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5774 - acc: 0.7156 - val_loss: 0.8232 - val_acc: 0.5573\n",
      "Epoch 173/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5755 - acc: 0.7203 - val_loss: 0.7927 - val_acc: 0.5667\n",
      "Epoch 174/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5790 - acc: 0.7150 - val_loss: 0.8093 - val_acc: 0.5572\n",
      "Epoch 175/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5765 - acc: 0.7166 - val_loss: 0.7856 - val_acc: 0.5628\n",
      "Epoch 176/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5751 - acc: 0.7171 - val_loss: 0.7937 - val_acc: 0.5655\n",
      "Epoch 177/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5723 - acc: 0.7215 - val_loss: 0.8198 - val_acc: 0.5592\n",
      "Epoch 178/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5735 - acc: 0.7223 - val_loss: 0.8254 - val_acc: 0.5614\n",
      "Epoch 179/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5741 - acc: 0.7177 - val_loss: 0.7890 - val_acc: 0.5697\n",
      "Epoch 180/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5716 - acc: 0.7228 - val_loss: 0.8042 - val_acc: 0.5631\n",
      "Epoch 181/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5704 - acc: 0.7198 - val_loss: 0.8166 - val_acc: 0.5600\n",
      "Epoch 182/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5886 - acc: 0.7192 - val_loss: 0.8575 - val_acc: 0.5535\n",
      "Epoch 183/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5905 - acc: 0.7086 - val_loss: 0.7963 - val_acc: 0.5603\n",
      "Epoch 184/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5766 - acc: 0.7202 - val_loss: 0.8221 - val_acc: 0.5599\n",
      "Epoch 185/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5747 - acc: 0.7222 - val_loss: 0.8274 - val_acc: 0.5582\n",
      "Epoch 186/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5717 - acc: 0.7219 - val_loss: 0.8273 - val_acc: 0.5573\n",
      "Epoch 187/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5699 - acc: 0.7226 - val_loss: 0.8214 - val_acc: 0.5655\n",
      "Epoch 188/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5709 - acc: 0.7184 - val_loss: 0.8033 - val_acc: 0.5630\n",
      "Epoch 189/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5718 - acc: 0.7198 - val_loss: 0.7964 - val_acc: 0.5622\n",
      "Epoch 190/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5758 - acc: 0.7165 - val_loss: 0.8058 - val_acc: 0.5617\n",
      "Epoch 191/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5696 - acc: 0.7211 - val_loss: 0.8151 - val_acc: 0.5635\n",
      "Epoch 192/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5708 - acc: 0.7205 - val_loss: 0.8084 - val_acc: 0.5676\n",
      "Epoch 193/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5715 - acc: 0.7207 - val_loss: 0.8110 - val_acc: 0.5644\n",
      "Epoch 194/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5697 - acc: 0.7221 - val_loss: 0.8019 - val_acc: 0.5660\n",
      "Epoch 195/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5717 - acc: 0.7205 - val_loss: 0.8069 - val_acc: 0.5617\n",
      "Epoch 196/300\n",
      "21816/21816 [==============================] - 0s 15us/step - loss: 0.5697 - acc: 0.7226 - val_loss: 0.8379 - val_acc: 0.5558\n",
      "Epoch 197/300\n",
      "21816/21816 [==============================] - 0s 13us/step - loss: 0.5680 - acc: 0.7234 - val_loss: 0.8388 - val_acc: 0.5561\n",
      "Epoch 198/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5728 - acc: 0.7208 - val_loss: 0.8034 - val_acc: 0.5642\n",
      "Epoch 199/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5732 - acc: 0.7198 - val_loss: 0.8498 - val_acc: 0.5587\n",
      "Epoch 200/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5735 - acc: 0.7171 - val_loss: 0.8306 - val_acc: 0.5584\n",
      "Epoch 201/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5708 - acc: 0.7224 - val_loss: 0.8253 - val_acc: 0.5622\n",
      "Epoch 202/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5741 - acc: 0.7186 - val_loss: 0.8013 - val_acc: 0.5623\n",
      "Epoch 203/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5715 - acc: 0.7203 - val_loss: 0.8166 - val_acc: 0.5614\n",
      "Epoch 204/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5718 - acc: 0.7193 - val_loss: 0.8310 - val_acc: 0.5603\n",
      "Epoch 205/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5718 - acc: 0.7200 - val_loss: 0.8176 - val_acc: 0.5587\n",
      "Epoch 206/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5700 - acc: 0.7206 - val_loss: 0.8310 - val_acc: 0.5587\n",
      "Epoch 207/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5695 - acc: 0.7212 - val_loss: 0.8306 - val_acc: 0.5593\n",
      "Epoch 208/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5690 - acc: 0.7215 - val_loss: 0.8549 - val_acc: 0.5504\n",
      "Epoch 209/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5737 - acc: 0.7170 - val_loss: 0.8158 - val_acc: 0.5629\n",
      "Epoch 210/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5704 - acc: 0.7228 - val_loss: 0.7986 - val_acc: 0.5679\n",
      "Epoch 211/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5690 - acc: 0.7211 - val_loss: 0.8222 - val_acc: 0.5644\n",
      "Epoch 212/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5746 - acc: 0.7188 - val_loss: 0.8238 - val_acc: 0.5611\n",
      "Epoch 213/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5698 - acc: 0.7218 - val_loss: 0.8192 - val_acc: 0.5619\n",
      "Epoch 214/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5742 - acc: 0.7151 - val_loss: 0.8140 - val_acc: 0.5596\n",
      "Epoch 215/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5688 - acc: 0.7215 - val_loss: 0.8257 - val_acc: 0.5652\n",
      "Epoch 216/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5683 - acc: 0.7236 - val_loss: 0.8317 - val_acc: 0.5621\n",
      "Epoch 217/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5698 - acc: 0.7236 - val_loss: 0.8229 - val_acc: 0.5566\n",
      "Epoch 218/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5695 - acc: 0.7234 - val_loss: 0.8435 - val_acc: 0.5599\n",
      "Epoch 219/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5673 - acc: 0.7210 - val_loss: 0.8235 - val_acc: 0.5621\n",
      "Epoch 220/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5704 - acc: 0.7205 - val_loss: 0.8243 - val_acc: 0.5557\n",
      "Epoch 221/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5687 - acc: 0.7219 - val_loss: 0.8629 - val_acc: 0.5545\n",
      "Epoch 222/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5695 - acc: 0.7205 - val_loss: 0.8372 - val_acc: 0.5561\n",
      "Epoch 223/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5737 - acc: 0.7156 - val_loss: 0.8127 - val_acc: 0.5579\n",
      "Epoch 224/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5722 - acc: 0.7169 - val_loss: 0.8342 - val_acc: 0.5620\n",
      "Epoch 225/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5732 - acc: 0.7178 - val_loss: 0.7825 - val_acc: 0.5701\n",
      "Epoch 226/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5680 - acc: 0.7230 - val_loss: 0.8335 - val_acc: 0.5623\n",
      "Epoch 227/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5671 - acc: 0.7258 - val_loss: 0.8219 - val_acc: 0.5621\n",
      "Epoch 228/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5785 - acc: 0.7217 - val_loss: 0.9179 - val_acc: 0.5564\n",
      "Epoch 229/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5920 - acc: 0.7220 - val_loss: 0.8422 - val_acc: 0.5612\n",
      "Epoch 230/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5760 - acc: 0.7198 - val_loss: 0.8434 - val_acc: 0.5569\n",
      "Epoch 231/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5694 - acc: 0.7238 - val_loss: 0.8406 - val_acc: 0.5597\n",
      "Epoch 232/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5721 - acc: 0.7203 - val_loss: 0.8369 - val_acc: 0.5533\n",
      "Epoch 233/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5706 - acc: 0.7188 - val_loss: 0.8413 - val_acc: 0.5576\n",
      "Epoch 234/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5676 - acc: 0.7221 - val_loss: 0.7936 - val_acc: 0.5689\n",
      "Epoch 235/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5682 - acc: 0.7238 - val_loss: 0.8629 - val_acc: 0.5506\n",
      "Epoch 236/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5717 - acc: 0.7175 - val_loss: 0.8190 - val_acc: 0.5608\n",
      "Epoch 237/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5695 - acc: 0.7210 - val_loss: 0.8260 - val_acc: 0.5590\n",
      "Epoch 238/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5683 - acc: 0.7223 - val_loss: 0.8420 - val_acc: 0.5592\n",
      "Epoch 239/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5646 - acc: 0.7230 - val_loss: 0.8263 - val_acc: 0.5565\n",
      "Epoch 240/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5650 - acc: 0.7242 - val_loss: 0.8356 - val_acc: 0.5550\n",
      "Epoch 241/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5641 - acc: 0.7264 - val_loss: 0.8267 - val_acc: 0.5599\n",
      "Epoch 242/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5706 - acc: 0.7233 - val_loss: 0.8088 - val_acc: 0.5636\n",
      "Epoch 243/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5677 - acc: 0.7249 - val_loss: 0.8403 - val_acc: 0.5604\n",
      "Epoch 244/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5690 - acc: 0.7225 - val_loss: 0.8111 - val_acc: 0.5665\n",
      "Epoch 245/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5688 - acc: 0.7223 - val_loss: 0.7891 - val_acc: 0.5684\n",
      "Epoch 246/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5667 - acc: 0.7222 - val_loss: 0.8322 - val_acc: 0.5583\n",
      "Epoch 247/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5669 - acc: 0.7223 - val_loss: 0.8276 - val_acc: 0.5597\n",
      "Epoch 248/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5650 - acc: 0.7240 - val_loss: 0.8660 - val_acc: 0.5620\n",
      "Epoch 249/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5634 - acc: 0.7278 - val_loss: 0.8268 - val_acc: 0.5596\n",
      "Epoch 250/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5647 - acc: 0.7275 - val_loss: 0.8261 - val_acc: 0.5634\n",
      "Epoch 251/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5689 - acc: 0.7218 - val_loss: 0.8796 - val_acc: 0.5437\n",
      "Epoch 252/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5783 - acc: 0.7226 - val_loss: 0.8638 - val_acc: 0.5442\n",
      "Epoch 253/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5728 - acc: 0.7220 - val_loss: 0.8480 - val_acc: 0.5464\n",
      "Epoch 254/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5714 - acc: 0.7231 - val_loss: 0.8661 - val_acc: 0.5456\n",
      "Epoch 255/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5656 - acc: 0.7251 - val_loss: 0.8386 - val_acc: 0.5519\n",
      "Epoch 256/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5634 - acc: 0.7260 - val_loss: 0.8416 - val_acc: 0.5506\n",
      "Epoch 257/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5652 - acc: 0.7245 - val_loss: 0.8396 - val_acc: 0.5540\n",
      "Epoch 258/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5653 - acc: 0.7232 - val_loss: 0.8416 - val_acc: 0.5509\n",
      "Epoch 259/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5647 - acc: 0.7235 - val_loss: 0.8393 - val_acc: 0.5506\n",
      "Epoch 260/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5656 - acc: 0.7230 - val_loss: 0.8294 - val_acc: 0.5577\n",
      "Epoch 261/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5646 - acc: 0.7231 - val_loss: 0.8512 - val_acc: 0.5532\n",
      "Epoch 262/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5595 - acc: 0.7276 - val_loss: 0.8713 - val_acc: 0.5525\n",
      "Epoch 263/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5636 - acc: 0.7245 - val_loss: 0.8695 - val_acc: 0.5461\n",
      "Epoch 264/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5640 - acc: 0.7248 - val_loss: 0.8518 - val_acc: 0.5562\n",
      "Epoch 265/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5654 - acc: 0.7252 - val_loss: 0.8563 - val_acc: 0.5515\n",
      "Epoch 266/300\n",
      "21816/21816 [==============================] - 0s 14us/step - loss: 0.5627 - acc: 0.7247 - val_loss: 0.8389 - val_acc: 0.5541\n",
      "Epoch 267/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5911 - acc: 0.7230 - val_loss: 0.9719 - val_acc: 0.5446\n",
      "Epoch 268/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5997 - acc: 0.7215 - val_loss: 0.8917 - val_acc: 0.5429\n",
      "Epoch 269/300\n",
      "21816/21816 [==============================] - 0s 12us/step - loss: 0.5838 - acc: 0.7200 - val_loss: 0.8715 - val_acc: 0.5482\n",
      "Epoch 270/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5696 - acc: 0.7255 - val_loss: 0.8816 - val_acc: 0.5483\n",
      "Epoch 271/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5673 - acc: 0.7257 - val_loss: 0.8655 - val_acc: 0.5517\n",
      "Epoch 272/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5668 - acc: 0.7251 - val_loss: 0.8441 - val_acc: 0.5531\n",
      "Epoch 273/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5650 - acc: 0.7245 - val_loss: 0.8516 - val_acc: 0.5536\n",
      "Epoch 274/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5635 - acc: 0.7263 - val_loss: 0.8480 - val_acc: 0.5573\n",
      "Epoch 275/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5678 - acc: 0.7225 - val_loss: 0.8276 - val_acc: 0.5565\n",
      "Epoch 276/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5633 - acc: 0.7252 - val_loss: 0.8293 - val_acc: 0.5607\n",
      "Epoch 277/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5650 - acc: 0.7246 - val_loss: 0.8350 - val_acc: 0.5532\n",
      "Epoch 278/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5663 - acc: 0.7239 - val_loss: 0.8806 - val_acc: 0.5480\n",
      "Epoch 279/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5670 - acc: 0.7269 - val_loss: 0.8259 - val_acc: 0.5549\n",
      "Epoch 280/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5657 - acc: 0.7258 - val_loss: 0.8663 - val_acc: 0.5540\n",
      "Epoch 281/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5611 - acc: 0.7280 - val_loss: 0.8203 - val_acc: 0.5563\n",
      "Epoch 282/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5680 - acc: 0.7237 - val_loss: 0.8122 - val_acc: 0.5589\n",
      "Epoch 283/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5654 - acc: 0.7228 - val_loss: 0.8288 - val_acc: 0.5613\n",
      "Epoch 284/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5689 - acc: 0.7241 - val_loss: 0.8634 - val_acc: 0.5545\n",
      "Epoch 285/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5622 - acc: 0.7292 - val_loss: 0.8532 - val_acc: 0.5583\n",
      "Epoch 286/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5656 - acc: 0.7223 - val_loss: 0.8001 - val_acc: 0.5630\n",
      "Epoch 287/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5630 - acc: 0.7266 - val_loss: 0.8452 - val_acc: 0.5513\n",
      "Epoch 288/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5639 - acc: 0.7246 - val_loss: 0.8114 - val_acc: 0.5624\n",
      "Epoch 289/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5679 - acc: 0.7201 - val_loss: 0.8657 - val_acc: 0.5569\n",
      "Epoch 290/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5649 - acc: 0.7252 - val_loss: 0.8531 - val_acc: 0.5611\n",
      "Epoch 291/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5608 - acc: 0.7263 - val_loss: 0.8435 - val_acc: 0.5559\n",
      "Epoch 292/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5595 - acc: 0.7290 - val_loss: 0.8678 - val_acc: 0.5522\n",
      "Epoch 293/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5571 - acc: 0.7301 - val_loss: 0.8300 - val_acc: 0.5572\n",
      "Epoch 294/300\n",
      "21816/21816 [==============================] - 0s 11us/step - loss: 0.5606 - acc: 0.7282 - val_loss: 0.8625 - val_acc: 0.5607\n",
      "Epoch 295/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5592 - acc: 0.7295 - val_loss: 0.8629 - val_acc: 0.5525\n",
      "Epoch 296/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5644 - acc: 0.7230 - val_loss: 0.8343 - val_acc: 0.5572\n",
      "Epoch 297/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5660 - acc: 0.7258 - val_loss: 0.8839 - val_acc: 0.5575\n",
      "Epoch 298/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5635 - acc: 0.7271 - val_loss: 0.8648 - val_acc: 0.5594\n",
      "Epoch 299/300\n",
      "21816/21816 [==============================] - 0s 10us/step - loss: 0.5674 - acc: 0.7242 - val_loss: 0.8933 - val_acc: 0.5479\n",
      "Epoch 300/300\n",
      "21816/21816 [==============================] - 0s 9us/step - loss: 0.5708 - acc: 0.7260 - val_loss: 0.8560 - val_acc: 0.5543\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "x = X.values\n",
    "kf = KFold(5, shuffle=True,random_state=2)\n",
    "nn_y = []\n",
    "nn_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train,test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #\",{fold})\n",
    "    \n",
    "    x_train = X_scaledtr\n",
    "    y_train = Y_train\n",
    "    x_test = X_scaledte\n",
    "    y_test = Y_test\n",
    "    model3=keras.Sequential()\n",
    "    model3.add(keras.layers.Dense(100, input_dim=77, activation='relu',kernel_regularizer=regularizers.l2(0.1)))\n",
    "    model3.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(25, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(12, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(6, activation='relu'))\n",
    "    model3.add(keras.layers.Dense(3, activation='sigmoid'))\n",
    "    model3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history=model3.fit(X_scaledtr, Y_train, epochs=300, batch_size=1000, validation_data=(X_scaledte, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x432 with 0 Axes>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28288251940>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x282882515f8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2828a324320>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Model accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epoch')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2828b043b70>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2828a33d9b0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2828a33d668>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x282887d0f28>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Model loss')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Loss')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epoch')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2828814de80>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAGDCAYAAAB+yq7tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xec1NXV+PHPndnee1/YBZZelg6KIoJYY4sFjL1gnqjRJCbRJL/YEtM0sSQ+6hNRYyL23sEoRVDq0mGXsmxftvc2M/f3x52Zna3sLruU5bxfL1878613FnDmzDn3XKW1RgghhBBCCCHEqcNyvAcghBBCCCGEEOLYkkBQCCGEEEIIIU4xEggKIYQQQgghxClGAkEhhBBCCCGEOMVIICiEEEIIIYQQpxgJBIUQQgghhBDiFCOBoBADSCmVopTSSimvHhx7o1JqzbEYlxBCCHEy66/3195cR4jBRgJBIZyUUtlKqWalVFS77RnON4mU4zMyIYQQ4uQl769CnJgkEBSirYPAYtcTpdQEwP/4DefEIN+UCiGEOEry/irECUYCQSHaegW43uP5DcC/PA9QSoUqpf6llCpRSh1SSv1GKWVx7rMqpR5TSpUqpQ4AF3Zy7gtKqUKlVL5S6ndKKWtPBqaUelMpVaSUqlJKrVJKjfPY56+Uetw5niql1BqllL9z3xyl1FqlVKVSKlcpdaNz+9dKqVs9rtGmdMb5Le0dSqksIMu57UnnNaqVUpuUUmd4HG9VSv1KKbVfKVXj3J+slPqHUurxdq/lQ6XUPT153UIIIQaFE/b9td11EpRSHyilypVS+5RSt3nsm6GU2uh8DyxWSv3Vud1PKfVvpVSZ8712g1Iqtrf3FuJYk0BQiLa+BUKUUmOcbyBXA/9ud8zTQCgwDJiLeWO7ybnvNuAiYDIwDbii3bkvAzZghPOYhcCt9MynQBoQA2wG/uOx7zFgKnAaEAH8AnAopYY4z3saiAbSgYwe3g/gUmAmMNb5fIPzGhHAq8CbSik/576fYr7tvQAIAW4G6p2vebHHm3kUMB9Y1otxCCGEOLmdyO+vnpYBeUCC8x6PKqXmO/c9CTyptQ4BhgNvOLff4Bx3MhAJ/BBo6MO9hTimJBAUoiPXt5bnAHuAfNcOjzev+7XWNVrrbOBx4DrnIVcBT2itc7XW5cAfPM6NBc4H7tFa12mtDwN/Axb1ZFBa66XOezYBDwKTnN+AWjBB191a63yttV1rvdZ53A+AFVrrZVrrFq11mda6N4HgH7TW5VrrBucY/u28hk1r/TjgC4xyHnsr8But9V5tbHUeux6owgR/OF/v11rr4l6MQwghxMnvhHx/9bhOMjAH+KXWutH5fvlPjzG0ACOUUlFa61qt9bce2yOBEc734E1a6+re3FuI40Hm/QjR0SvAKiCVdmUrQBTgAxzy2HYISHQ+TgBy2+1zGQp4A4VKKdc2S7vjO+V8g/w9cCUms+fwGI8v4Afs7+TU5C6291SbsSmlfoYJ+BIAjcn8uSb/d3evl4FrgeXOn08exZiEEEKcnE6499d2EoByrXVNu/tMcz6+BXgY2KOUOgg8pLX+yPm6koHXlFJhmEznr7XWLb28vxDHlGQEhWhHa30IM6n9AuCddrtLMd/8DfXYNoTWbzULMW8GnvtccoEmIEprHeb8L0RrPY4juwa4BFiAKT9JcW5XzjE1YspU2svtYjtAHRDg8Tyuk2O064FzPuAvMd/KhmutwzCZPte7bnf3+jdwiVJqEjAGeK+L44QQQgxSJ+j7q6cCIEIpFdzZGLTWWVrrxZgpGn8C3lJKBTorbh7SWo/FTNG4iLbzIYU4IUkgKETnbgHO1lrXeW7UWtsxcwJ+r5QKVkoNxcyNc81zeAP4sVIqSSkVDtzncW4h8AXwuFIqRCllUUoNV0rN7cF4gjFvcmWY4O1Rj+s6gKXAX52T3K1KqdlKKV/MPMIFSqmrlFJeSqlIpVS689QM4HKlVIBSaoTzNR9pDDagBPBSSv0WkxF0+SfwiFIqTRkTlVKRzjHmYeYXvgK87So1FUIIcco50d5fPceQC6wF/uBsADPROd7/ACilrlVKRTvfdyudp9mVUvOUUhOc1TvVmIDW3pt7C3E8SCAoRCe01vu11hu72H0XJpt2AFiDaZqy1Lnv/4DPga2Yhi7tv/G8HlP6sguoAN4C4nswpH9hylPyned+227/vcB2TLBVjvmm0qK1zsF88/oz5/YMYJLznL8BzUAxpnTzP3Tvc0zjmUznWBppW3bzV8wb9ReYN8IXaNsa/GVgAiYYFEIIcQo6Ad9f21uMqbopAN4FHtBaL3fuOw/YqZSqxUxxWKS1bsRU1LyFee/bDaykYyMcIU44Smt95KOEEOIoKaXOxLwxpji/TRVCCCGEEMeJZASFEANOKeUN3A38U4JAIYQQQojjTwJBIcSAUkqNwcyliAeeOM7DEUIIIYQQSGmoEEIIIYQQQpxyJCMohBBCCCGEEKcYCQSFEEIIIYQQ4hTjdbwH0F+ioqJ0SkrK8R6GEEKIY2DTpk2lWuvo4z2Ok4W8RwohxKmhN++PgyYQTElJYePGrpalEUIIMZgopQ4d7zGcTOQ9UgghTg29eX+U0lAhhBBCCCGEOMVIICiEEEIIIYQQpxgJBIUQQgghhBDiFDNo5ggKIYQQQgghTk0tLS3k5eXR2Nh4vIdyTPj5+ZGUlIS3t3efryGBoBBCCCGEEOKklpeXR3BwMCkpKSiljvdwBpTWmrKyMvLy8khNTe3zdaQ0VAghhBBCCHFSa2xsJDIyctAHgQBKKSIjI486+ymBoBBCCCGEEOKkdyoEgS798VolEBRCCCGEEEKIo1BWVkZ6ejrp6enExcWRmJjoft7c3Nyja9x0003s3bt3gEfaSuYICiGEEEIIIcRRiIyMJCMjA4AHH3yQoKAg7r333jbHaK3RWmOxdJ6Le/HFFwd8nJ4kIyiEEEIIIYQQA2Dfvn2MHz+eH/7wh0yZMoXCwkKWLFnCtGnTGDduHA8//LD72Dlz5pCRkYHNZiMsLIz77ruPSZMmMXv2bA4fPtzvY5OMoBBCCCGEEGLQeOjDnewqqO7Xa45NCOGB743r07m7du3ixRdf5NlnnwXgj3/8IxEREdhsNubNm8cVV1zB2LFj25xTVVXF3Llz+eMf/8hPf/pTli5dyn333XfUr8OTZASFEGIQyy6to6HZPqD3aGyxU1rbNKD3EMdXTlk9X+05jN2hj/dQhBDipDN8+HCmT5/ufr5s2TKmTJnClClT2L17N7t27epwjr+/P+effz4AU6dOJTs7u9/HJRlBIYQYJD7eVsjuwmruPXcUAKW1TSx8YhV3nDWCuxekDdh9n/lqH69tyOW7X80/pTq2HU9KqZ8AtwIa2A7cpLUesFWUP95eyJ8+28Puh8/D38c6ULcRQoh+0dfM3UAJDAx0P87KyuLJJ59k/fr1hIWFce2113a6DISPj4/7sdVqxWaz9fu4JCMohBCDxNub83h25X53BvD9jAKabQ6251d1OLbF7uB//r2JDdnlPbp2WW0TX+818xO25FTg8MgM7Syo5nBNE9UN/f8mJTpSSiUCPwamaa3HA1Zg0UDe08tiAnybwzGQtxFCiEGvurqa4OBgQkJCKCws5PPPPz9uY5FAUAghBonc8npsDs3WvEoA3tqUB8De4o7zJLbmVvLpjiL++kVmp9fKr2xoE+z979f7ufHFDazYVcxlz6zlo+2F7n0Hy+oAKKhqcG/7ZHshmcU1ALyzOY/znlhFk82O1lJa2E+8AH+llBcQABQM5M0szkBQ4kAhhDg6U6ZMYezYsYwfP57bbruN008//biNRUpDhRDiJPDZjkKSwgMYnxja6X6tNXkVJhDbdKiCYD8vdhdWkxTuT255A3VNNgJ9W/+Xv25/mfl5oIzM4hpGxga79+WW1zPvsa/569XpXDwpAYDNORUAPPaFWd/o2wNlXDwpAZvdQW55PQCFVQ2MiQ+hprGFHy/bwrSUcJ5ePIUHPthJTaON9QfL+cnrW3nkknGcPyG+n39Dpw6tdb5S6jEgB2gAvtBaf9H+OKXUEmAJwJAhQ47qnlZnxa9dAnkhhDiiBx980P14xIgR7mUlwCwE/8orr3R63po1a9yPKysr3Y8XLVrEokX9X/ghGUEhhOijJpud7NI69/O6JlunGa+jzYI1NNv58WsZ/Pnzve7rlbVrzlJW10xDiykJ3XSogrc25eFjtfDjs83cwMziGtZklfKLt7bS0Gxn7f4yhkYG4ONl4dXvctpca92BMpNZzDVvQs02Bzuc3df2FJks30ZnSWlhVSMtdvP6CirNHIe1+8353x4o545XN1PbZEpG//NtDqW1TUQE+iD6TikVDlwCpAIJQKBS6tr2x2mtn9daT9NaT4uOjj6qe1qdGUFpFiOEEIOHBIJCCNFHT32ZxXlPrqKh2c6arFKm/m45T6zIanPMxuxyJj+ynL1FNVQ1tGCzd11b9/SXWTz1ZVabkkww2bdmm4NN2eXY7A7+ufog03+/gve25PPoJ7vJq6h3Z+Vign3ZkF3Oe1vyOWdsLDNSIwATCC7bkMMbG/O4+aUNbMqp4JwxscwbFc2nOwrb3HPDwXL3Of/vvR0seWUjzTYHAc4mIUG+XmQW17L4+W+5/53t7vMKKk1GclVmCf7eVqwWxfqD5dx33mj8va0s312Ml0UxMSmsr79yYSwADmqtS7TWLcA7wGkDeUN3aahkBIUQYtCQQFAIIfpAa817WwpobHGwZl8pt7y8gWabg+dXHXAvpdBks/PLt7dRWd/CpkMVXPjUau5atqXTDGF+ZQN/W5HJX5dn8su3t7XZ52rSUtdsZ0tuJc+tOoBDwz2vZ/D8qgO89E02uc6y0J+eMxKLUlTUt3DF1CSGRATg521hT1ENGTmVJIX7szmngmabg7NGxXD++HiKq5vIyGstQXE1kNldWMMbG3P5em8JAItnmPLCG04bCpjM4Zp9pQAE+FgprGpEa83KzBJOHxHFbWcM46bTU1hy5jBGxwdjd2jGJYRI18mjlwPMUkoFKNOmdT6weyBvaFWSERRCiMFG5ggKIUQfbM2rIt+ZAfvXumyabA6eWjyZe17bwtNfZvGbi8bysze2sr+kDosywVVeRQN5FQ3ctWwLo2KDWTJ3GJ9uL+LiSQksc5Znfm9SAm9tzuMn54wkOtiX/1t9gE92FDEhMZTt+VX8v/d2UFrbxB8vn8A3+8vILKphVVYJ4c5yy+9NSuD8CfFk5FZyZloUSikmJ4fz8bZCDtc08f8uGsu1s4ZQVNXI0MhAqhpa8LYqPttRBJisZHZZPTHBvhyuMQGtv7eV8ABvfjw/jdgQX66ZOZT/fJdDenIYX+8tIcDHytj4EAoqG3jsi73mNZ49gqunt85LGxMfwpacSiYPCT+Gf0qDk9b6O6XUW8BmwAZsAZ4fyHtapDRUCCEGHckICiFOGOsPlnPLSxto6aZ8cqDkltdz3Qvfsc0jM+bS2GLnjQ25bco6P9xagI/Vgo+XhTX7SvHztnDB+DiunTWUf317iCv+dy0fbSvk/vNHMzI2mBW7iwGIDPTho22FPL48k798tpd7Xs9gZWYJr2/MZd6oGH6+cBRam06bK/eW8OfP9lLd0MLtc4eREhnAnqIa5o+O4erpyTy9eDLfn5pIZnEtG7PLiQz0IdDXi1B/b+aOjHav6XfZ5ER3UDdlSBi+XlaGRpo1jcyxMby+IZdfv7uD1VmlWC2KG09PAUApeO+O03np5hmE+nuz5MzhBPl6se6++bx443TGJ4aQFhNEQpg/3x0s5x9f7WfxjCFcOTW5ze9wbHwIAFOHSiDYH7TWD2itR2utx2utr9NaNx35rL5zZQSlNFQIIQYPyQgKIQac3aHdzSa689qGHL7cc5i9RTVddsccKI9+spvVWaUcKKnj4x/PYcXuw3y2o4ixCSFYleJvKzKJDPJh/phYmm0O3tuSz9mjY8itqGdnQTUTEkPxslr45XmjWZlZwu6iGh67chJXTE1iW16Vu8nKRz+eQ0OznbMfX8k/1xwE4OV12ZTUNHHRpHiGRAYwMzWCNzflcfqIKAJ8rGz57Tn4eplyytzyBm47I9Ud5J05MppHP9nD15klXc69O39CHL/9YAcOB4xNCOmw/xfnjeL8J1ezu7CaP31/ApdOTqSoqpE/f7aXsfEhjIoL7nCOq7zzn9dPp8Xu4OW12QCkxQTxu0vHuzNILueMjeW7g+WcOfLompaI40OaxQghxOAjgaAQYkA5HJrLnvmGQB8vnr9+KsF+3h2OeXltNi12B2uyzHyz7flVXQaCjS12fv/xbv675zC/umAMF048+mUINudU8OmOIi6aGM8n2wt5Yc1BXt+QS0OLnRW7i3HFNBm5lcwfE8vyXcWU1TWzaEYyH2QUsLOgmvRkE4QF+nrx5u2zaWxxMCQyAIBh0Sb7FhHoQ1yIH0oppqeEsyG7AovCPQfvtOFRAFw7ayh3LdtCQWUuc0fGuIPAiyYmdBj7qNhgJiWHUVnfzKLpyR32AwT7eXPtzKEcrmlyX8vTyNhgfrIgjVVZpVw+JQlvq4Xk8ADCA0xmsTtxoX4AhAWYP9e7F6R1GvTHhvjx9OLJ3V5LnLgkEBRCiO6VlZUxf/58AIqKirBarbg6Nq9fvx4fn551zF66dCkXXHABcXFxAzZWFwkEhRAD6otdxWzLqwLgymfX8cwPpjAsOqjNMS9+c5BD5fW4qs625VWxeEbn11v6zUFe+fYQQb5evL4xl0nJoTTbHKRGBVLTZCPEI9AsqGzAalHEhphgpaiqkSueXctjV05i1rBI93HrnV0yf3/ZBMpqm3npm2xqmmw8fuUkVmaW8NG2AqKCfMjIrURrzctrs0kM8+eMtGh3pm9Scms2LsZ5PxdXIDgyNsidybtlTirVDTamDA1j2fpc0mKC3OO8YEI8T6zIZH9JHXNHdR+IKaV4/44jL0b7m4vGdrv/zrPTuNO51ASYOWGf33MmIf4dA/fO3HR6KuMSQzlLMn6DkjsQlNJQIYToVGRkpHu9wAcffJCgoCDuvffeXl9n6dKlTJky5ZgEgjJHUAjRJ3VNNp75eh9NNnun+13z6Z5btZ/kCH+W3jiNoupGrnh2nXtdOTAZvhyPIHBYVCA78qs6XO9ASS1/+XwPz369n7NHx7B4RjLr9pey6PlvufCpNdz68kYmPfQFt768kZrGFgD+59+bWPx/33KorI63N+XxxsZc8ioa3GWML6w5yCMf7SK7tI6oIF9C/b05f0IcNU02lIKzRkXzt6vTWfnzeZwzNo6tuZV8sLWA9dnl3D53GFaLYu7IaEbFBrcJLNsbFmUC39FxrWWZ542P5/OfnMnckTEAnD4iyr3PalH8/NzRBPpYmT865kh/FAMmJsQPP++edfgM9PVi3qgYd6ArBheLdA0VQog+e/nll5kxYwbp6en86Ec/wuFwYLPZuO6665gwYQLjx4/nqaee4vXXXycjI4Orr76a9PR0mpubB3RckhEUQvTJsvU5/PmzvaTFBHPO2Fj39oq6Zh76cCef7SziT9+fyJacSn570VjOHh3L0hunc/kza3ltfQ63njEMgIOldTg0TEwKJcjXi4lJYbyw5gBNNnubMsZ/rTvES2uz8bYq7l04itomG/+3+iB5FQ1EBvrw5Z7DXDghno+3F/JeRgHfn5LI9vwqHBrOf3I19c12fLzMd19f7j5MZX0zb2/KI7usjnEJIaRGmTLOc8fF8cAHO5mcHEZkkC8AyREBpCeHsmx9Dr9+dwfjE0P4wUyzhMKY+BA+/8mZ3f6u0mKDiA/147ThHYPF2cMjmZAYyiXpbcs+zxsfx8Kx53aYayfE8eDKCDqOfR8nIYTovU/vg6LtRz6uN+ImwPl/7PVpO3bs4N1332Xt2rV4eXmxZMkSXnvtNYYPH05paSnbt5txVlZWEhYWxtNPP83f//530tPT+3f8nZBAUAjRRmOLnWa7o02JZXtaa97alAeYRcddgWBeRT3Xv7Ce3Ip6FIpfvr0NL4vi0smJAEwZEs7M1AieXXmAktom7pw3gqzDtQD8+YqJjI4L4eNthbTYNVnFtW3mCe4vqWV8YgivLZlNkK8XNruDqCAfUqMCee66aeRV1DMhMZTdj1fzxc4i0mKCcGjTFbOhxc7UoeFsOlTB7XOH8dzKA7y3JZ99JbU02xxsyank8ilmjLEhfty7cBTj2jVVmeJc9iAswJsnF03uUfMblwAfL9bdP7/TfaH+3nx415xO90kQKE4UVmf9kJSGCiFE76xYsYINGzYwbdo0ABoaGkhOTubcc89l79693H333VxwwQUsXLjwmI9NAkEhTiHvZ+QzOq7zLpBgGrtc98J37C2q4cnFk5k3qvOyRM8umFnFNe7tj32+l+LqRl69bRbvbM5j2fpcFoyJJSKwdYL0T88Zyc/e3MpzKw8QHeRLdUMLFgWpUWYe3ag4U0aZWVzDna9uJtTfm0cvn8D+w7XMHBZJkK/535aX1cIbt88m1N+biEAf9z0Wjovjn6sPuIPI9+84HQ1EBvmwYlcxF09K4LMdRfxr3SGabSa9YXNoUpz3B7hj3ogOrzktNpgXb5zOxKRQd6ZQiFOFlIYKIU4qfcjcDRStNTfffDOPPPJIh33btm3j008/5amnnuLtt9/m+ecHdEnYDmSOoBCnCLtD8/M3t/Hcqv1dHvOf9TlsyK7A38fKbS9vZN3+MrTWvL4hh625Zn29oqpG7lq2hbAAb6YMCSOzuNZ9/u7CGmYNi2R6SgQ3n56Kr5eFH8wc0uYeM4dFsuaXZzMxKZS3N+eTdbiWoZGB7jLQIRGBWC2Kr/aWkF1Wz9a8Kn72xlYKqhoZEdO2ycyw6KAOQdm542KxOUxDl5TIAFKiAkmNCiTEz5vLpyThZbVw2vAoDpTWtb2WRyDYlXmjYyQIFKckd2moZASFEKJXFixYwBtvvEFpqemMXlZWRk5ODiUlJWitufLKK3nooYfYvHkzAMHBwdTU1HR3yX4zoIGgUuo8pdRepdQ+pdR9nez/m1Iqw/lfplKq0mPfDUqpLOd/NwzkOIU4FRRUNtBsd5BTVt/pfq01z369nxmpESz/6VxSogL50X828XVmCb98ezuX/OMbFj//Lec+sYqy2iZeumkG01Ii2FdSi92hsdkdHCitZUSsCdbSYoPZ9uBC5nXR7OSKqUnsLqxmTVZpmwDPx8vC0MgAVuwyC7CfNaq1M+fw6CMHa+nJYVw5NYn6ZjuTh3S+eLlrrp6XRTHamR1NjQrq9FghROuC8pIRFEKI3pkwYQIPPPAACxYsYOLEiSxcuJDi4mJyc3M588wzSU9P57bbbuPRRx8F4KabbuLWW289uZvFKKWswD+Ac4A8YINS6gOt9S7XMVrrn3gcfxcw2fk4AngAmAZoYJPz3IqBGq8Qg112mcmAHSo3geCHWwt4PyOfZ6+dipfVQm55A/mVDfxw7jBC/Lz5xzVTOPeJVdzzWgY+XhZunZPKf/ccZmJSKA98bxwjYoLIKq6h2ebgUFkdGmixa9JiWstOO1uzzuV7ExP46/JMfKwWLp7UtlHK8OggDpTUYVFw65xh7nX22mcEO6OU4s9XTOTs0TFdrkXo6vA5PDqIKUPD2Vtcw1Dnmn9CiI5am8VIICiEEEfy4IMPtnl+zTXXcM0113Q4bsuWLR22XXXVVVx11VUDNbQ2BnKO4Axgn9b6AIBS6jXgEmBXF8cvxgR/AOcCy7XW5c5zlwPnAcsGcLxCnLTqm20E+HT/zznbWQpZUtPEJ9sLuef1DOwOTWZxLWMTQvj2QBnQGiSNijPdQJfvKuaCCXH84rzR/OK80W2uOTLWBH17imrcc4hGxvYssxYe6MOm35zTadOVETFBLN9VTGpUILOGRRDs50VDs52hkUfOCIIJBs+f0PVC89HBvsxIiWBMfDC3zBnG7GGRPV4mQYhTkevfqU0CQSGEGDQGMhBMBHI9nucBMzs7UCk1FEgF/tvNuYmdnLcEWAIwZMiQ9ruFOCWsyizh+qXrmZESQaCvlR/OHc7Mdmva2ewOsj1KQh/8YCeh/t6U1zWzNa/SBIIHy4gM9GmTdfvRWcP5as9hFk3v/N/XqLhgooJ8eembbM5IM+vgDY/ueYllV503XdcYEx+Cl9XCOWNi2V9Si7e1/6rZly2ZhUWZoHGIZAOF6JZFFpQXQohBZyDnCHb2Ca+rd5BFwFtaa9fK1D06V2v9vNZ6mtZ6WnR0dB+HKcTJ7eu9JfhYLdQ02diaV8Udr27h/Yx8PtxaQH2zjcziGsY98Dmf7SjC22r+aR2uaeLS9ETCArzJyKlEa813B8qZOSyizYLgk4eEk/HAQs4c2fm/Lz9vK3cvSGN9djnL1ueQGOZPoO/Rf7/kCkbHOpdwePTyCfz71k6/R+ozq0XJ4udC9JBrjqCUhgohxOAxkIFgHpDs8TwJKOji2EW0LfvszblCnNI25VSQPiSMT+8+g1dumUFlfTN3v5bBXcu2cNk/1rL+YDlNNgf5lQ1MGxrhPu+MtCgmJYWxNa+S9QfLya9s6HS5iKAjBHaLpicza1gEBVWNTEzqfE5eb42ND+HaWUP43kQzd9DP20pwN+saCiEGlit7L81ihBAnMn0KVS30x2sdyNLQDUCaUioVyMcEex1mSSqlRgHhwDqPzZ8DjyqlXC3/FgL3D+BYhTjpLFufw7a8SnbmV3HbmcMAGJcQyr9unoFda7bkVPLX5Zms2F3sPmdicih7iqqpabQxIzWCLbmV/P2/WTy7cj8hfl5cNDGhq9t1ydtq4bUlsymqaiTYr3/+l+LjZeF3l07ol2sJIY6eaw6wLB8hhDhR+fn5UVZWRmRk5KCv+NFaU1ZWhp+f31FdZ8ACQa21TSl1JyaoswJLtdY7lVIPAxu11h84D10MvKY9wlqtdblS6hFMMAnwsKtxjBCnmq25lTzz9T5a7JrfXjTWvfD5/60+wIES0wBm2tDWZRJOG2Hm6oUH+PDX5ZmsyixhWHQgtY02pg+NICOnEotSBPp6MXdkNE//N4uv9pZw8+mp+Pv0vWFKXOjR/c9ICHHias0IHueBCCFEF5KSksjGSuAJAAAgAElEQVTLy6OkpOR4D+WY8PPzIykp6aiuMZAZQbTWnwCftNv223bPH+zi3KXA0gEbnBAnga25lfzgn9/h522hyebg+qXrGRoZwFmjYjhQUoevl4Vmu6PT9fJGxQXj42Wh2eZg9rBIfnfpeJRSTEoOw9WjZerQcD66aw6f7yjiutkpx/bFCSFOGq4+TdIsRghxovL29iY1NfV4D+OkMqCBoBCi7xpb7Pz4tS2E+nvz1v/MJr+igeuXrqekponVWaUAvHTTDBpabEQE+nQ439tqYXxCCJtzKhkdF+wuk4gO9m1z3LiEUMYl9M/cPiHE4GSRZjFCCDHoDGSzGCHEEfz1i7385r3tbM6p4OK/r6Gyvtm974kVWRwqq+cvV0wkPtSfaSkRbHtgIa/cMgOAhFA/Zg2L4OzRsV1ef2JSGACj4kIG9oUIIQY1L4v5uCDrCAohxOAhGUEhjpPi6kb+d+V+LEqhUGzLq+L9jAJuOC2FT7cX8uzK/Syekeye8wfgZbUwLSWCJWcOIyHU74iToc8fH8f6g+WMS5BAUAjRd844UDKCQggxiEggKMRx8s/VB2ixa0DzzuY8AN7enMcNp6XwwAc7mZQUygPfG9fpub+6YEyP7jFzWCSf3H1Gfw1ZCHGKssqC8kIIMehIaagQx8EfP93D/60+yFznQu11zXZign3ZllfFxuxyDtc08b1JCfh5972LpxBC9BfXgvKyjqAQQgweEggKcYztLarh2ZX7+f6UJJ6/firDos1yEHfNTwNg2fpcAPd2IYQ43iwWWUdQCCEGGwkEhTjG3tyYi7dV8esLx+DrZWVGSgQWBZekJxDs58UXO4sAGBYVdJxHKoQQhmQEhRBi8JFAUIgBVlrbxP6SWgBa7A7ey8hn/uhY95IPdy9IY+mN0wnx82ZsfAg1TTZ8rBaSwv2P57CFEMLNYpFAUAghBhsJBIUYQIVVDVz6j2+4/oX1AGTkVlJa28wl6QnuY+JD/TlrVAyAez2/oZEBeFnln6cQ4sRgldJQIYQYdOSTphD9rMXu4L63t7E1t5Lb/rWRvIoG8isbKKlpYtOhCgCmp0Z0eu74RLPMw/BoKQsVQpw4WktDj/NAhBBC9BtZPkKIo/DY53sZnxiC1rAqq4RHL5vAroJqXtuQy3sZ+TS2OLhu1lBe+fYQOwuq2HyogqGRAUQF+cJn90PkCJh+i/t6roygNIoRQpxI3MtHOCQSFEKIwUICQSH6aEtOBX//ah9j4kPwsSq25lVx1bRkdhVWA9BkczB7WCT3njvKGQhWszmnkjPSnAvE73of4tPbBIIjYoK4dtYQvjcpobNbCiHEcdEaCB7ngQghhOg3EggK0UdP/3cfALudgR/Aq9/l4O1lIdTfm1dvm0lyRAAhft4MjQzgsx1FlNY2MWVImDm4sQqaqttc02pR/O7SCcfsNQghRE8440BZUF4IIQYRmSMoRCe01mTkVtJs6/j1t9aaRz/ZzX/3HGbxjCHu7bOGRfDhtgK+3V/G2PgQxiWEEuLnDcD4hFC251cBMHNYJNht0FwLTTXH5gUJIQYNpdQopVSGx3/VSql7BvieWBQ4pGuoEEIMGhIICtGJl9Zmc+k/vuGe17d0+OCzbn8Zz686wLWzhvC7S8czMSmUtJggfnfpeJptDg6U1rmbvrjMHh6Jt1Xx2JWTGBkb3JoJbJcRFEKII9Fa79Vap2ut04GpQD3w7kDf12pRkhEUQohBREpDhWhnd2E1j3y0i5TIAD7ZXsRdags/O2ckSeEB+HhZ+Hh7IQE+Vn5z4VisFsUzP5iCwwFDIgO4bHISb2/Oczd9cfnBzCFcNjmRQF/nP7nGSvNTMoJCiKMzH9ivtT400DeyKCUZQSGEGEQkEBSnvBe/OcjY+BBTsgmszirBoeHNH57GGxtz+dvyTD7eVkhYgDfXzhzK5zuLmDc6Bj9vKwBJ4QHua9177kia7Q7mJlnA4QCLSborpVqDQDDzA0ECQSHE0VoELDsWN7JalCwoL4QQg4iUhopB42BpHQWVDV3udzg02lnWdKisjqufW8e+wzX87uPd3PHqZsrrmnE4NFtzq0iO8Cc62Jc75o3gs3vO5C9XTGRWaiR//2ofpbXNnD8+rtN7xIf68/RFCYQ/lw673ut6sK5A0NYItuY+v2YhxKlLKeUDXAy82cX+JUqpjUqpjSUlJUd9P6uS0lAhhBhMJCMoTlq55fXc83oGf7h8AmkxQdz44nqSwv158cYZPLEikzc35fHHyycwf0wsf/hkN//+9hDJEQE8d91UHvloF98dLOfPn+3F7tCU1jYz7XfLSYsJpqaxhSlDw933GRETxIiYIK6clsyarFK+2FXEgjGx3QzsWxPglWbBWzeDXxhc9Ne2xzR6zA1srgWvzheYF0KIbpwPbNZaF3e2U2v9PPA8wLRp0446grNapTRUCCEGE8kIiqPSYndwuLrxuNz7m32lbDpUwcV/X8OO/GoOldWz6VAFf/9vFs98vR+LgiWvbOKjbQU8v/oA6UPCKKpuZN5jX7Ni92EAvthlPj898L2xnD8+nr3FNRRUNZKeHNbpPeekRfHwJePdZaGdyttgftYWQ+4GOPBVx2NcGUFobRhTlQd/SoGSvb39VQghTk2LOUZloWAygjYJBIUQYtCQQFAclae/zOLsx1dS12Tr9bmfbi/kvCdWdTj3y93FvLkx94jnZ5fVA9DY4mDJKxvdj19Yc5AZKRF8+bOzCA/w5udvbkNreOjicXx45xzuPDuNG09L4ftTkgBIiQzgptNTeXJROolh/gBM6iIQ7JFcZyBYUwQ1hVCRDS3tSlbbBILOeYKVOdBQAeUH+n5vIcQpQSkVAJwDvHOs7mmxKBxSGiqEEIOGBIKiz7TWfLitkNomG9/sKz3i8QdKatusy7d8dzF7imp4a1Nem+P+9NkeHvviyFmxAyW1jIgJYtH0ZAqrGt1BXF2znYXjYgny9eLaWUNpaLEzMjaIETHBJEcE8NNzRvLgxeM4a1Q0gDv752W1cMe8EUQG+jC+XdfPHrM1Q2GGeXx4FzhaQDtMmWhVvikVbarpPBC0tzh/ypxBIUT3tNb1WutIrXXVkY/uH1YlzWKEEGIwkUDwFPDqdzk8/OGuDtt/8dZW/vHVPgB3E5XeyDpcy8HSOgC+2lvS7QeE5buKOfvxlVz+v9+QW24yeTvzTUnkC2sO8sbGXBqa7RRXN5JZXEtxdRNVDS3d3v9AaR3DogK5//wxJIX7c8NpQ0mJNB08F441zVx+MHMoQb5eXDo5scP5s4dH4u9t5fQRUe5t18wcwoZfL8Dfp5vSz+4c3mnmB/oEQ8XB1u0le2H/l7DjbTi0tm0g6Jov6A4Eu3/dQghxPJiuocd7FEIIIfqLNIsZ5Gx2B39bkUlZbRP3nJNGiJ83AA3Ndt7enI9Fwd6iGnbkV/H+nacT7Nx/JDe9uJ7vDpYDMHVoOMvW57BsfQ7v3XF6h/l1h2sa+dkbGQyPDiSnrJ4bXlzPa0tmkXW4hrHxIewqrOYXb22juKqRBGdWD2DzoQr2Ha7liqlJhAf6dHhdh8rqWDAmltAAb1b/Yh5KKaoaWsjIrWSIMyCMDvZlzS/ndfq6ooJ8WXf/2e7fiYvFonr0O+hUsTPgTj0T9n7cur1kN1ic/9yKtneeEXRIRlAIceKyWJDSUCGEGEQkEByk7A6N1aJYmVlCSU0TAG9vyiOzuIZb5qRSVtuM3aGxAx9sLQDgma/388vzRh/x2lX1LXydWUJUkC/njI3l7NExbDpUAUBGTkWHQHDFrsNUN9p4/fbZVNa3cO0L33H9C+txaLh7QRoTEkP5+Vtb+fd3h5gyJBwfq4Vmu4PffrCD3PIGnl25n7f+5zRSowK5/53taK25fe5wWuyaYdGBgFmnD+Dn53Ycf1iAT4dtPdnXJ6V7weoDydNbA0HfUJMR9A0xz4t3QEsjBMZA3eHWZjFSGiqEOIFJaagQQgwuEggOQpX1zcz501f87ep03tmcR2SgDw0tdn738W7sDs07m/Pd8+N+fcEYmu0O9h+u5YXVB7lhdgo/fm0LPz1nJLOcC6x7XveOVzczITEMreGZH0xhekoEWmvSk8M474nV5Fa0NkV5c2Muq7NK0UBsiC+j44JRSnHP/DQeX54JwPjEUBLC/LllTio3v7SRT3cUsWh6Mu9uySe3vIHh0YHkVzbw7Nf7efjScby3JR8fL4t7+YbhzkDwhFGaBRHDIcRViqogZY6ZL+jaVrQdgmIhNMkZCLbLCMq6gkKIE5DFIusICiHEYCKB4EmiodlOi8PhLmOsqm9hwd9W8qsLRnPZ5KQ2x+4urKG2ycYn2wtZlVnCpZMTya9s4Ou9JVw/eyif7yzi853FDI0M4LYzhwHw7YEy3tmSz6vfHWL9wXI+21HUIRB8Zd0hvtlXxjf7ygjwsTIpyWT+lFIMjQwkKdyfvAoz/+9wdSMPfrCTumY73lbFBRPiUXkbIW48t88dzofbCiivayYh1A+As0bGsHhGMimRgdx4egrb8qrYVVjNJemJFFU38tamPOakRdHQYqehxc4nOwoBGB4dNHC/9N5y2E3mL248BMWYbYHRkJBusoOugK9svzk2Zgwoq0ezGGf3VMkICiFOQFYl6wgKIcRgIs1iThK/eW8HM3//JS+sMQ1I3t2SR0lNE+9szncfo7WmprGF/SW1AHy0rYC6ZjtzRkRxSXoCw6IDuffcUdwxbwQAU4a0Lpo+LsGULb62wSzbsKvAY8FzoLHFzktrswkPMIHojNQIfLza/vVJCvcnt9xkBJ/4MosWuybU35sWu+ai8Fx4YQGseQIfLwsv3TSDl26a4S7ptFgUf7h8IrfPHY6vl5W0WBPgzRsVw82np9Jsc/Drd7e77/XelnwmJYf1f2lnX638CzwcYZaKiBppMn4AIfEQP8k8risx+9CmkYxfGPgGyxxBIcRJwTSLkUBQCCEGCwkETxJbcitotNl55KNd5Fc2uAO27w6UU+tch++9jHxmPvolG7NNE5cWu0Yp0x3zsslJ/PdnZxHi583V05NZMCa2TSfNYD9vhkUHctg5n3BXYTUOh2bFrmKeWJHJ5zuLKKtr5qnFkzlvXByLZwzpMMbkiABynRnBjJxKTh8RyfWzhwIwq2a5OajeLDOREObP+MSul2hYODaOuSOjGZcQwoiYIH48P43qRhtTh4bj523BoeGcMTFH8yvtX+ueNj+1HaJGtQaCwfEQN7H1uHGXgZfJgmL1MvMG3RlBZwDYk66hOd+aElMhhDgWCjK4tPkjtL33a8YKIYQ4MUkgeAJoaLZ3WL6hsr6Z855YxZacCppsdg6V1XPhhHgAHvxgJ3uKargkPYFmu4PVmSWACb7qm+18sr2IQOfyB+MSQjpkzXy9rPzzhmnMHRndZvsEZ2BmtShqm2xkl9XxyMe7eGJFFi9+k010sC+nD4/i2eumcu64uA6vIzk8gJpGG1UNLeRV1JMcEcCdZ4/g3SVTCM563xzU0tj2JIe909/JhRPjefnmGe4OnvfMT+POeSO46+wR7nEuGBvb7e/1mApPbX0cPRL8w03TmOB4CI4zjWEAEqfCFUvN49BkZ0bQ1SymF6WhS8+FZ+f03/iFEKI7B77mh/XPoRxSsSCEEIOFBILHQWFVAw9/uIunv8yiuLqReY99zY0vbqDJ1hoUrT9Yzp6iGt7YmEt2aT12h+acsbGMjQ9h+a5i4kP9+P1lEwjx82JVlgkE95eYNf2a7Q7OGh1DYpg/547tGLB1xRVgzR9tgpbnVx3gUJkzw5dbyYIxsd0urZAUbpZ+2FVQTXWjjaRwf3y9rEyuXwdNzuUSaotaT/jyYXgkqkfNUSwWxb3njuKsUTGcNz6emakRjIoN7vxgrc1/x1JVnskEjlgA0aNBKbjsWZj1I/M43pkVDE2G0RfCnRvhtLvAL6Q1EOxLaag0bhBCHAsW8+WidkhGUAghBgsJBI+Ddzfn8tE3m3l8eSYXPrWGoupGVmaWcN/braV+2/JM4LR812Eyi03p4IiYIC6caLKCPz93FEG+XoxLCGVXodnvmhsIMDImmK/uPcs9H7AnZqRGAHDd7KF4WRSvbcglMtCHGSlm+8JxzgzcmiegYEuH85MjzNp96w6UAZAUbp6z811TKpm2EGqKzbbmelj9OGgH1BT0eIwAt8xJ5fXbZ7vnF3aQ8R94KAzWPdOr6/ZZc70peZ14JVz7Nnj5mu3jv2+ygwAJk0FZTKdQgKg08PZvO0ewL8tH1JX0z2sQQojuONdBVVoCQSGEGCwkEDxGPtleyNr9Zn5c8L4PWO13D788K4HS2ibOHx/H3fPTeHdLPl/sNBmzbflVKAWltU28uSkPpUyHzBtPS+HJRelcmm7m942KCyar2HQJLaxqJCrIlIEOiw7Ex8vSq8XRJyaF8e398zkjLZr7LxjDounJ/PmKidw1fwSzh0Vy2vBIqMqHFQ/AV3/ocH6yM/D7Zp95nYlh/ibIyfoCxl5iyiRdGcGM/7SeWJXf/lJH59Ba8/Pz+6F4Z/9euzPVzvGHdpw36Tb7Trj+A5MB9OTt31ou25eMoOv12VtgxYPQUNHzc4UQoqecgaC2d17OL4QQ4uQjy0ccA+V1zdz92hbsDs2jl03ApzwTX1pYMjuWoLAIzh0XS3iAD1/sKub+d7YzJj6EbXmVnDcuji93H2ZVZgmRgT74eZvSnEvSW5u8jI4Lpr7Zzsq9JjP0w7nDWb6rmJnDIvo01jjncg63zElts/2MNOd8woMrzc/9/4UP7zZBzOXPARAa4E1qVKB7cfmkcH/I+ghsjaZJyoGvoa7UzIVzBWvQGkj1l4pDziYs1VCyB2LH9e/126vMMT9Dk7o+xj8MUs/ouN3Lz/x+oOdzBD3LQQ/vhuHzzDqFa/5mGtOMv7znYxdCiJ5wloaqLuZ1CyGEOPlIRnCA5ZbX8+6WfFrsmuHRQTz2RSY+9SYrZkVz3ayhxAT74W218PTiybTYHVz13Doq61uYkxbF41eZpQe6Wi9vVJyZJ/fJdrOu3pkjo3n99tnEBPsNzAs6sBIs3iZ7tekl2P1hm8Bk9nCz9qC/t5WIQB/I/gZ8giF5prOTpjaLqDdUQIwzQKvK698xVhw0wRGYNfsGmmv8Ycm9P9fLF2ymU2uPu4a6jgcTAHpua2no/RiEEOJIlAkE0RIICiHEYCGB4ADKLa/njD9/xSMf7WJ8Ygi3zx1OaW0TUY4y5xFtG32MiAnihRun4+9txaJgRkoE35uUwAd3nu4OCNtLczZM+XJPMRYFQyMDBu4FaW0ygmMugojh5oNBSx1Ut87xO314FGCygUopyF0PSdPMt8nBzsY1NUUmEAxNNGvp9VdGMHsNHFpnrhczDkKSTCCYuwEaq/rnHp2pyjXz/4Lje3+uZ0awp6WhLfWtj92BYGPHfUII0V+cpaFddXoWQghx8pFAcACV17V+oF9y5nDOTDNBUpxyzuPSjg7nTE+JYMVP5/LdrxaQ1rAN7C1MTAozjVj2fgbv39Hm+CBfL5Ij/GlscTB/TCy+XtaBe0Hr/gE1hTB8Ptz4MVzxgtleluU+xJURTAp3zg88vBOSZzgH6wwEa4uhsdIssRCa1PUcQa2hMrfn43vpQnjxPPM4YhhEDoectbB0IXz3XG9eac/lbzZZz+AEsHr3/vw2GUFnaeiRuqh6Bnu1JW3P6c+MYOFWePaM1mY2QohTlzsQlGYxQggxWEggOIBa7CbQ+9fNM7h4UgIxIX6MjgsmTpkF3zsLBMEslRBtK4KXLoA9H5mNzfWw7GrY8m9oqm1z/NXTkrliahJPL548YK+FvI3wxa9hzMUwaRGExEOSM8ArbQ0EIwJ9uHJqEgvHxUH+JvMaXYFgsLPrqCsj6B8OIYldZwR3fwBPpUPt4d6PNyLVBIKVOWYMJXt7f42eeP1aE2z2dR6i1bf3GcFmZyDoF2oysgD2ASgNLdoORdugurD/rimEODk55whKICiEEIOHNIsZQC12U/rpZW3t3HnlhFCCVzs/rHe3Bpxrbbm6UmishuW/bd1XUwi+ae6nd56dxoA7vNv8XPhIa+YrJAG8A6FsX5tD/3Kls4x15euAgsRp5rlrUfXqAlOq6R8Ooc2Qv7HzexbvNB866ssgKKb78TnaBdXhqRDpsXRG+YHuz+8Le4t5LbN+BAse6ts1vPzMnBu7refLR7gygoExpiwVPOYI9mNpqGscjiPMWRRCDH6uZjEyR1AIIQYNyQgOIJszOPGxWkx2pbqAWyZ6NHHpIiNoTnZ+CG+qgTdvhE0vQqQz4OvvLps9UePMCnnOg1MKoka0ZgTbNzkp329KP/3DzHMvHwiIMp08wcwPDEkwgV5nmSxXN87mHgQ3TR5zAH1DICCiXSC43wTeLY0mI9kfaosBDVEjzWvrC9eag7ZGj0DwCIGXOxCMdp5nG5hmMa6/g71ZzkIIMTjJHEEhhBh0JBAcQK7SUG/dBM/OgVcua9NYpVuuD9/NtSYbN3ERXPO62XY8SvWqCyAgsjVwcYlMM4Fg+QF4NNE0a6k9bMpXqws6NlAJSYDiHeaxf7hp6ALwwjmtWUeXikPmZ0+yXHXOBjwpZ8D0W0yQmjDFzBWccKXJQDZUwMvfg8dH9e61d8UVUIYk9P0aXs4vBmxNvW8WE+Rc0qOlzqM0dAAygkcKTIUQg58rEJQF5YUQYtCQQHAAuUpDI7M/MRsqstsGgt1lBF0f7JtqTJloQGRrwHFcMoJFnXfFjB5tyhMzPzdj3rcC/jnflLJWF5i5hJ5Ck6D8oHnsHw7Dz4bxV5iM6e6P2h7rygi6ghuHvety2npnIHj6PbDgQfM4KBp+vAXGf988L9sPeet786q75/qzdHVD7YtOM4I9nCMY6AwEm+sGplmMBIJCCBfn8hEWyQgKIcSgIYHgALI5A8GITGcmLzINanoYCLo+2DdUmKygXyh4+5vgqbrAfOD/fTzsfG+ARt9OTSfZPYCkqYCGjUvN822vmwCueKcpJw1uly0LScC9bIZ/uGkgc8ULprzSc66grbk14HUFgg9HwNu3dj4+VyAYGNlxX8Rw87M/5gnWFMMXvzHBkbtctj8ygo2tTRh6PEfQMxB0LR/Rn4FgDwNTIcTgZ5F1BIUQYrCRQHAAtdgdhFNNQOF3ZkN9abuMYCfZrZois/aeKyPoOt4vxPwMSTTbDu8yAcGqxwbuBbQfV/vsHjgbwSgozTTPXc1LineaALb9OSGJrY/9w9teJ29j6++kOg93wNhc35oF2/FW2+s1VsOri8z6hmAyp+2FDzXr/HXVlKY3sr6AtU+b8taaQrB4d37PnnJnBJv60CzGFQjWDlBpqGtZC8kICnHKc5aGSrMYIYQYPCQQHEAtdgeTLM4sVNIM0wG0u9LQjFfN/LUXzmldAN0VWPmFmp/B8SY75yqbDBsycC/Axd5i5v11lhH0C2ldOiHQo7Nns3PtuQ4Zwa4CwSkmUN7wT1Mm6np9YIKbiuzOx7bpJcj8FLb8xzzvLCjz8oWwof2TPXV1c63KM3M1g+PAchT/jNpkBHvYLOaYlYY6xyFdQ4UQrkBQSkOFEGLQkEBwoJTt57TvfsRcy1Y0CkYsMB+o2zRE8cgIrnsG3vuf1ueuQNDVGMbXlRFMMMGkK1AKHzpgL8HN1R2zs0AQWtcJnHqj+RkQ1bqvwxxBj0DQFdwCJDmXmPjkXvj8V62NYsAEguX7zeMgj/l49hb47lnzuLkGvPzBJ7DzMY7/PtT1YT3C9twBen7X5bK90aeMoDPYcy2p0Vw/wM1ipDRUiFOerCMohBCDjgSCA2XXeySWrOImr8+xR440C5wDVB5qzVp5ZgR3vA3xk+ACZ6lnozPz5MrGuIKmkESoK2ldssEzmOpPeZtau2IeqTtm6pmm9HLSIpj7Szj39637OusaCuAbClaPZSxjx0PoEPN6CjKgLKu1S11LQ+v8Ps8xZK8x8whdv4PuSjSn3gA413NUR/HX3vXnUpXrbKBzFI1ioG1GsMeBYJ0pSfVzLsvRXDswy0dIsxghhIsrI4hkBIUQYrCQQHCgeJREOuIntw1SXOWRnnMEHTYTNPkGm+euEkQX1xxBV0bNNSeuJ2U6hVsh84uej72l0Syz8OkvzPMjdccce6npzhk5HOb9Ckae17qvffDo+r34twtgrd5wdwYs/L157RnLTDmtl58pfSxzZgQ9l6+odGYN0xaan501inEJGwLjLu16f0+1Lw09mqUjoG1G0BX023rQNdQ7oDX72Vw3QIFgD0tVhRCDn0W6hgohxGAjgeBA8SyfSZjcOp8LIDTZ/PTMCDps5htXV2DQ2D4QdAZOqWean67S0J6U6Tx3Jrx6Zc/HnrPWZJ2ylkPxLlj/vNnuOb/Pk1IQntL63D/MzP/zCzOdTj15+5nSUc/5gS4Wq5krCGa+4IizzfmeGUFXd0xwBqgKhs0zz4/UtOX7L8AZ93bfrfVIXKWhRdtMOWpXv5Oe6lNGsB582gWCrnN6WxraUAGf3tcaSHpybZPSUCGEc/kIaRYjhBCDhwSCA8UZoH1onwXjLm8XCLoygu0DQWtrYNBU1fZ6rjmCYUMgaXrr9iO9KTfV9n7s+740P1vqzZqABRlwziMQGNX9eZ7CU7vOloWntJ3r5ylqlMl2gZlX6R3onCPoXHuwxSMQrMqHoFiIm2CeHykQtFhb57n0lSsQdAWmyTOP7nptMoLOoN7R0vV6iWB+H97+4BNknjfX9n35iOxv4Lv/NV1Q23MFgDInSAjhLA21yILyQggxaHgd+RDRJ84A7aGWG7goJLpteZ07i9SuNLS7jKArEAQTWOZtcJ7XRSDocMD7P+rbfLh9X0LKGWYJiMZKuPFjGHpa764x9xdts3eeLn/elIJ2xuoF8elmOYq4SSbgaahwLidBu4xgvgmqo0aab6s9g+2uuH4fWptMZm95lux6B7ZmMAv484kAACAASURBVPuqTUbQI/NmbwEvn87PaWkw9/byMX9nPEtDbQ3mz76nnUzdwV4nf49kHUEhhItrzvbRVFQIIYQ4oUggOFBcH6wtVpRS5kO7X6jJKIUmmX3t5whavDwygjWt+3yC2jZWmXgVZK+GvZ90HQju/Ri2Lmt97rm0Q3caq6BkN0z8LUy5wQS0vQ0CAUad3/W+yOHdn3veH8w4LBZTAunZQbR9aWj0SFNuevUrrctYdMsZ/GmHu9SpVxqrndfQMGRW1wFtT7kDwaa2XxbYm7sOBJvrzO8FTHmoZ2komN+Ra/+RuJeI6ORbfukaKoRwcc0RlIygEEIMGhIIDhTnB2tl9Qg2AqPBbmud79cmELS3zQh6Zp7adwYNjILFy+CPQzsvDdUaVj9uSjDtLSZzZu0iqGjPVVroHw4TezGvsD8lpLc+9g6E8p3mcXCCyXiBeY3V+TD8bPN89IU9u7YrC9hd6WV3mqohYphZziJlTt+u4cldGtrYNhjrLvhqqW+dH+gT5MwIegTILQ09DwS7W7vQHQjKBz8hTnnuQFDmCAohxGAhcwQHijNTpzwzRgFRZl09d3liN3MEPUtDPctCPVmsnWcEy/ZDwRaYdQf8cA2MuZg2ZajdcZUY9jRwHGje/q3zJUMTW+cINlWbuXG97drpLgftQyCotclUDp8Hoy+CCVf0/hrtdZcR7IqrNBRMQNhS17bTaG8axnQ3D1AygkKcsJRSYUqpt5RSe5RSu5VSswf0hu7lIxzovn6RJoQQ4oQiGcGB4vxgbbF4/IrTrzHBi/IoT/Q83uLtEQh6NIvpaq1Ai1fnGcHDzgxa8nQIiDDn9/SN2xWMWH27P+5Y8cxshSRA3kbzWqryW7f1Sie/+57I22TWDnTYTGnvhY/38r5dsHqZElW7c/kI7wATyHUXfDXXtXZjdZeGenT97E3DGFe2TwJBIU42TwKfaa2vUEr5AD0sA+gj53uZFw7sDo2XtQ9zrIUQQpxQJBAcKM5MncVzbt/UG8zPA187N3QzR9Dzg71fFxlBZe38A/zh3YAyHTjBBJ49DXxcH/qPdu5bf/H2DAQTAe0sd3Wubeiab9lTfS0N/f/snXm8JGdd7p9fd3WfffY1mSQz2SAJ2WBMgCAQ1oAskU1Q1ACKooh6vS6o1wUFAb2oKKhhh4BsikRAuIAEhBCSSUgC2ZNJMjOZSWbmzHb27q5+7x/v+3ZVV1d3Vy9V1dX9fD+f86leqrve06fPOfX08/x+v2+9XQ+wB5o7tN3ijJtmMRWfEGwxu88f/axFQ0vaaVbVPjqCLeoHCSGpISKrADwdwFUAoJQqAYj3ExsjBPNw4SrFkwdCCBkCGA2NC+PUSS7s32WYI+jWC0HAE0FNHcG87hAZ5OCdwLodPjfNNDeJgjto0VDf9zC9WV+sLHldRDuOhtq3fIdC8Mhu77Vp9vPoFmfMRENLXu1fuxpBfzTUjo8YX2Pu78QRbCEEOUeQkEHldACHAHxERH4oIh8UkalYj2j+djpwQ//tEEIIyR4UgnFRraCKHApOyEvsH2Hg21/XCPoimZNmbl+rGsHQaOhdwKZz648X2RE0LlCzjpVJY4XgxBpPJFVWvGHyM1s7fMIuoqFuGTi2x7vedyFoHMFqub0QVEoLv7CuoRNWCHbgCFoB2LJZDIUgIQOGA+CJAP5JKXUxgAUAfxDcSUTeKCK7RGTXoUOHejuinSOIKlzWCBJCyFAQqxAUkStE5B4RuV9EGv5JmX1eJSJ3isgdIvIp3+2uiNxqvq6Nc52xUK3AlTwK+TAhGCJG3HKjIzi5Vsc/J9aGHyMsGlpe1s1i6oSgdFAjaKOhAyIEreCZXO/VxZWXdMfQ6c2dR1g7jYauzOvxFX7B3fdo6Jj+nlTVE76VJuKrNK/3s2K0MOnNEezJEWw1R5DRUEIGjH0A9imlfmCufx5aGNahlLpaKbVTKbVz48YIc1ZbEagRJIQQkn1ii/mLSB7A+wA8F/qf1k0icq1S6k7fPmcBeCuAy5RSR0XEP+xuSSl1EbJK1UUVOTihQjAknmhrBG3zEOUCzgTw6k/qAethhHUNPXyvfuymcwLHy3DXUEALQX+HzeNmmHyndBINdSvAey8GNpxVf3uzms1ucca14ATaO4K2m6wVgrZGEOJ9YNCVEKQjSEhWUEo9KiJ7ReRxSql7ADwbwJ3tHtcTZnxEHi6qFIKEEDIUxFnvfQmA+5VSuwFARD4N4KWo/2f1ywDep5Q6CgBKqYMxridZqi6qyKMQ1lktOD6iWgWgap+4whnXIwGcYuvB7BISDd1/i95uvdC/Y+fR0IERgkYY1QnBJW+YfMd0EA2dvQ9YOKi/7BoWZ+OpESxFFYKmm2xNCJoawXyxu2gou4YSklV+A8AnTcfQ3QBeF+vRas1iGA0lhJBhIc5o6MkA9vqu7zO3+TkbwNki8j0RuUFErvDdN25qG24QkSvDDtDX+od+U63ARZNoaFCM2JNw84lrrU6w3QiHnNPYLGbPDXpw/brTfYeLEA0tLQL3/r/Bi4ZaR3BinScEy8s6Grqqw46hQGfR0Ed/5FvHFHDaU/XlOLqGrszpyzUh2KRrqBWCdg0Ta/X7KI5mMa3uI4SkilLqVhP7vEApdaX9QDU2bLMYqdIRJISQISFOIRg2ZCj438MBcBaAZwJ4DYAPiog5m8WpSqmdAH4WwN+JyBkNT9bP+od+o1xUJQcn18oRNNdrQtDnCAL1jWPCyOUaT9L33ACccqlvcDqiRUPv/CLwqVd6TVEGRQhaYTS5DiiY12XhYHfD5IHOoqGP3u7tv+504OSd2hUs9rk5n1P0hKCtEWzmwq3YaKj5NZn2palr0dCF6MeuuX50BAkhLRBBVRzk4aJCIUgIIUNBnEJwH4BTfNe3Adgfss8XlVJlpdSDAO6BFoZQSu03290ArgNwcYxr7T/VClzkUAztGtrMETRC0AqedmIsGA2deww4+iBw6pODO0ZwBE00cXFWbwema2hIjeDsA3rbTY0gOnAED9wObLkA2Hw+sOV84Cm/Dvz6TfUiux84411EQ40jOOX7AGR8tX6uxSPRj11tEg2tut77M7iWr/4h8K4d0Y9BCBkKlOTYLIYQQoaIOIXgTQDOEpEdpobh1QCC3T//A8DlACAiG6CjortFZK2IjPluvwxxF8L3m2oFFeSbOIL2NlXbF0CjI9hOCOac+mYxe2/Q21Of0ni8dsLHrsE6U4PiCBZ8XUPt63Jkt96u6qZZTEQhqJSOhm45H7jqS8BP/V/doXRqfefHbIcz5jWLaecIBmsE/Y6gMwZMbQIWDjc+rrwMvPeJwEdfBBzf593erFmM//hBt/CG9wFLHYhNQshQoCSPHKqoskaQEEKGgtiEoFKqAuDNAL4G4C4An1VK3SEibxORl5jdvgZgVkTuBPAtAL+rlJoFcA6AXSJym7n9nf5uo5mgWkVVtekaWnMEjZgL1gi2c+VygfERJ4zh6q8PrB2vzT9uW5Nmo4eDIgTHfM5XX4RgxGjo3KNa7Gy5wMwwnGy9fy/Y5kBAdEew9roEheAGYCGkXnZxFjjyAPDQ/wD/8x7vdvtzDzqCtntsq7UQQkYKJQ4cuHQECSFkSIizayiUUl8B8JXAbX/iu6wA/C/z5d/negDnx7m22KlWUEEOxU6axdiZeDVHsE2NoOQDswjNCXtYbWG7LpnWERo0R/Cki4Gfvho489lanAEmGirAzJbun7fd62EFcRwOYBD/zyuKEMyPefHhyXVa3Kqqvn1qIzB3oPFxrk/YHff1cKoJwUD3WX+zmrDREoSQkUNJTo+PoCNICCFDQawD5Uca0zXUaTk+olk0dKx+24xcrv4E3p685wJD1iXXPgppH7s8YI5gLgdc+DNaJNt6wbn93Q2TB6JHQ5PsnmqFP9B+oPzKifrxFbk8MLnBPE8RmN4Y7gj6n++ETyjWGsK0ioZSCBJCAJVzTI1g2ishhBDSDygE40K5cJGDk+uiWUxHNYK+SF9tBmBQCEaYIzio0VA/fmHcVaMYRI+GWuHUzpXtB3VC0Ijd4HxIy/LxxoH2tk7QGdeO4MKhRqFbWTb7btFC2lJtEg2tE4K+y9YxBhpHlxBChhpbI8hoKCGEDAcUgnFRdVFRORSdFo5g02Yxdo5gh11Dq2X9HA1dLQVthU/VJwRzjnbiBg1nwrvczegIAJEHytccwS5cx06Z9MVPrSgMRjUty8cbB9rbzqE2GlqtAMvH6vex38/a7bpesGyEYbMaQbu/5OsdQRvPDXsMIWSo0Y4gawQJIWRYGMCz/SGh1jW0m4Hydo5glGYx/mhoqTEWCkSMhpo1LJ8YTDcQAPKOFiZAd8PkgcGMhq73jci0P/umjuCJRiFYcwSLXvOYh74L7L/V28c6guvM2AdbR9hsaLy9vThNIUgI0UgOeamiwjQAIYQMBRSCcVF1UVHSpkawWTTUOoLtagSdQLOYSrhwiRIN9TeLScIF6xYbnezWEYwaDW3VeKffrD/Tu2yP18oRHAtEQ60j6IzrrqEA8JnXAlc/w9vHRl3XBoVgG0ewOFUfDZ1/zLvMJjKEjBQq5yDPaCghhAwNsXYNHWladQ1t2yzGiJ12IkRy9Sfw1bJ2zRp3ROTxEdVyMnVx3eKM6eHr3dYIDmI01D/uo100NNgsBvAcwXwRmJ4Kf5ztGrp2u95e8wrvMhDSLMZcL04Bi765hP6OpM3WSAgZTnIO8nBRoRAkhJChgI5gXFQrKKtmXUMD8cTaHMEOawTDoqGhjmCEaKjf3RnUaCjgieRuZggC0aOhdo5eEqK44Kt9dIoApE2zmIAQnDHuaHHacweDBKOh5QXg4B2+aGjgePb7L041j4aymygho0UuDwdVVFwKQUIIGQYoBGNCKReuyqHQyhFsaBYTrBGMMkfQLwQrTWoEoziCPmdxkKOh9jXpWghGjYY26cAaN7lCo8C3VFa0oAt2DT33JcArP6prDSfWoeZ6Tm0C9v8Q+NiLvW6fUxuAgs81bNo11DqC0/XR0F5rBA/dA/zwms4fRwhJH8kbR5A1goQQMgxQCMaEcnU0NFQI1nZqVyPYRoQ0jI8otYiGorUL5ncEk6iL6xZnHL0Nk48aDbWOYELu6Jhx+fIFU/sZIgTtjMfxNfW3O2PAeT+tBX/e8bqQ5gvAvl3Ag98Bjj5s9h2vr6+0tYPBer9ajeCkFoX2veOPiXYjBG/5OPDl3+n8cYSQ9DE1gnQECSFkOKAQjAllB8rnuhkob+cItmsWk6+f5VYtN4+G+o8Xht/1GWRHsDCuRWC3a+y0a2hSovikC81xy9rpDXMES8bVKzapA7Rc9hY9L9AteRFPO04ib0SjfY+V5vW2WgH+bDXw338JzB8EZu/zHUt56/EPpu9GCJYW2G2UkKxixkewRpAQQoYDNouJCeXqgfIto6ENjqARN1Z8RGkWEzkaao/XRPvXRUMHuEawOA2sPqX7x0vEzz4qCTaLAYBXfBT44SeATec0j4ba2X/+AfRhXPabwIn9wG3/6gnaJSMEnTHgWX+kI6L/9Xu6+QzgCcbv/DUwez9wxxf0dSs6rdvsdw67EXTlJTaZISSjSC6PPFYYDSWEkCGBQjAuqhW4GEehZbMYKwRts5hAjWDbZjFOSLOYFkKwVV1cXbOYAY6GXvHO9rHOlnTaNTSh12JqPfC039KXgwLfYhu++JvLNCNf0O5iTQge1Vv74ULwOUoL3uXD93uXi9N6a98fbo+OYHkR2mGsAqEzNgkhA0vOQV44PoIQQoYFCsGYUHagfJRmMbYxRzAa2s4RzOVDxkeEOVgRxI+/A+QgR0M3n9vb4yNHQ22zmBTc0VbNYoBocdV8UYs2K9yWj+n3nX2PFSbr9/cLweN7vcs1R9AKwYoRqtXuuoZaMVutALkBdp4JIQ2IHR/BGkFCCBkK+JF8XFRdVJs2iwk6goEawUK3XUOb1QhGaRaTkWhor0RxRwHdLEZyTZrvxEywCZClsqS3ThRHsKifw4rHpaPa3bTff1AIlhe9y7aeEKiPhgL6wwb72G4inmXzPTQbj0EIGVzyjh4fwWgoIYQMBRSCcVG1XUO7aBZzxrOA5/w5sOWC1sfIOfXNYtyy9xxhx2slftyMdA3tmQ6ioWkJ4qDAt3TkCBpX1zaDWTpmZhQaWkVD/RSCjmDJe2yw02gUrOBkwxhCMoeuEWSzGEIIGRYoBGNCVV24yDdpFtOmRrA4pevF7PVm5HL9i4ZWMxIN7ZXIA+VTFILBbrAW66ZFqhE0a18xQnD5eH2TmYZo6Hz484RFQ2tCsMtmMd0+lhCSKsLxEYQQMlRQCMZFVQ+Ubz0+okk0NCr9jIZmpWtor0QeKJ+mI9isWUyHNYKAz+lT9Y1vojqCVgj6m8U4/RCCjJYRkjUkb4QgHUFCCBkKKARjQlSLgfLBEQbdCsFgU5FeoqGj4gh2MlA+NUewHzWCgWgoUC8gg7MI/d1Acw7wzD/UsVD7GtTVCJrju3QECRklJJeHAxcuP8ghhJChgEIwLlpFQ9s1i4lKztHOkXX6mrpYUbqG+gfKD3GNYCddQ500o6H9cgSbCMFW8dJVJwPP/H3gj/b7hKA/GmqbxVAIEjJKaEfQRZnRUEIIGQooBOOiqgfKOy3nCKravgC6i4YC9YKy1RxBRkMzEg1t1iwm4kB5oLFG0H8b0FoIrjnV9xjzfqprFmOO3/UcQbBrKCEZxEZDOUeQEEKGA84RjAlRFeMIRhkobx3BNs1hgtiB3FVXP9YtMRralojR0IFsFtOFEKxzBFs0i7Gcfjlwzot9z2OFYNj4iA67hroV7zF0BAnJHGIGyldcRkMJIWQYoBCMCam6EWoEm4yPiIrd37orzZrFIIojOCLjIyJHQ1MWgs0cwXzR+wCgFQ3NYlAfdc0XPefRmfDqD5//DmDzuY3P45b1Bw6q6usa2qGrZ4/RzWMJIaljawTZLIYQQoYDRkPjQumB8k7YSXtD11Ajwjp14mw01ArJptHQwNzCMOocQUZDU20WI/kmzWKWozWKAdo7giKes+ePiQY/BLD3lRe8DwtqzWI6dATLFIKEZJqcgzwUhSAhhAwJFIIxIcpFpVk0tKFZTJc1gjZKah/vltrUCLZqFuOvERyFaGgWm8UsR3dr7c/Q/zMPClsr6Pwx0eDzT23S2/mD3ocF3TaLsfWB3TyWEJI+OUc7gmwWQwghQwGFYBwohZzSzWLGnJC6v6BDZ0+Kg2Ml2hFsFuOWgVwrEdfGEbRClF1DdYfOQWsWU172GrW0I2ztwdrCmhD0OYLBn/3UBv2+nD/oOYBOl81ibI1jN48lhKSP5JEXjo8ghJBhgUIwDowwq6g8ik5YNDSkWUzO8W6PSs4XDa1WtXgIHSgfIRrqloHitL48zI5gFHcUaFFvmQDNmsVUlqM1igGaCMGgIxghGprLA5PrgQWfEOyHI8iuoYRkj1weDqooMxpKCCFDAZvFxIE5Qa4ih7FQIRjSLKbTWChQHw2t1RmGdQ1tI36qrl7L2AywfGy4awRtNHSQx0fk8rpraZCOhGCImA+6fUUrBFtEQwFgenMgGmqbxXQqBFkjSEi/EJGHAMwBcAFUlFI7Yz9ozkEOVbiMhhJCyFBAIRgH5gS5ghzGClEGyrvdCcFaNNT13JrQaGgb8WNHA1hHkF1D028W06xraE+OYDAaGuIIhj1uehMw/5j3PulLsxhGQwnpA5crpQ4ndrScGSjPaCghhAwFjIbGgXE7XORRbDU+wl8j2OkMQcATj1XXO0nvJhpqT+jHZsxzDHM0NNCxtRkD2SxmpfNmMX4aoqGBZjH5sfB48tQmYP6Q11ColSOoVPP3WV2zGDqChGQOEw11OUeQEEKGAgrBODAnyErycCILwV6ioRXvpLyraKh5bE0IMho6mM1ilurdu1Z00yymmchs5giGiblv/BnwsRc33g5oR9MyCI7gt/8auPVfG28/sb9zt5OQ5FEA/p+I3CwibwzbQUTeKCK7RGTXoUOHej+i+T/l8oMcQggZCigE46A2DqKJy9esWUyn+LuGtnIE20ZDrSNom8UwGqqbxaT0OuScJs1iOnEEQ94HDeMjpsy2nRDcrKOyi7NmPysEQ8TSnu8Dh+4Jf55BcwRv/ihw0wfrb1s+DvzDk4DbQgQiIYPFZUqpJwJ4AYBfF5GnB3dQSl2tlNqplNq5cePG3o9o/qcpflBCCCFDAYVgHBg3R8LcOcAXv+vVETQ/vmqbGsF20VB7Qr/udP34Nad0vpasEDkaupJeRDaXazJQfqmDgfK+tdsPDJoNi/dHQ8OYNrMETzxi9isasRqyxtkHgJW58Ofx1wim3TVUKWDxMPDYHfWi9ODdWrAefyS9tRESAaXUfrM9COALAC6J/aDm/5RyB8DRJ4QQ0jMUgnFgTpClZd2fBJrF9FIjWPGEYDcD5e1jN5wN/NEBYNM5na8lM2Sga2jTZjFdOoLjq/W2qRC0jmCT79cKQSuO8k64EFw+rsVVZcmrJ/QzSAPly4s6qlpZAmbv924/dJfelubTWRchERCRKRGZsZcBPA/Aj+M/sP4/VXUHwNEnhBDSMxSCcWBOcnOtHCXJeQ5d20HwzZ7D1zW02koIBsZVNFkvcoXhbhQDRIuGVl0tmtPqntqsWUy3NYITa8xtQSEYGB/RrCPp9Ga9PbHPe+6c0yj2Zh/wLocJqUEaKG9jrgDw6I+8yzbW2szVJGQw2AzguyJyG4AbAXxZKfXV2I9qHcG0f38JIYT0BY6PiINqm2goYIRgjzWC/jmCVti0Gh/Rrmtoq/UOC1GioZUVvU1LFPfFEfStfdwIwaDQm1ir33e12tAmjuBUwBHMFcIdwSO7vculeU+AWgapRnDB13H/0duB81+hLx+6W2/pCJIBRim1G8CFiR+4ViNIIUgIIcNAW0dQRN4sImuTWMzQYE5yc63iniJ9EILmMarqE3Nh4yPaCUHTaKYbVzJzRIiG1hrvpNksJiCUlOqsRlDE+3nWoqGB98bFrwWu+rJvfmQTR3B8ld4uHdHbWjQ00DDC7wiGOWqDNFB+0XwvOQc4cLt3+0EjBFcoBAlpgEKQEEKGiijR0C0AbhKRz4rIFSJhg8ZIHVGjobVmMV3WCFp3q1rxRUPDxkdEjIYOeywU8DmCLfapCcE0m8UEhJJdUydxVfuhQE0IBoTe+Crg1Cd7Hyg0qxHMGwdw+bj3vNYRLC0A//w0YM8P6mvtwoTUIA2Ut9HQTed4TXCWjwNz+/VlOoKENMJoKCGEDBVthaBS6o8BnAXgQwCuAnCfiLxDRM6IeW3ZxcT6WgpB9MMR9EVDW46PsOtq0yxmJIRgm8Y5QLTXMk7CoqF2Bl8z1y4M+/OcXNf6sXa/Vg5oYcoTgraWtOoCx/fpGrsDtwJHH/KOUQpxBCtL3v1pdw1dNNHQ1acCJRNZtUI257BGkJAwKAQJIWSoiNQsRimlADxqvioA1gL4vIi8O8a1ZRfzTzLvtIqG+prF9BwNdb3GHaHjI9pEQ6stRk8MHRGiobZGcJCaxdhGK4VOhKARstt/Enjh3wCnPbX58YDW329hAlg+YZ7X0Y9xy8DSUX1baR5YPgas3qavhzmCpQVgbEZfTvtEcnFWC+5VW4Hygr5t3gzcXn0KHUFCwqiNj2DXUEIIGQai1Ai+RURuBvBuAN8DcL5S6k0AngTg5TGvL5vYGsGWzWKkdyFou4b2Gg0dSUewVY1gyq9HzumPI2iFXWESuOSXm38/tWhoGyHo2iY6Rf2hQbXiE4IL+mtmq74e5qgtHvEaz6QtBBcOA5PrdX1kyQhB6xKu3c4aQULC8JcjEEIIyTxRHMENAF6mlHq+UupzSqkyACilqgBeFOvqsooVgs1qroBA19Bu5whaIVhtE2dsE4estnATh42OoqEpOYIS4gj2Eg1t9T4EvJ97q+cuTtXvb2sE64TgvDdqIsxRW5z1ZhJWW7z+SbA4a4TglP55uxWvk+ja7XQECQmjFg2lI0gIIcNAFCH4FQBH7BURmRGRSwFAKXVXXAvLNEZYOfk2XUPRJ0dQuZ6L1U00dJTGR3TUNTSlGsGwaGhXQrBYv216PKf9fv75hfkwIThvHMEt+nqoIzjr3Z+2o7B4BJja4M1QLC9oR9AZ12K2vJh+Z1NCBg3zt0JUuc2OhBBCskAUIfhPAPwfjy+Y20gzbNdQJ8lmMb0MlB+hGsFa19AIQrCdkxYXkmuMhnZVIxihCQzgfQDQLhrqf958QAguHtXXJ9bq91HQUauUgJUTwNRGfT11IXhYN9EpGiFYWgQWZoHJDd5cRbqChNRj/09xfAQhhAwFUYSgmGYxAGqR0FGwjrrHnMTnWwnBumYx5R6FoL9GsNVA+WZdQ0dpfESEaGjFVwuXBv12BNtGQ6MIwUnf/sYRdMvA0jF92/xjejs2o7+CNXZ2BqGNjqbeNXTWqxEEtJu5eBiY8t3GOkFC6jH/IyTtD3IIIYT0hShCcLdpGFMwX78JYHfcC8s05iTecdo1i/HVCHYTy4wcDW3jgtUGyo+Cvs9CNNRpdMxqQjDiQHmgi2hoRCGYLzQ2i5k/qLfFKe2oBaOhtv5uEKKhVVevezIQDV04bBxB09mUjiAh9dSEIKOhhBAyDEQRgr8K4KkAHgGwD8ClAN4Y56KyjjKirL0j2Gs01DymbTS0XbMY+9iUhE+SRImGWhEztir+9YQheQCqfo22s2VxMvQhodSioVGbxUQQgpLTjqV1LWtC0DiCxSmgONMoouwA91qzmBQdwaVj+ndhcn19NHTxsK4bpCNISDjmb0lO0REkhJBhoK36UEodBPDqBNYyNFTcCgoAnHY1gr02i/HXCEaJhnJ8RLRoqBU3E2vjX08Y/p+rdYrLS3pbiMMRjDhHEPBEY87RLuWScSrtaInidLgjaIXg1EYAkq4QrK1lA1Aw3VDLCyE1ghwqT0gd5vc/R0eQEEKGgihzyCvKogAAIABJREFUBMdF5NdF5P0i8mH7lcTiskq5rP9JFlpGQ/vgCNbcLbd1nLG2X5PnqY2PYDQUgE8Irol9NaH4f66W8qLeFqYa929GrUawTbOYKNFQ65zVxGUgGlrbb1pHKw/cCnz8SmD5uL7diq/J9eHR1zi5/bPA1/7Iu15byzpvLMbiES0GJ9fRESSJIyJniMiYufxMU46R0h+gFuStEKQjSAghw0CUaOgnAGwB8HwA3wawDQA/Km9BpaKFoFNoN0fQOoK9zhF0vYYvLcdHNGsWM0qOYIRo6NJRHW9Mc6A8UC+WakKwE0ewUL9tt1+UaKh1KHOOfs81CMEpLaSWjwO7vwU8doe+3YqvibUmVprgieRtnwZu/ZR33Q6O90dDjz2st1OsESSp8G8AXBE5E8CHAOwA8KnWD0kBKwQ5PoIQQoaCKELwTKXU/wGwoJT6GICfAnB+vMvKNpWKPskttKwRFJ8Q7LFG0DqCkgdyYT/SNi7YSI2PaDNTEdDiJq1YKFAv8C0lKwQ7qRG07l0bR9AKwFbP3RANzev3nHX8LLZZjGXuUb1dnAXG13gzCFtFc/vN7H3A8jFviH3NEfRFQ4/t8W6rOYL8vIskRlUpVQHw0wD+Tin12wC2prymRszvf15VUK22+BtKCCEkE0QRgvajv2Mi8gQAqwFsj21FQ0ClrGOahUKbaGi/Bsrb8RHNnJ+2A+VHaHxE1GhoWrFQoL4brKW8qEdHhAr9JkSNhq7dAVz5z8DjX9h8n0IgGpormJEQCpja5O03NuPNPAS8JjILh7UDByTrCJaXgWN7tfC0NX8LYY6gEYJTMc8RvP4fgYe+1//nJVmnLCKvAfCLAL5kbhu8P8jmf0RRKqhQCBJCSOaJclZ5tYisBfDHAK4FcCeAd8W6qoxTcwQLHQyUl16ioVUt5po5es2iocf26A6K1bJeTzfx1KyRKUfQ9/MqL3bmBgL6pM12+WyFCHDRa7x6uTDCoqELh/Tl1du8/YpT2oGz+B1BKwQlQSF4ZDdqot/OPFw8ol2/wrj3fR010VA7UkJy8dQIfvtdwG3/2v/nJVnndQCeAuDtSqkHRWQHgGtSXlMjRgg6cFGpJujqE0IIiYWWNpSI5ACcUEodBfAdAKcnsqqM4xoh6LQSgnVzBKu91QgqV3dtbOroNXHB3nepFhg7Xz8ibiCidw3ddG4y6wkjtFnMUhdCsNg+FhoVGw31N4uxrN4G7L8FgOg1vvBvgFs+Dtz/DW++4OIRYM0p+nLOSa5r6Oz93uWlI/r9vjirm8IA+nfImfAcwZkt+j1SnO6/I6iUjpsyckoCKKXuBPAWADAfvM4opd6Z7qpCML//WgjSESSEkKzT0hFUSlUBvDmhtQwNrmkWU2wpBH3NYpTrnfx3gj8aevwRb1h32LGARvFjG5Ds+jBw0sWdHz+TRImGHkvZEQxpFlNa6GyGIACccilw9vP6syYrQv01gpbVRuAVp7WIOuUS4KX/CMxsBeaNIzh3wIyOQLJdQ/3u5B1fAN7/ZODBb3vuJKBfV+UCY6u9WGgcQrC0AEABKyf6+7wk84jIdSKySkTWAbgNwEdE5D1pr6sB87epiApcl0KQEEKyThT18XUR+d8icoqIrLNfsa8sw1ghWGjZNdTvCPaha+jRB4F1TQzbZnHIaSMcL3kj8Np/7/z4WaRd11ClBigaGnQEO+gYCgDnvwJ41cf7s6ZiSDTUsv4Ms08gWjqzBZh7TK998bDPEcwn5wge9jmC+27W27kDOgJqsQ1jVvl6cxTG62sd+4EVlnQESSOrlVInALwMwEeUUk8C8JyU19SIzxEsMxpKCCGZJ4oQfD2AX4eOht5svnbFuais47oRagT9zWKU212NYM0RLANHHgTW7WhxLKDBBauWgZ1vAF741/WdHoeZdtHQ0oJ+XdIUgs2axXQaDe0nYc1iAADSXAhOb9aO4In9+voqU0uYy9d/b3FRdYF9NwLrz9LXD93l3VfnCFoheJJ3W2FSC9hueOQW4OhDjbfbmsNlOoKkAUdEtgJ4FbxmMYOHiYQXUIHLaCghhGSetkJQKbUj5Iu1gi2wNYLFVo4g+uEIGlfm2F5dI9jMEUQT8eO26DQ6tLSJhtaGyQ+aI5i2EAyOjzDvvamNeiwE0PhhwvRmXY935EF93TaVSSoaevtndI3g035bX7djIwDdHdRi3c4ZnxB0xoFKl0LwMz8PXBfST8t2LaUjSBp5G4CvAXhAKXWTiJwO4L42j0ke83tfEBcVRkMJISTztBWCIvILYV9RnlxErhCRe0TkfhH5gyb7vEpE7hSRO0TkU77bf1FE7jNfvxj9W0qfqhnQXiy2qxGsmoii6q1rqG2I0Wk0dBSFYLto6EAIQVsjGJgj2Gk0tJ/UmsXYaKh5763a6s3dKwaE4Mxmvd3/Q71dfbLeJtU19Dt/A2y9CLjwNY1NcyZ96XYrsOscwYnuHMHSAnBiX3gd4AqjoSQcpdTnlFIXKKXeZK7vVkq9PO11NSCCqjgogOMjCCFkGIgyvO4nfJfHATwbwC0AWhYfiUgewPsAPBfAPgA3ici1pjua3ecsAG8FcJlS6qiIbDK3rwPwpwB2Qls3N5vHHo38naWIjYaOFdvVCCrvZL8bR1AEgEQQgi2ioaMwRN5Pu2hoTQimOUcwrGvoYuvxDnFj6+iCXUNnTvLW1RANNTWoj5gk+SojBJPoGlp19eiIZ/yenr04sUbPNBxbpUVaaDTUXyM44XU87QQbCa2sNN5nBWBprvsUABlKRGQbgH8AcBn0H+rvAvhNpdS+VBcWQjVXgAMXLmsECSEk87QVgkqp3/BfF5HVAD4R4bkvAXC/Umq3edynAbwUeg6h5ZcBvM8KPKWUPfN6PoCvK6WOmMd+HcAVADIxgCtXmkdZ5VF02gyUV1XvZL+brqGAPqmef0wLOnui3XgwvfGLH6W0KzNqjmCmo6ED4AgGo6GrtjYXgtYR3LdLx0TtYPskmsUs2mH3plPpxFr9e3LOi7UTfvozvX3tumf64Age2a23lZBGM/4upKV5YHx1589PhpWPAPgUgFea6681tz03tRU1QeUKKKCCMqOhhBCSebpRH4sAzoqw38kA9vqu7zO3+TkbwNki8j0RuUFErujgsQPLmhP34F61DWPFNkIQ6M0R9D9u7fbmz1FzwXy32WjeyDmCGYiGhjaLWfJcuTSoNYsx7xf7vp3a5BOCgWjoxnP0bYuH6z+kyCUQDbXD7m0toK1jXLsDePkH9O+LJSwa6ky0rxE88iDwyM31t80+oLdhQtAfCWXDGFLPRqXUR5RSFfP1UQAb015UGCrnsFkMIYQMCVFqBP9TRK41X18CcA+AL0Z4bgm5Lfifw4EWlc8E8BoAHxSRNREfCxF5o4jsEpFdhw4dirCkBFAK60/ciR9Vd2DMafXymmYx1qXrpkbQ/7jNLQagh0VDTR1jreZrVGgXDbW1XWOrkllPGMEaQaV07VmajmDeMQPqjRC0Qmt6oxZ2xelGh6s4CZx7pb5sG8UAyTSLqQlBnyMIhM/aDO0aGsERvO6vgM+/of62qI4g6wRJPYdF5LUikjdfrwUw2/ZRKWCjoWWX0VBCCMk6UVTA3/guVwA8HLFuYR+AU3zXtwHYH7LPDUqpMoAHReQeaGG4D1oc+h97XfAASqmrAVwNADt37hyMjyeP78VE5TjuyZ0OJxemZw22RrDXaGh5QW9Pe1qLnULET9UIwVFzBEM/Y/DhlvTWGWu9X5wEo6GVFQCq84Hy/aYw4b1fFg7rrRVaP3MNsCEkKHDhq4Fbr2kUgnGPj2gQgsYRnNnauO/qU7Sz6a8bLEy0nyO4eMQ7jqUmBMNqBP1CkI4gqeP1AP4RwN9Cf2J3PYDXpbqiZuQKKAgdQUIIGQaiqI89AH6glPq2Uup7AGZFZHuEx90E4CwR2SEiRQCvBnBtYJ//AHA5AIjIBuio6G7oNtrPE5G1IrIWwPPMbYPPgdsAAMdWnweRdkKw2ns01LL9shbHMlt/HNI0tBm5GsF20VDrlOZSdEqDzWLKi3qb5vgIQA9ht4JqwZTzWqF1xuX1Ys9y2mV6VqV1BgHTNTRuIRgQqq0cwUt/BXjzjZ5bDBghuNj6GKV5/eUXjHZURpiIpCNImqCU2qOUeolSaqNSapNS6kro4fIDh8oXUIDLGkFCCBkCogjBzwHwZ0Bcc1tLlFIVAG+GFnB3AfisUuoOEXmbiLzE7PY1aGF5J4BvAfhdpdSsaRLzF9Bi8iYAb7ONYwae/beighxkyxNa71drFtNjNNSy8ZzWxwKaOIKMhtbhlnQEspWIj5ugIzgoQvDnPgc84/f15ScZs2JTi/cdoDt2vug9wKmX+m5LqEZQ8l5tYE0IhjiC+UJjTagzoYW4/WAgDCvmlsyfpvKSHh0BtK8RpCNI2vO/0l5AGLZZDB1BQgjJPlFUgKOUKtkrSqmScfjaopT6CoCvBG77E99lBf3PruEfnlLqwwA+HOU4g4R76B48XN2MUzata72j5AD4x0d0GQ21tHx8SKfMWo3giDmCNVo4gvlIb+/4CDaLKQ2IEFx/hnf54p/TX92QxPiIhUO6UYz9vbjgVbruc2p968dZbD1meRHIN+nuacXc4qyuLzz6sL4+uaH5+IjijB4fwWYxpD1tP40yY5p2AXhEKfWi+JcEIOfAgYsKx0cQQkjmiaI+DvkcPIjISwEcjm9J2Wb5xCyOYAZnbJpus6dtFmNrBLt0BK/6MvCWW9scKiQOOao1gm2joaX0xXGtWYxxzawjmHaNYL+IwxE8/giw+9ve9cVZLcgsa7cDT/7V6M9XE4IBZ++O/2gcDL9oenrY+sDN54Z3HC3New1pGA0l7Yliuf0mdOImOfJFFFFBhdFQQgjJPFGE4K8C+EMR2SMiewD8PoBfiXdZ2aWycBTH1DTO2Nim1b/keh8oDwDbnwas29HmWCFxyJGtEYwYDU2TWjTUrLEWDU2xa2g/6dURVAq4/XP1Iu1b7wA+7XMorSPYLX5H0HL0IeBzvwj84J/0GqwgXDTR0CNmdMSmc/X7KOiYrMwD05sAyOhGQ5UC9t7UvhHPiCAicyJyIuRrDsBJbR67DcBPAfhgIou1mK6hFUZDCSEk87QVgkqpB5RSTwZwLoDzlFJPVUrdH//SsoksH8MJTGHHhnZCsE+OYLRVmW2YIzhiNYLtBsoPYjS0JgRTnCPYT3L53rqGPnw98O+/BNz0Ae+2R3bpyGXJdNFdOOQ1iumGmhD0OXvHH9Hb+76uo5/2d8jvCI6v8RrSuIF4aGlex1PHVo2uI3hkN/Ch5wC3fzrtlQwESqkZpdSqkK8ZpVS7P85/B+D3UF/DHz953TWU0VBCCMk+UeYIvkNE1iil5pVSc6aT518msbis8dDhBeRXjsEtrsZkq2HygNcspl9dQ9sdCwh0DTVlnyPnCGYhGmrWWA3WCA6JIyg9RkP336K3t3zCOHNzwKF79G22W+jC4d6EoGNea3/Ec+6A3u67CTj2sHd7zRHcDaw73ffYgOu1MgeMTQPjIywE992kt9suSXcdGUdEXgTgoFLq5jb79X/WrukaymgoIYRknyjR0BcopY7ZK0qpowBeGN+SsstbP/9DTGEJl5x7eoS9bUTR/DON0xFsGQ1N2f1KmkxEQ4M1gkaMFIfFEexxoPz+H+rt4XuA7/09cP83UHN4Fw/r2OHKiT5FQ31C8IQZg6qqwJ1f9G73O4Lrz/BmUAbjj6V5oDgNjM0Ay8e7X1uaLB4Bvv3u7qK9SmkhWJwBNj6u/2sbLS4D8BIReQjApwE8S0SuCe6klLpaKbVTKbVz48YePhjxIfkiHFRQ4kB5QgjJPFGEYF5EatO1RWQCQIrTtgeX0vxRAMD2bSHz1ILUxkf0qWto64OZLaOh2YyGmrjjsDiCvdYI7v8hcPrlugHMN/4U+Jxv7vbCLPDYHfrymtO6P0ZYs5i5R3Xn1uI08MB/e7efeAS4+aPA8X3GERzXt4c6gjM6PrqQ0X5bt38W+Nbbgf23alEY9ef4438D3nMOcP83gZOfGG8CYgRQSr1VKbVNKbUdekbvfyulXpvEscWxcwQpBAkhJOtEUR/XAPimiLxBRN4A4OsAPhbvsrLJZNXEvezsslaI1DeLkRiFYGg0dETHR4TNVPQzEI6gb47gvpuB696pXZQo76sskOthoPzSUe287fhJ4M27gNf+m36+vPlsavEwcMe/6264Zz2n+zWGNYuZ26/nEK46CTh8r3f73V8C/vM39Xtq/ZlAwQpBX41gpaTfW2PTwNYLgQO36tuyxiO79Pbog8B7LwJ2RZzws+cGHa09+iCw7SfiWx+JnZxTRAEVlCoUgoQQknWiNIt5N4C/BHAOdMOYrwLo4aP24WXSNZ0AJ6IKwYSaxUgghgqM8PiIkNfCzyAIwZojWAVu/oiuEbzqPzk+AgAO3Ka3J12sP8Q48znAz1wDvPjv9e0Lh/SIhzOe1TgkvhPC6vxOHNAicGaLFwed2qS3a7cDV/4TcM5LfI6gL1Y6e5/ejq8BTnuKft4Dbca+DCKPmJK0Pd/X8dZHfxTtcbMPeJcpBPuKUuq6xGYIAsjl9UB5OoKEEJJ9otpQj0J3Jns5gGcj6blFGaHmCEY5AW0YKJ9w19BajSCjoXW45fRdUn+zmNICMLNZC59hIed03zX04e/r352Tnujd9rgXABe+Wn+ocf83gRP7gPN+urc1hjqCB7QjOL3Fu216s1nDC4GLfla7gbZG0O8I/vfbtat73suAU59qvpfre1tjHBy4DfjCr3oNigBg7406brt4xJuV+PD39dbfNKcVR3brOO8z/xA44/L+rpkkijhFOOLSESSEkCGgqQoQkbOhaw9eA2AWwGcAiFKK/8WbMFk1c8UiRfjScAR9/7hH1hGM0DW0OJ3cesLwN4spL+q6tGGil66hD/0PsOWCRtddRDeHseLqtKf2tsZgjaBSukZwZkv9fsf36O1Zz/NuC7qJB24H7vky8Kw/BqbW69vWn6VdNfxWb+vsN7s+Atz2r7rj6vP+Qn/fn7tKO55P+21vv4OmDvPYnvbP6Zb1fue/Anjm78exapIgtWgou4YSQkjmaeUI3g3t/r1YKfU0pdQ/AOihw8PwM1NzBKNEQ+34CCPOYh0fERKHHNkawSxFQ40jmLYw7TfdNospL+mukzt+Mvz+yQ36A47iNLD6lN7WGHQEF4/ouYCrTtKuoOVZ/weA1AvPYNfQu/5T/77vfIO3z8lP0gJx0LAu5g3v1yM5juzWzXAO3Abs/YFxY33u9LG9rX+WSgFHH9bv5XVRuimTQUfM+Ag6goQQkn1aCcGXQ0dCvyUiHxCRZ8PL1ZEQplQHjqDk9EmSSrBZTF3XUOPIjJojmIloqK9ZTGlheGoDLd02i9n7Ay3Utz89/H7rtm18fO9deIOdP+fM6IiZrZ4rKDngJ34J+LNjnvgLe+y9/wWccikwuc7bZ2ymsato3DT78MPPsT3arSxMAt/4c+DB7+jbS/PADz+p3dgNvtEP1bKOzN7yCeDjL61vgONWgE9cCVzzMn2dQnA4yBdRZI0gIYQMBU3PlpRSX1BK/QyAxwO4DsBvA9gsIv8kIs9r9riRRSnMqHmUchOAE8FRss1ikqwRrJsjaB3BEasRzMIcQX+zmGGMhnbbLGb3dfq1OfXJ4fdPmrmBm87pemk1RHTE0zqCh02zlzWneEJwbMZ7P/nx1wge36cbqpx9Rf0++aJ+ryXFx14MfPl32u93fI92/C57i46z3vB+L6o8t1+7satO0tdtp9ajDwH/83/1z+fGf/Ge6/r36ttsHeG6M/r0zZBUyTmsESSEkCEhStfQBaXUJ01Xsm0AbgXwB7GvLGu86zRcJV/GsjMTbX/bLMYKEnYNTYa20dABmCNYcwQrumnHUEZDWwhBpYA9P2i8/e6vANsvA8ZXhT/ODpDffF7vawR04xcb77z/G8D4amDLhZ4QLDb5Xbex0soS8NB39eWznlu/T76QnBBcOgo8+D/ArZ8Elo4138+tAMcf0WL3yb+m46uH7wUe/yJP9G1/OrD6ZH351Ev19rZ/1WMhpjYC171Lu9gA8P33AWc8W89zLM54Px+SbfJFOHBRrrBShBBCsk5H+Sml1BGl1L8opZ4V14Iyy/JxAEAlNx7xAYFmMbHWCIZEQ0e1RhCAdkhb1QgOUjR0fgijoaZraDMx/sB/Ax9+nh4cbzl8H3D4Hi1KmtFPRxDQTmx5Sdfx3vd1LWryjtc1dKyJEHR8cwRXTN2wHTNhsY5glLhmr+z5AQClo6g//nzz/eYO6J/LmlOB4hTwuq8CL3g3cPkfaXEteT36YpURgttNreYPrwHGVun9SnO6qY5SWoBuvRB4xYeBF/9duHtKske+gBwUKpVy2ishhBDSIzEWpo0QVS8is245Qhc9wKsRrCbQNTQsGlqrERyxaCjgNeoJY6Cioe5wRkP90dcw7IgC25Fy9gHg2+/Wlx/3wubPu/FxQGFK17H1A2dcu3qP3gYsHPQ6gxYngbHVLYSgjYYuN//Axb7Huu2e2gl7rtfO/8bHAzd+wFtTEPt620Y7ThG49FeAjWcDT/x5XQ85NgOsP1Pfv+UC72f5gndpRxDQH15UlvX7d2wG2LZTdwwlw4F5L7sUgoQQknlGUAXEgO9k7qF1T8P2KI8RMc1ibDQ0zmYxYV1DTSwtbfcrDexrH8YgNYtxS/qEeuiiob7oa5gTfuIRvZ17TLtqH3kBMP8YsOMZOrbYjHNerAfJj/Xp9bKO4Pfeq4XUmc/x7lu1tb0jWF4GHPM+C364YOuIKyvxvd/cCvCttwN3Xguc/ETgqW8BPvNzul6w6gK/8MV6t/n4Xr1dc1rjc+18vXd5w1nAm76vnddf/qZ+nTY+DnjgW/r+0oLnhDZ7jUh2MeUEVf+cTEIIIZmEQrAfmHq795Rfgckn/B5+NcpjGprFJNw1tOZUpOx+pUK7aOiAOIL2ZHoYo6FA886hx40QnH8MuP2zevuzn2usswsi0j8RCOgawYe+B6wcBy7/Y2B6o3ff89/RXKDn8vpkubLs/e4F31P2epx1go/9CPjue/Tl818BnPMi4HE/pZvAADoKuv4M4LO/oGOeS0f17au3tX/uzefqrX+UhBV9K/MUgsNM3gpBOoKEEJJ1KAT7gRFVCxjHqkLET/drzWLSjoaOoiPYJBqq1GAIQSuUlk/obXEqvbXEgd8RDMM6gvOPAvd8BdhyvhaBSdeYrT4FeORmLZ78w9QB4Mxnt36sM67dvpwDQBqdT+sCNotp9oO5x/T2pe8HzvtpffnlHwS++7fAd96tX/+FWeDOL+o47rozdP1fIWqdcwArjEtzOh7qv40MD1YIJtn1lhBCSCxQCPYDc0JbRh75XNST1QTHRzQbKC+5eJ3IQaVZNNQKk9SjoeZnYl2VwrAJQesINhGCx/fp7aF7gIN3As/583QajbzsauAl7+3O1SqMa0cw7+gPFoLrT8IRnH9Ub3c83XOVi5PAlieYY5eBfTfqy4/+SNdinv/K7o9n3dg6R5BCcOgwHx4qOoKEEJJ5RlAFxID5VL8CB04+4ktqXakkHEEbTwuOjxhFNxBA02horW5yAOKykh/+aGiYK1utAifM8PZHbtHbjY9PZl1B8oXuo43OuNcsJuz9ZMcx9CoE3Qrw728EDt7VeN/8Qb2dDnQstb/31TKw1zemo7zYuitrO6xzXVrQYhBgNHQYMe/naoWOICGEZB0KwX5gagTLyMOJ6ghaVyrJgfJ1NYKV9J2vtLAdW4MMkhDM5YGVIY2G2g8mwhzBhUP690ny3ockG85Kbm39whkzQrDkNYbxU4uG9ngyPbcfuP0zeryFn2pVj3GYWOt1MW04dgXYexOw9SJgfI2Oce54evdrsXMVS/O+aCiF4NCR1x/kqDhjzYQQQhKB0dB+YE5oXZWLHg2tOYJGkKQxUH4UR0cAzaOhgzRbMed4NYKjFA09YWKhm87VzU7yxfAuloOOM6FrBJvVnPYrGlpe0tvFw3pbWQGu/Q3g4eu1k2pnHvqxr39lSddAPukq3XFVVbuvDwS0QHDGtZNtP8RgNHT4MO9dCkFCCMk+I6oE+oyrT2grcFDIdyAE/c1iYu0aGtIsZhDGJKQGo6GpUhNBISeStmPoyRdrIbjujJoDkSmcMS3Smv2etXoNOqG8qLcLs3r7zbdphxDQXUC37Qw5tlnP4hEtBteeBjz5Tb2tw1Kc1m4go6HDi40WMxpKCCGZh9HQfuCLhuYjC7pAs5gkuoaCNYIAmncNHSQhmMvpsQXA8EVDW8UibX3gSU/U2yzGQgGva2gzR9DpkyNYskLwkN7uvRGY2Wrum2/tCFo3sZ8fCBWndI2gjYYOm5tNvPdLlY4gIYRkHQrBflBrFtNJjWBO6zKVRNfQkGYxbiWbTks/EAx+NFTywxsNdVo0Spk7oD+g2Hyevr7h7OTW1U9sjWBlpXU0tNeh3P5oqFK60+rZz/eG2gcbxQDeB0DWTeznBx9jM17X0OL0aHYlHnb6Vd9KCCEkdfhfuh/4xkd01iwmIUcwLBo6yo5gFqKhhUnU1jis0dCwaNnco8DMFh0JLUwCpz452bX1i8KEr2toEtHQQ8D8Y9pF3nQesOkcfftMiCNoPwCyj+3n34HitJ4juDLHWOiwUus622T8CyGEkMxAIdgPbLMY5OFErhGUwPiIOH8UYV1DR7hGMAvR0A1nepcLQyoE3RA3bN4Iwan1wO89qAfJZxF/19D8WOP9/XJV/DWCh+7Wlzee7Tmq05sbH1NzBGOIho5Ne9FQDpMfTpKYgUkIISQRKAT7QV00tIMaQSjd5h1IIRo6wo5gFrqGbjpXb/NjMY8WSYFWJ5LWEQR662CZNrUawWZzBPvVNdQIwfICsP9WfXnj44HN5+vLoY5gMBra5xrBFdMshh1DhxPjKAtrBAkhJPM30bv2AAAgAElEQVRQCPYD2yxGdVojmJAj2CwaOrI1gqZja5BBcgTtEPUw1yzr2BrB0GjogfAGJ1nDGTddQ0sxR0OXvMsPXw+Mr9Yu4OOuAM58LrDl/MbH2GYxpTiioTOmayijoUOLee86ykXFDUlWEEIIyQwUgv3ANz6iszmCaQ6Ub+JUjAQy+NFQW+M1jDRzw8pLwPLxcBcra9QcwTbNYnoV+lbMAcCe7wMbHqc/+Fm7HXjt57UwbDh2nM1iprUbWJrnMPlhxbxfCqig7IZ8oEYIISQzUAj2A9/4CCcf8SVtqBFMIhrqdwQrjIYGGaRoqHUEh5FmImjuUb0dCiE4FrFZTJ+ioYAe4n7qpe0f01Aj2MdkQG2O4AlGQ4cV4+gXpYxShY4gIYRkGQrBfuBvFtNxNDSJGkEbDfXd5jIa2sAgOYLjq9JeQXw4TWKRwyQECxP6A6LyUhNH0DaL6WM0FADOen77xzTMEezj+704pT/cWphlNHRYMaNJxlBGidFQQgjJNCOqBPqM6x8oH1EI1prFJOgIcqC8oVk01DqCAyAEAeDclw7fDEGg+Qy9eSsEtya7njiwdZArc00GyreYpdgJ5QXPhSvORBu3URsfsaC3/fw7YMWfXRcZPsx7dxwlCkFCCMk4FIL9oGprBPMoRI6GJugIIqRZjFsZjAhkGoiEGoKeIzggr8urPp72CuIh30QEWUdwWJrFAFoIOi1qBMMa5nRCeQmY2qA/UDrjmdHeu3FHQy2Mhg4nPkewzGgoIYRkGgrBfmDHR6gOHEHJaTFSTbJraNARHNEffxaiocOM06Q+bu6AFimT65JfU7+xQrBZsxj7u9ezI7ikXeOXXe2NHGlH3M1iLBNr+/e8ZHDIOVDIYUwYDSWEkKwzokqgz9SaxTgodDNQXnKeWIsD4UD5ejISDR1WmkVDF48Ak+vj/V1ICsc3AzHs/SSib+9VCJYWgOIkcO5Loj8mzvERhUnv8nkv69/zksFBBG5+DGMVNoshhJCsw2Yx/cC4ei5ynTmCtkYwTjfQO2DjHMFRrREUNOkaOmDR0GGl2Qy9yopusjIM2BpAoPn7KV/sT7OYTl8zES0Ga9HQPr7ft16o5xe+6frhcHZJKCo/hjHWCBJCSOahI9gPfM1inFwHoq7mCMZZH2gIjkxwK+waGoTR0GTI5fV7Pjg+orJc76RlmXaOoL29H+Mjuolg5gq+aGgfheDUBj2/kAw11fwYawQJIWQIoCPYD0w0tAIHTuRoqGkWU3VjbhTjOx67hhpCoqGH7gUO3q0v0xGMH2esUQRVVuqdtCxTiCoEexwoX17szkXNF+IZH0ESQUTGReRGEblNRO4QkT9P8vjKGWeNICGEDAEjagn1GdsspqM5gsahU9VkHMGg+BnlGsGwgfLv+wlzXz4ZYT7q5AuNHTMrSyPoCHYZDV04DNz9JV3n56/Li0rO58iOatOobLMC4FlKqXkRKQD4roj8l1LqhiQOrqwjSCFICCGZhmcA/cCMj+hojqB/fEQncdJukVwgGjrCjmCzaCigo7okfvLGESwvaxdQxDiCwyIE/TWCzYRgofto6B1fAL7yv/XlYjdC0Pe7P6ofCGUYpZQCMG+uFsxXkz9qMeBoIchmMYQQkm0YDe0H1QqqyEEh19kcwVqzmKRqBAPNYka1RrBZ11CSHM4YsHQUePtm4Nvv0rcNVY2gL67ZTGiFxWOjsjLnXe42Glq7zGhoFhGRvIjcCuAggK8rpX4Qss8bRWSXiOw6dOhQ/w7ujJtmMclpT0IIIf2HQrAfuGUoI+YiO4LwjY9IJIooaBwfMaIngGHR0A1np7OWUSVfAOYP6svX/ZXeDlONYGRHsMtoqG30Aug5gp3ij4OOajIg4yilXKXURQC2AbhERJ4Qss/VSqmdSqmdGzdu7NuxxdYI0hEkhJBMQyHYD6oVuKJPrKLXCPqaxSTiCPqioVUXgBrdE8CwaGjYOAkSH3njCPoZKkcwYo1gcJZiVEp+IdiDIyj5ZKLpJDaUUscAXAfgisQOWmCNICGEDAM8A+gHbhlVcZDPCSTqMGy7X1KOoN8FKy3o7bDMbOuYkGhotQycfjnwpu+ns6RRI18Alo54108cGC5HsK5raAxzBMsLvmN18XtsPwRifWAmEZGNIrLGXJ4A8BwAdyd2fGecNYKEEDIEjGqRWH+pluEaIRgZO0Q+KUfQHw0tmR4DY9MJHHcACYuGuhVg1UnA5nPTWdOo4QQcwX03jqYjWFoIv68dfkew2EU01NYHj2o8PPtsBfAxEclDf6D7WaXUl5I6eK44TkeQEEKGAArBfuCW4UoehW6EoFv23ME48UdD7clncSb+4w4iEmKEVyscG5EkwWHq+3YNlyOY930fzb6nfBFwj4bf145yj9FQ6whydEQmUUrdDuDitI4vzjjGpYQVOoKEEJJpGA3tB1UXVelgdAQA7dDBDHZPIhoKLw5pOw6OqiPYLBo6qjWTaRB0ohYODZcjmMt532PTaGgP4yP8TmJXcwStI8j3POmcfHGC0VBCCBkCKAT7QbUMFw6cqKMjAM8FTDMaWhxRIShojIZWKzwpThK/S1acBpaPa3FeGBIhCHgjJFoOlO9SCJYXveefXN/54+17ndFQ0gVi5gjSESSEkGxDIdgPXF0jGLljKOATgglFEv3R0BUrBLuoLRoGwrqGuhXG5JLEL7qnNwGLpnHMsDiCgCd24xCCpUXg9GcCr/sv4OQndf54+17ne550gzOOMSlhuVRJeyWEEEJ6gGcB/aBaQQX5DoWgbRZTSX6gfK1ZzIjWCDaNhvLXITH8NXRTm4DFWX15qISg+V6aDpTvsWtocRI47andPZ6OIOkFZxx5KJTKXX6QQQghZCCgI9gPrCPYSTTU1gi65WTmePldsJGPhoZ0DWU0NFmsAMk5wMRanxAckmYxgBdzjcsR7KY20MLxEaQXzO9pZWUp5YUQQgjpBQrBflCtwO3aEUywRrDWLGbUx0cEoqHVqn5t6Agmh2PEUXFKf9lREkPlCNpoaIuuoZUeagR7iXbn2SyG9IDpVFspUQgSQkiWoRDsB9UyKuiwa2hNCCbVNdQ/UN4IwcKI1ggGo6FVE8+jEEwO65IVp42gMe/NYXIE20VDu+0aqpTuGtqLEKyNj6AQJF1gfk+r5eWUF0IIIaQXKAT7gWtqBLvpGuqWE6oR9LlgK/NaBCYRSR1EgtHQqml4QHckOawQLEzWR5SHyhFsFw0d00IwGFNuh1sClNtbNDTPaCjpAfPerpYoBAkhJMuMqBLoM9UyKui0a6ivWUwig8z9zWLmRjcWCpgOqj5H0KUjmDjW+StO6aYnwduHgbZCsAhA6Xh4J9gZgj05goyGkh6gI0gIIUMBhWA/cLuIhsI3PkKSaBYjXlncyvzoNooBUDdTEfAcQcbkkqMhGmoYKkfQ1gi2iIYCgLvS2fOWF/W2p2YxdnwE3/OkC8zvqapQCBJCSJaJVYGIyBUico+I3C8ifxBy/1UickhEbjVfv+S7z/Xdfm2c6+yZqosKcijkux0fkXTX0IURdwSbREMTcWYJAJ8QDEZDh8gRLLQZKG+/10oHQnD3t4E7zZ/DnprFcHwE6QHz3lV0BAkhJNPEloUTkTyA9wF4LoB9AG4SkWuVUncGdv2MUurNIU+xpJS6KK719ZVqGRXldNgsxj8+Iulo6DxQHNUZgjDRUJ8QtNFQxuSSIx/oGmoZSkewj0LwG38K7L9VX+7L+AjGoUkXmN9ToSNICCGZJk4r6hIA9yuldiulSgA+DeClMR4vPdwyysij0E2zmKTGRwg88bMy4jWCDdFQWyNIIZgY/hrBwhDXCOac5k2ZHOMYRj2ZrlaBQ/eg9t4t9tIsxtYI0hEkXWB+TykECSEk28QpBE8GsNd3fZ+5LcjLReR2Efm8iJziu31cRHaJyA0icmXYAUTkjWafXYcOHerj0jukp/ERCTWL8TdIKc33FivLOg3RUNOsg81iksO6r4WpQDR0Ip31xMHkemB8TfP7a45gxJPpYw979YFAb+NfOD6C9IJ1BKsrUJ12vSWEEDIwxCkEw1RR8D/GfwLYrpS6AMA3AHzMd9+pSqmdAH4WwN+JyBkNT6bU1UqpnUqpnRs3buzXujvHraCkOhwoX2sWk9D4CL8LNurNYkTCu4YyJpcceX/XUH80dIgcwae8GXj9V5vfb2OwUYXgobvrr/fkCDIaSnrA/J4WqiWUXQpBQgjJKnEKwX0A/A7fNgD7/TsopWaVUrZA5gMAnuS7b7/Z7gZwHYCLY1xrb1QrqCAHp5O5fKk4gv5mMSNcI8iuoenjjECN4PgqYMNZze/vtEbw4F311/tSI8hoKOkC83s6JmUslTscf0IIIWRgiFMI3gTgLBHZISJFAK8GUNf9U0S2+q6+BMBd5va1IjJmLm8AcBmAYJOZwaFaRlnlke+oa6htFpPk+IiqrjMqL9ARVGE1gnRHEqNps5ghcgTbUeiwRvDQ3TpuaulpjqD58IkffpBusEIQZSxTCBJCSGaJ7cxXKVURkTcD+BqAPIAPK6XuEJG3AdillLoWwFtE5CUAKgCOALjKPPwcAP8iIlVosfrOkG6jg0M30dA0BspD6fpAYLSbxTQMlDeOIGNyyREWDc0VRmuER8eO4J3ASRfrrqGLh3tzBGvRUApB0gXmvUshSAgh2SbWM1+l1FcAfCVw25/4Lr8VwFtDHnc9gPPjXFtfMY5gd9HQhGoEbTTUCsFRbhbDaGj6WAHiF4LDFAuNgv1+y0vR9j+2Bzj1KcDS0d6FYI5CkPSAee+Oo8RoKCGEZJgEMokjgFtGSeW6bBaTVI2giYaWFvT1kZ4jyGho6lg3rOAbHzFKsVDA1ywmgiNYXgKWjwPTm4E1p+nuqp188BSE4yNIL+TycHNFjEsJSyUKQUIIySo88+0VpQDloow8nI5qBHPhl2PDuGD2pHPUTrr9NI2G0h1JjC0XABf9HHDKJfqDkMLk6DqCUWoE5x/T25ktwLrTe3+tauMj+C+AdEe1MIXJ0jKWy9X2OxNCCBlIeBbQKyZWWEKnNYK+fZOMhtL9QvNo6Ci/JgkzNg1c+X7venFq9D6c6MQRnDNCcHoLcNZzgCe8rLdjs0aQ9IgqTGFallkjSAghGYbR0F4xM+hK1Rzy3dQIAr1FvCIfz8QhOTyd0dBBZCQdQdssJkKN4PyjejuzuT/H5vgI0iOqMIVJLLNGkBBCMgyFYK8YEVFSeRS6GR8BJDtQvsoOmXUzFQHfQHm6I6lRnKYj2Aq/I9gP7O8/P/wg3VKcwhSWWSNICCEZhkKwV0x92bKbQyHfycvpE4JJNothDBKN0VC6pKkzNu3N1RsV8o5+z0WqEXxU7+ufI9gLOTaLIb0hY1OYlBUsVygECSEkq/DMt1eMI1hGHhPFDgRdXbOYpISg8tyvURY9jIYOHpf/YUJNkwYMZzy6Izi1qX8xco6PID0iY9OYwsN0BAkhJMPwzLdXjMNWQR4ThU6EYNKOYA46Gkr3q+aOWhgNTZ/Tn5n2CtLBGWs/R/D4I9oR7Fd9IMDxEaRn8uMzmASbxRBCSJYZYTXQJ9wSAKCsenEEExofwWiogV1DyYDQzhHceyPwoefqy2e/oH/H5fgI0iO5sWlMCcdHEEJIluFZQK+Yk7gVFDtzBFOpEVQUPUBINNS+JnQEScI44/U1gkvHtDOdHwOWjgA3fsC7b6pP9YEAx0eQ3ilOYRIr7BpKCCEZZoTVQJ8wJ3HLKGC8o2ho0jWCNhpKIdg4UN5GQ0f4NSHpEBSCn3oVMLkB2HQO8N2/1R9abH4C8NiPvfdpP5hYp7f9aj5DRo/itG4WUyqlvRJCCCFdwjPfXinrk7gVFDHJaGhGYDSUDAjOWL0QPHgXUJoH9t4AFKf0fS//EPDgd4Czn9+/4256PPBrNwAbH9+/5ySJISKnAPg4gC0AqgCuVkr9faKLKE4BAKrLC4kelhBCSP/gmW+vmJO4FVXosEYw7WhoErMLB5SmXUMZkyMJ468RXDoGrJzQlxdngVd9AjjjcmBsRgu3frPpnP4/J0mKCoDfUUrdIiIzAG4Wka8rpe5MbAVWCK7MJ3ZIQggh/WUE+7X3GXMSt9xpjWDa0dBRrg0KRkPZSZWkhd8RPL5Xb3MOMLFWO4BjM+mtjQwsSqkDSqlbzOU5AHcBODnRRRSnAQDuMoUgIYRkFZ759kpFt35f6bRGsK5ZTFLRUNYIagLRULesxWEiPwdCfBQmgMXD+vIxIwSv/Gdg/elaJBLSBhHZDuBiAD9I9MDGEXRX5hI9LCGEkP4xymqgP9S6hvYQDeVA+WQJi4YyFkrSwBmr1Rnj+D69Pf0ZwPSm9NZEMoOITAP4NwC/pZQ6EXL/GwG8EQBOPfXU/h7cOIJqhTWChBCSVWiB9IrtGqqKmOw2GprUQHlVZQwSMK+FXwi6ox2VJenhrxE8vkePjZjamO6aSCYQkQK0CPykUurfw/ZRSl2tlNqplNq5cWOf31dWCJYYDSWEkKxCIdgrta6hA+4IAuD4CEtINHSUm+eQ9PDXCB7bC6zeVv+3gZAQREQAfAjAXUqp96SyCBMNlTIdQUIIySoUgr1S8YTgmNPBy5mKI0ghCIDRUDI4OBM+R3AvsOaUdNdDssJlAH4ewLNE5Fbz9cJEV2CEYMFdQtmtttmZEELIIDLCaqBPmJO4XGEC0skn+SZWAyDBGkHOEQTgvRaWaoXRUJIOzlit4RSO7e3vrEAytCilvou6jmMpYITgNJYwv1zB2qliqsshhBDSOXQEe6WyjIo4GCt2KCROuhi46Of05USiYCYOSSGIxmhoZcRfD5IazjjgloDSIrBwEFjT54YehMSF+TBzEiuYW66kvBhCCCHdwLPfXqksoyIdzhAEtPh76fuAc18KnPqUeNZWdzx/NFRGe1RCQ7OYMoUgSQc7IuLIbr1dvS29tRDSCU4RVSlgSpYxt1JOezWEEEK6gGe/vVJZRlmKnTWKsYgkFwXzR0NHPQYZFg2lECRpUJjQ29n79HY1awRJdnALU5gsL9MRJISQjDLCtlCfqKxgBV04gonji4aOvOgJ6Ro66uKYpIN1BA/fr7dsFkMyhCpOYQoUgoQQklUoBHulvIQSCoMvBG0ckvVwIdFQviYkJZxxvT18LwABVp2c6nII6YjiNKZlCfOMhhJCSCahEOwV4wiOdxMNTRJ/NHTUZ+YxGkoGBesIzt4HzGylM00yhUyswRos0BEkhJCMQiHYK5VlLKOIyUF3BOuioaN+ssloKBkQHFMjePh+xkJJ5shNrccamacQJISQjEIh2CuVZSwrp7tmMUni7xo66u5XaDSUQpCkwObzAAhQmmOjGJI58pPrKAQJISTDUAj2SmUZS6qA8UF3BEWMEHQpBO1rYWFclqTF2tOAM5+tL9MRJFljci3WyjzmllkjSAghWYRCsFcqK1iqZqFZjI2Glil6GA0lg8TO1+stHUGSNSbWYhwlLC8upL0SQgghXUAh2COqvITFqoOJ4qC/lP5mMaPuCDIaSgaIs68Afuo9wBNelvZKCOmMibUAALV0NOWFEEII6YYRVwR9oLKMZVXAZHHAX8paNJQD5cO7ho66S0pSI5cHfuINaa+CkM6ZWAcAkKUjKS+EEEJINwy6jTXwqMoKllHMQI1gDjoa6lL0AGA0lBBCesQ4grnlYykvhBBCSDdQCPZKZRkrWRgob6OhbpnRUEZDCSGkdya1IwhGQwkhJJNQCPaIKi9hBQU8bstM2ktpjT8aOvJCkAPlCSGkZ4wj6KwcRbWq2uxMCCFk0KAQ7IF7DxxFXrk466QNeNJpa9NeTmtq0VC6X+FdQykECSGkI0yN4GrM4+hiKeXFEEII6RQKwR747PfvBwA87ZwstH23XUNZI6ijoXQECSGkJwoTcHNFrJF5zC5QCBJCSNbg2W+HfOPOx3DvfXdjp/ox9v5oCQAwOTmV8qoi4I+GOmNpryZdggPlKyuAM57eegghJIuIwB1bgzWleRyeW8HZmwe8RIIQQkgdFIId8B9f/Dd89Qe3408LH8dWOYJL7B1ZEFa2QUqVzWLqoqFKAaV5oDid6ooIISSLqIm1WDs/j8N0BAkhJHOMuiLwUAp44Jvh9zkT+MhDa/Ezt7wJVxZXoMZW4c7H/QHOvf2dtfsHHyN+GIOsj4aWFwEooJgBV5cQQgaM3OQ6rJGjuGNuJe2lEEII6ZARVwQeSlUh17y86f3Tladj0lmB+6w/Qf6CV+LcyfVATQhmyRF02RhFxLtcWtBbCkFCCOkYZ3oD1skeHJ6nECSEkKwx4orAQynBy1f+LPS+vy28H690vgPlTCD/lF8DCgEHMAv1ZQLTLIaOoH4x4MVCAUZDCSGkC2TVSdgq38TsPKOhhBCSNUZdEdSQnOAvfuP1ofdN/6gMfP/tkNOfUS8CN5wNHL43G44go6EeYprlqqrnCI5RCBJCSMesPhnTWMT8iSNpr4QQQkiHjLgi8BARnHfS6vA7V78euPX9wBMC0dFtl2ghuDIX/wJ7xUZDXQrBWjRUKWDFOoKMhhJCSMesOhkAIHP7U14IIYSQThlxRRCRqQ3A7+4GcoGxi1e8A5jeBJz9/HTW1QkijIbWsDWCylcjSEeQEEI6xgjB4jyFICGEZI1RVwTRCYpAABhfDTznT5NfS1cwGlqj5ghWfTWCdAQJIaRjVmshOLn8KJRSEH8zLkIIIQNNiLohQ0mtayiFYF00lF1DCSGke2a2QkGwUc3iEDuHEkJIpqAQHBUYDfXhj4ZaR3AmtdUQQkhmyRdQmtiErZjFntnFtFdDCCGkA0ZdEYwQ/mhoPu3FpEtd11BGQ0l2KJfL2LdvH5aXl9NeSmKMj49j27ZtKBQKaS+FNEGtOglb52fx0Owidm5fl/ZyCCGERIRCcFSQnOcI5kf8hCoYDZV8RkaAkFFn3759mJmZwfbt20eiFksphdnZWezbtw87duxIezmkCcV1p+KkAzfiptmFtJdCCCGkAxgNHRVEAAVGQwE0dA0tTnvikJABZnl5GevXrx8JEQjosT7r168fKQc0i+RWb8NJuSN4mEKQEEIyBYXgqCA5QLnaFRx1IRiMhjIWSjLEqIhAy6h9v1ERkQ+LyEER+XHaa8GGMzGBFSweeijtlRBCCOkACsGRQQC3rC+OfI1gYKD8GGcIEhKF2dlZXHTRRbjooouwZcsWnHzyybXrpVIp0nO87nWvwz333BPzSkeCjwK4Iu1FAAA2PwEAMHn07pQXQv5/e3ceJ1V1LXr8t2qunummGZsZFBAUAVGR6FURBV/UvJiE3Jg44CUac2NuYhLz4rvicI0ab140mBBN8BlvPg7RaDSJ13meQBGQQQUBm6GxJ3rums7Z9499aBpoEJruru6q9f186lOnTg29Vu3q2rVq77NLKaUOR5YPDWUREXC8D2q+LD9GcL+poToiqNShKCkpYeXKlQAsWrSIvLw8rrnmmr1uY4zBGIOvo99eBe67775ujzMbGGNeFZGR6Y4DgAETAChLbKa+NUlhNNv7GKWU6ht0RDBbiLdqKOjU0Lapoe2OEVRKddrGjRuZNGkSV1xxBVOnTqWiooKFCxcyffp0jjnmGG688ca2286aNYuVK1eSSqUoKiri2muv5bjjjuPkk0+msrIyjVmoTgvn05pbxnhfOesrGtIdjVJKqUOU5RVBNml3nE3WF4LtVw1tgoIh6Y1HqU644am1rNvRtR+6Jw4p4PovHtOp+65bt4777ruPJUuWAHDrrbdSXFxMKpXi9NNP58ILL2TixIl73ae+vp7TTjuNW2+9lR/84AcsXbqUa6+99ojzUJaILAQWAgwfPrxb/5Z/8GTGN67mufJdnDS6pFv/llJKqa6hI4LZov2CC9l+jOC+PyivI4JKHbExY8ZwwgkntF1+8MEHmTp1KlOnTmX9+vWsW7duv/tEo1Hmzp0LwLRp09iyZUtPhZsVjDH3GGOmG2Oml5aWduvfCg2ZxGhfBas366iuUkr1Fd06NCQi5wB3An7g98aYW/e5/hLgF8B2b9diY8zvvesuBq7z9t9sjLm/O2PNeNKu5tcRQXtuXD1GUPVZnR256y65uXv+jzZs2MCdd97JsmXLKCoq4qKLLurwJyBCoVDbtt/vJ5VK9UisqhsMPg4/LqmtyzHmZF3tVSml+oBuGxEUET9wNzAXmAh8XUQmdnDTh40xU7zT7iKwGLgeOBGYAVwvIv26K9bs0K5T1h+Ut+d6jKBS3aKhoYH8/HwKCgqoqKjgmWeeSXdIGUdEHgTeAo4WkW0isiCtAY06FVcCTEssp7y2Ja2hKKWUOjTdOTQ0A9hojNkEICIPAecD+88P2t/ZwHPGmFrvvs9hl8l+sJtizXyixwjusbsQdHREUKluMHXqVCZOnMikSZMYPXo0p5xySrpDyjjGmK+nO4a9RAqJDZnB6VtX8vJHVVw8U99XlVKqt+vOimAosLXd5W3YEb59fVlETgU+Bv7NGLP1APcd2l2BZgWdGrrH7uci0QIYLQSV6oRFixa1bY8dO7btZyXA/gj8Aw880OH9Xn/99bbturq6tu358+czf/78rg9U9ZicY+Yxfvt1/OLd97l45sh0h6OUUupzdGdF0NEBAmafy08BDxpj4iJyBXA/cMYh3rdHV0Tr+3SxmDaBiD1f/bA9LyxLXyxKKZUpjp4Hz17HcZVP8EnVWYwp1Wn3fdILN9rfHT79OghG0h2Nylbv3Q9v/hpaaqBoOJSMgaHTIJwP4reDGgWDoWCo/VxbNGLv2W/qkHRnIbgNGNbuchmwo/0NjDE17S7eC9zW7r7/tM99X973Dxhj7gHuAZg+ffp+haJqZ68RwSw/RnD8PMjpD6/eDoXDYcJ56Y5IKaX6vpIxxMaeyyUbnuWOF1dx49f60JTg6o0QzoP8QemOJL1cF95eAslm+OQluPA+KD0q3VHtzRho2J7ZXxf0N5wAABv8SURBVOLuWAnJFhgx016ON9oCKFs018Df/g0GTYKRs6CuHMrfhjWPHfg+xaNh+MlQsRpGnQpHzYH8Ifb167rgO4xlUcrfgcYdMPGCjC8uu7MQXA6ME5FR2FVB5wP/3P4GIjLYGFPhXTwPWO9tPwPc0m6BmDnAT7sx1synxwjuESmE2dfDk/8Kp/0YAqHPv49SSqnPFTnjx0Q2/p1xH/ySZTMmMGNUcbpD+nxOEu49wxY/s34AZ/ws3RGlT/1W+zxM/gp88iL87lQ4+2aYvqD3fCBe9RA8cQWccR184ZreE1dXefu38Mz/sdszvwefrYGNz8MJl8Np10Je9/4UzCFLNENDBfQbcfiLENZthXVPwLg5UHr0/td/+JRdx+G8xTD4WLvPGDs6mIqB64CbgtpN0FxtC+UNz8L6p6BkLLx9tz2JD0onQNWHMGAC9BtpRw+dpP0N6YHHQDAXRp8GTZXQWgvJGDx6mf0/mHAelJ1gH3/I8TD2TAiEO/d8JVvh5VuhYqUd2Tz1RxCMdu6xulC3VQTGmJSIfBdb1PmBpcaYtSJyI/CuMeZJ4Hsich6QAmqBS7z71orITdhiEuDG3QvHqM7SQnAvx38TymZ0/AaklFKqc4ZMIXnSv/LNt3/N4j/+lMAltzB1RCd+YD7WYEcB+o20I3XdaedqiNfDgIl2psiQKTD+3O79m71V1Yf2/ITL4ayb4K9Xwd9/aD/wn3Fd7yi6PnjEfsB/8WY7cnT2LYc32tObpeLwwk12RMsYeONXkDcIJp4Py39vT2Uz7P9EUxUcN98WE04S3KQdQRw6rePH3vkBtO6CQcdCtOjI4ty+Au7/ov0t5oKhcNKVMPViiBTY/90tr9kib/fnzfavm+3vwdJz7PTj138FX3sAhp2457AlY2DNX6B4DAyavOd+IpDbf+84Ssbs2T5x4d65NlfDR/+wo6snfhuqN0DNRvv4/hBsesUWex3JHwwnXAbv3gfrn9yzP3eAVxg2QO1mSLXC6NPte0jxGFsofvwM7NoMw06CHStsHEfNgU/ftIXrwMnw2n/C2idsWzVW2DYZfqId1Swd36Or+3drRWCM+Qfwj332/Xu77Z9ygJE+Y8xSYGl3xpdVou1+fSPbjxEE+4YyYHy6o1BKqYwTnHMDzTVb+e6Gh1j9h2U8PPgChh17GiMnTGNwv7zP/41BY+BPX4Gtb9sPXt9+1R4L1F3K3wbAmf8gvj9/C3n0MltcTL+sdxQ+PanSm5hVerT93PCNR+FvV8Nrd9gRl7NugDFnpC++1l2w+VU4+bu2+Hnnt3Zk6eTvwslXpa+9UglbRO8evSp/245ajZhpi6UdK+0Ux/bxua4tiurLYdzZtrj79A1bnJx4pS2kmishb6C93/YVsOllWHE/NOywxdyzHYxel463x9S5KXsyxt52/d9oW25j0GQ44//aLz9CufaxC8tsm7dUQ/+j9hQjn62DUI79UmZ33P+4BoI5cPZ/wAePwrPXwSu324Ju6zL7xcqo0+zrKRiB3FL7fBx1ji2sckrgS0vgsX+B++bawn7gJFuwvXSLnfp76o873567C8gxpx+8zZqroGknbHnD5p9bCrE6GDrdvuecdRPE6m2xvflVWxjWldvnY+QsWwh+/AyUTYPKtfDx0xDKh4ET7ety+Mn2uVz1EJSMg28+YWPa8Lz9nyp/y/7NZffYEUywz82PPumx17IYkxmH1k2fPt28++676Q6j9yp/G5aebbcv/huM+kJ641FKHbb169czYcKEdIfR4zrKW0TeM8ZMT1NIfU6P95HG0Lz8AVpf/AX9Y+UAxE2QKvpRFyihOVRKPFKKkzcQX/4gIoWl5BYNpKBkIKWtnxB97Fs0H3cp0TUPIiNOQr50D+QPPLwYPltrRxzCeTB4Ckz4IuR0MFX14W/iVqzigsBvyE/V8vuC3xMtfwXGzrYfZguG2OKno/tmmsevgE9e4tm5r/BZQ4yLThqBGAMr/wte/392ROPoc+ELP7Qffnva+3+Cv34HZ8GL+MumwtrHYcUfYdNLMPmrtrg4lC+7W+vgie/AxPNsAeLE9x9J27ESCofBjveh/E1bmHS0eE7FKnuoScUquOC3MOZMuPNYO4WxeDQ4KVvsHTUXTlgA7/1/O8WxZqMtRMD+nvGxX7VTENc/BT/ebIuNgzHGFoQ+vx3hMi6sfsQWi0077XoQvoCdYlm7GSb8L/s/ULHKxlBXfuDHzimBubfDtuXwzhK7b/jJMO1SW6yuuB8uWAJTvF+x2b4C3lpsi8YhU+yI2uu/tM9t/iA73dJNwtZ37O2/9icbT0stbHwBqtbbIqu11k7lnPEvduZWXzp0xxj7/xEpgtx9ZkEkWuxChQcauY41wK4tUP2xfW2c+O0jCuVw+kctBLNFohluGWK3L3sGhp+U3niUUoct3YVgTU0NZ555JgA7d+7E7/dTWmqPV1m2bBmh0KF12kuXLmXevHkMGnRoC3NoIXjk0tZHGkOiagNb17xBbOtKUnXbCbdWkZespp9TQy6tHd5tqxnAGYk7uND3Cj8P/gEABx91/v5ETSuxQD7VBROJmBgpCWB8IQhEkECYoA8kGGHA1n9AKo5jIOo0kQzkUTvkNKRwKDlFg/CFo/hDUYIv38ybTOFbuy4jNxQg6aS4beibzKv9I8Fkg00jlIdbOhGJFuEbdxamcCgSjII/bI8ZihTZaWuRwv2/yU+02GlwgbC9vRO309SKR+2/AEi80Z7vu99J2eloyVZ7XTjf/p0d79uCJafY/u1X77DHSB09134Ij/bbcxzSwUYYEs22OHro6zT5Cpj66VUkUi4XTBnCz86dSGl+2P7t138Fy++1H1zP/Hc78uEk7Qf/ouF7zz7qihENJ2mPq2quhEkXwrPX0dTUwPT6n/P92Uez8Auj8Qk275dutsc2zvvFnjhqN9kFRkrG2ql6a/9ip+ptec0WOYgdjfL54dxf2kJk5wfQuNPeZsBEW2zF6uwUSH/Itlv1BlvUtdbZ6ZvRYigcCjWb7CjgJy/a0bIP/27bbexseOtuWxxGCu30wPyBdqXd/EG2wF3zmH1tjD0LLnr0yJ+7g0m0wOZXbCEaq7fHz1VvsG1cMBTeuNOOcIGdJlw0HJbda48hBTjl+zB70cHbeOca+7y3L55j9dD4WccLENV8Yp+DE6+wU0xVp2khqDq2qNCeX/4ClOnnJ6X6mnQXgu0tWrSIvLw8rrnmmsO+76xZs1i8eDFTpkw5pNtrIXjkemsfaeKNNFZvp67mMxprK2mt+wxTt5UPItNoGXA8AwoifPjBe4ysfpmI20xJqpJGE6YkVUmZu4NGcgjiECJJWJKESeIiRInTQC4XJ35CZXg4IxMbWeh/ikmymcFSS0SSe8VxTeo7TDvvSmaN7c9vXv6Ep1btoCmeJJ9WxsgOLg38N6XUUearYrhUfW5eLj4MYBACOAe4jZCUEK2+PFqCxUSIURyzH7TrQ4NoCpYQclrIS1YTdRr3uq+Dn7g/lxynYa/9u3zFRNwWosT2vr0vTEPRBIKJemKRUuKR/hQ0biQYryMeLqaw/sO22z7sP5c7fJfx5all3PvaJgCGFkUZUZLD8OIcRuUm+eJHP2FgzbL9ckoF8xBjEJMilT+MVN4QCIRIFY1GRIj7IpjC4RTlBKFhB27pMQQTu4hVbSYeHUgoECAnWYMUDbfHXC37Hax5DBMphHgjYlwW+a7iUec0muIpZo4p4eozxzFuYD5Fy3+F7+Vb7Oja8JNsgbfxOTtSBhAutFMWxW9HZ865xS7CEimEbe/ZUSmwo4ChPBg2w442+oNw1o12aqA/ZEfywC7iAnD8RTDnP+wqnw/8b/s4U74BF/xm7yendRdsfs1On+xodLvqYzvFcsZCGDe7w9dMj4k32edmyJQ9U0KdlJ3+KmIXWekBlY0xKhviTBhcgN+XZdO0j4AWgqpjPx9u3wQXvmxXP1JK9Sm9uRC8//77ufvuu0kkEsycOZPFixfjui6XXnopK1euxBjDwoULGThwIAsWLGDo0KFEo9FDGknUQvDIZWIf6biGlkSKoN9HPOUSTzq0Jh1aEg4t8RSOayjJDzO6fy4Jx+XTmhYaYylqm+JU79qFScZwkjGaY3H+6YTjGT+4sO2xEymXdRUNbN/VSkV9KynX4BehKZaExgpK2UVLSzM+N4HfTRBKNhCO1xJINZJyXBzHBVyMMTSbKAmChH0pioIu4YCfTWYQBS3lFEorUbeJnGQNCQdWmqMwCOPlU4qkiRYiVNGPXaaAJsklJiHyaaGQZgppYrMM5Y3AiRwdrGQiW3g+Zy75+fn0r34Pdm0h1zQRlTgFtHCMbwu1poABsot+NPIZxew0/SilnmXueKopZKDUsqLwHH749XlMLitkU1UTj7+/nc3VzZTXtvBpTQv1rUkEl5HyGSXUkyTAINlFmVQyTKpw8ZHCzzCpZJDsIkKC0VKBg48wCfyy/+dOx0iH+wHuSH2VB1Kz+XP4RoKkmJO4nceuOo31FQ3c8NQ6WhK20PYJTA9vY748y0T3Y3IlwdvhU3gh71z+ufm/GOps5XfF17AzNAq/T/CJ0BBLEgn6GRCMMSL+Mc1FR7MllkPSMQzID3Nc/fM0xuGtyCyiIT+RoJ9o0E++L8ElH19Fc6iEJ8ffjkMA1xiM6zC8YTnbcycRkxwM0Jp0aIylyAsHKIgGKIgECQd8+ERsHD7BL4LfB4KwobKRVVvraYglGVoUZWi/KIMLoxTlBMmPBEg6LpuqmqlrSTKiJIeg37f3Y4iQGwqQE/ZT35Ik6PcRDvgIBXzEkg51LUlqWxIkUi6jS3MJ+X24xuAa2s5TjkvKMRTnhqhuitMvN2RHhbFLD4qId25jbj8wuHufz4c3wu5isNt+n1DbnGBzdTO5YT/FuSH654URgZa4QzTkJyfkJ+j38eKHlfzk0dU0xlPkhwNMLitkQH6YopwQuWE/kYDXHiE/uWE/uaEAueFAW67hgJ9I0Icx0BhLkRv2UxANUhAJEgrsPUUz5bjUNCcojAaJBPefWuy6hoTjEg74Pv8Y5wMwxmAM+HqgoD2c/lGXj8wmQ46z32jFm9IdiVLqSD19rZ3C1JUGTYa5tx723dasWcPjjz/Om2++SSAQYOHChTz00EOMGTOG6upqPvjAxllXV0dRURG//vWvD2tEUKmO+H1CfsQuaBEJ+iF64JX2wgE/Rw1sP93y4NOSQwEfU4YVMWVYR6srdt9q02ce4f0vaduaSdJxqW9NthXJCcelSASfQNJAgWPIxxD0+zjPKySSjsuV/XMJ+u0H5dGlefxwzt75tiYcqpvi1LcmcY0h5Rpc1+C4hnDQT0siRV1LEscYyl2DawzrHIMD5AYcqN/BrsZmWiMDKG7exC5fEcGiMvq7VbTEU3yaKsK3azN5LVsp94+geNjRXBH082TLg4RMkvuOGsGxZUUcW1bEOZMGs3xzLVt3tVDbnKC+dQTvujP5MBygoTVJdVOceMrlt+Gf4BgboxOzXxI4rqEgGqC+NUlFPaxwx1G7I8aAfEMo4GP1tjqeZzJFOSEiqTixpEss6RBLOrQmHO5N/gzHCLJzCz7vebVF0UB8Uo0I+EQIB3zkRwI0xR0aWpMkHPegbRgK+DhmSAFDi6LsqI+xfEstDbHUXrfxiS2sGuOpAzxKZpgwuIAFs0axonwXa3c0sKK8jl3NCVqSDo7b+YEsEfCL/TJg9+tiN7/3vxD0C6GAj9akQyxp2ywU8LW1c27YjzFty++0yY8EyAsHaIylaIwlaY47FESDNMSSJFIuPoGA30fQJ/bc7yPoFwJ+Iejz0T8/zCPfPrnTuR0uLQSzyZfugVdutdMdlFKqizz//PMsX76c6dPtF5Ctra0MGzaMs88+m48++oirr76aefPmMWfOnDRHqlT2CPp99M/r5G+eHUQ05GdYcQ7DOv0II9ttH9due1y77WMP6ZEKo0FmTzzMRYS6iDGmU6NDMa8o3108O8bgunjnhoEFkf1GrJrjKRpiSRpjKQI+YVBhhGjQT0NripTr7vcYTfEULYkURTkhHNcQT7rEUw7hgJ9+uUH65YTw+4TN1c04rmkbIfWJHe3z+4SAT6huitM/L9xW+BsAAwY7utW+EDLG2OnQ3o1cA02xFMGAfezmuIPjuhTmhBhZkkMs6VLbHKe6KYExhtxwwI7ox22xPWFwAbPG9ScS9HPhtLL9nsekYwvzloRDczxFc9yhOZEikXJJpFziKXs92OKsJeHQEEvaYjzl2i8wDPh9EPAKsPqWBK1JB9dAPOmSdFyiITsKHA76qG+xz4HrGlqSzl6jojZrQ31riuZ4inEDAhREg0RDdmS2IBokJ+Qn5RiSrh1xTTkuSdeQ9OJJOi554Z4tzbQQzCYFg+GLd6Y7CqVUV+jEyF13McZw2WWXcdNNN+133erVq3n66ae56667eOyxx7jnnnvSEKFSSnWtzk4RjAT9HU4/PJjcsJ322G72MgCFOUf2e3MTBh98UZZhxTl7nfcmQW80bfesANU5GfILnEoppdJl9uzZPPLII1RXVwN2ddHy8nKqqqowxvCVr3yFG264gRUrVgCQn59PY2PjwR5SKaWUUt1MRwSVUkodkcmTJ3P99dcze/ZsXNclGAyyZMkS/H4/CxYsaJtCddtttwFw6aWXcvnllx/yYjFKKaWU6nq6aqhSSvURvWnV0J6kq4YeOe0jlVIqOxxO/6hTQ5VSSimllFIqy2ghqJRSSimllFJZRgtBpZRSSimllMoyWggqpVQfkinHdR+qbMtXKaWU6ilaCCqlVB8RiUSoqanJmuLIGENNTQ2RSCTdoSillFIZR38+Qiml+oiysjK2bdtGVVVVukPpMZFIhLKysnSHoZRSSmUcLQSVUqqPCAaDjBo1Kt1hKKWUUioD6NRQpZRSSimllMoyWggqpZRSSimlVJbRQlAppZRSSimlsoxkyupzIlIFfNoFD9UfqO6Cx+ntsiHPbMgRNM9Mo3kemhHGmNKuCibTdVEfqa/NzKJ5ZpZsyDMbcoQe7B8zphDsKiLyrjFmerrj6G7ZkGc25AiaZ6bRPFVvlS1tpnlmFs0zc2RDjtCzeerUUKWUUkoppZTKMloIKqWUUkoppVSW0UJwf/ekO4Aekg15ZkOOoHlmGs1T9VbZ0maaZ2bRPDNHNuQIPZinHiOolFJKKaWUUllGRwSVUkoppZRSKstoIegRkXNE5CMR2Sgi16Y7nq4kIltE5AMRWSki73r7ikXkORHZ4J33S3ech0tElopIpYisabevw7zEustr39UiMjV9kR+eA+S5SES2e226UkTmtbvup16eH4nI2emJ+vCIyDAReUlE1ovIWhG52tufUe15kDwzrT0jIrJMRFZ5ed7g7R8lIu947fmwiIS8/WHv8kbv+pHpjF/tT/tI7SN7o2zoH0H7yExr017VRxpjsv4E+IFPgNFACFgFTEx3XF2Y3xag/z77bgeu9bavBW5Ld5ydyOtUYCqw5vPyAuYBTwMCnAS8k+74jzDPRcA1Hdx2ovf6DQOjvNe1P905HEKOg4Gp3nY+8LGXS0a150HyzLT2FCDP2w4C73jt9Agw39u/BLjS2/4OsMTbng88nO4c9LRXe2ofqX1krzxlQ//oxa59ZAa1aW/qI3VE0JoBbDTGbDLGJICHgPPTHFN3Ox+439u+H7ggjbF0ijHmVaB2n90Hyut84I/GehsoEpHBPRPpkTlAngdyPvCQMSZujNkMbMS+vns1Y0yFMWaFt90IrAeGkmHteZA8D6SvtqcxxjR5F4PeyQBnAI96+/dtz93t/ChwpohID4WrPp/2kdpH9krZ0D+C9pEHuUufbNPe1EdqIWgNBba2u7yNg7/w+hoDPCsi74nIQm/fQGNMBdh/PGBA2qLrWgfKKxPb+LvelI+l7aYt9fk8vSkPx2O/IcvY9twnT8iw9hQRv4isBCqB57Df1NYZY1LeTdrn0pand309UNKzEauD6LOvw0OkfWTmtXFGvZ+2p31kZrRpb+kjtRC0OqqqM2k51VOMMVOBucBVInJqugNKg0xr498CY4ApQAXwn97+Pp2niOQBjwHfN8Y0HOymHezry3lmXHsaYxxjzBSgDPsN7YSObuad99k8s0Smt4/2kZnVxhn3frqb9pGZ06a9pY/UQtDaBgxrd7kM2JGmWLqcMWaHd14JPI59wX22e5qAd16Zvgi71IHyyqg2NsZ85r2JuMC97JkK0WfzFJEg9o3/T8aYv3i7M649O8ozE9tzN2NMHfAy9viHIhEJeFe1z6UtT+/6Qg59upfqfn3+dXgw2kcCGdTGmfp+qn1k5rUppL+P1ELQWg6M81brCWEPxHwyzTF1CRHJFZH83dvAHGANNr+LvZtdDPw1PRF2uQPl9STwLW8lrZOA+t3TKfqifeb6fwnbpmDznO+tMDUKGAcs6+n4Dpc31/0PwHpjzC/bXZVR7XmgPDOwPUtFpMjbjgKzscd6vARc6N1s3/bc3c4XAi8aY/rEt7pZQvtI7SP7jEx7PwXtIzOtTXtVH3moq8pk+gm7wtLH2Dm6P0t3PF2Y12jsikqrgLW7c8POLX4B2OCdF6c71k7k9iB2ikAS+23JggPlhR1Wv9tr3w+A6emO/wjzfMDLY7X3BjG43e1/5uX5ETA33fEfYo6zsNMcVgMrvdO8TGvPg+SZae15LPC+l88a4N+9/aOxnfRG4M9A2Nsf8S5v9K4fne4c9LRfm2of2QviPczcMr6PzIb+0Ytb+8gMatPe1EeK9weUUkoppZRSSmUJnRqqlFJKKaWUUllGC0GllFJKKaWUyjJaCCqllFJKKaVUltFCUCmllFJKKaWyjBaCSimllFJKKZVltBBUqhcQEUdEVrY7XduFjz1SRNZ8/i2VUkqp3kf7SKW6R+Dzb6KU6gGtxpgp6Q5CKaWU6oW0j1SqG+iIoFK9mIhsEZHbRGSZdxrr7R8hIi+IyGrvfLi3f6CIPC4iq7zTTO+h/CJyr4isFZFnRSSatqSUUkqpLqB9pFJHRgtBpXqH6D7TXr7W7roGY8wMYDHwK2/fYuCPxphjgT8Bd3n77wJeMcYcB0wF1nr7xwF3G2OOAeqAL3dzPkoppVRX0T5SqW4gxph0x6BU1hORJmNMXgf7twBnGGM2iUgQ2GmMKRGRamCwMSbp7a8wxvQXkSqgzBgTb/cYI4HnjDHjvMs/AYLGmJu7PzOllFLqyGgfqVT30BFBpXo/c4DtA92mI/F22w56fLBSSqnMoH2kUp2khaBSvd/X2p2/5W2/Ccz3tr8BvO5tvwBcCSAifhEp6KkglVJKqTTQPlKpTtJvPJTqHaIisrLd5f82xuxeHjssIu9gv7j5urfve8BSEfkRUAVc6u2/GrhHRBZgv9W8Eqjo9uiVUkqp7qN9pFLdQI8RVKoX845/mG6MqU53LEoppVRvon2kUkdGp4YqpZRSSimlVJbREUGllFJKKaWUyjI6IqiUUkoppZRSWUYLQaWUUkoppZTKMloIKqWUUkoppVSW0UJQKaWUUkoppbKMFoJKKaWUUkoplWW0EFRKKaWUUkqpLPM/mqfnK8l/YxYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy and loss\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see model performance have improved with the K fold cross validation, but still it is very unusual and distributed/overfitted. So we will go with the Feature engineering in the next file. We will perform pca analysis, and run models with less features. Finally we will run prediction model on entire dataset to finalize our AL driven portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
